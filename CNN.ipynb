{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-21T23:56:58.441990Z",
     "start_time": "2024-08-21T23:56:54.268473Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T00:03:06.306678Z",
     "start_time": "2024-08-14T00:03:05.419145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('datasets/dataset_L.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, :-7].values  # First 170 columns as features\n",
    "y = df.iloc[:, -7:].values  # Last 7 columns as labels\n",
    "\n",
    "# Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n"
   ],
   "id": "a8b0ab4089c2ef9d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN with drop out, 3 layers",
   "id": "a3458faed127469b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T00:03:11.852272Z",
     "start_time": "2024-08-14T00:03:11.836716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n=32):\n",
    "        super(NetDropout, self).__init__()\n",
    "        self.n = n\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, self.n, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout1d(p=0.3)\n",
    "        self.conv2 = nn.Conv1d(self.n, self.n // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout1d(p=0.3)\n",
    "        self.conv3 = nn.Conv1d(self.n // 2, self.n // 2, kernel_size=3, padding=1)\n",
    "        self.conv3_dropout = nn.Dropout1d(p=0.3)\n",
    "\n",
    "        # Calculate the correct input size for the fully connected layer\n",
    "        self.fc1 = nn.Linear((self.n // 2) * (170 // 8), 32)  # 170 // 8 due to three max_pool1d with kernel_size=2\n",
    "        self.fc2 = nn.Linear(32, 7)\n",
    "        \n",
    "        self.lsftmx = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool1d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool1d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = F.max_pool1d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = self.conv3_dropout(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.lsftmx(self.fc2(out))\n",
    "        return out\n"
   ],
   "id": "f56801f7aa7adcfd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN with drop out, 4 layers",
   "id": "66b547bd68bfebc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:07:03.712242Z",
     "start_time": "2024-08-13T02:07:03.699332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class NetDropoutBig(nn.Module):\n",
    "    def __init__(self, n=32):\n",
    "        super(NetDropoutBig, self).__init__()\n",
    "        self.n = n\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, self.n, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout1d(p=0.3)\n",
    "        self.conv2 = nn.Conv1d(self.n, self.n // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout1d(p=0.3)\n",
    "        self.conv3 = nn.Conv1d(self.n // 2, self.n // 2, kernel_size=3, padding=1)\n",
    "        self.conv3_dropout = nn.Dropout1d(p=0.3)\n",
    "        self.conv4 = nn.Conv1d(self.n // 2, self.n // 4, kernel_size=3, padding=1)\n",
    "        self.conv4_dropout = nn.Dropout1d(p=0.3)\n",
    "\n",
    "        # Calculate the correct input size for the fully connected layer\n",
    "        self.fc1 = nn.Linear((self.n // 4) * (170 // 16), 32)  # 170 // 16 due to four max_pool1d with kernel_size=2\n",
    "        self.fc2 = nn.Linear(32, 7)\n",
    "        \n",
    "        self.lsftmx = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool1d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool1d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = F.max_pool1d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = self.conv3_dropout(out)\n",
    "        out = F.max_pool1d(torch.tanh(self.conv4(out)), 2)\n",
    "        out = self.conv4_dropout(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.lsftmx(self.fc2(out))\n",
    "        return out\n"
   ],
   "id": "ad1d2885163d3f14",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T00:04:16.151472Z",
     "start_time": "2024-08-14T00:04:13.384834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 80% training and 20% testing split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "n_epochs = 1000\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = NetDropout().to(device)\n",
    "# model = NetDropoutBig().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Assuming multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "3270b498b017dd09",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T00:37:15.884999Z",
     "start_time": "2024-08-14T00:04:36.397210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "for epoch in range(n_epochs):  # Number of epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n"
   ],
   "id": "9b875f77e2305975",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\IT\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8445943310612538\n",
      "Epoch 2, Loss: 1.6360719882353127\n",
      "Epoch 3, Loss: 1.5664033948398026\n",
      "Epoch 4, Loss: 1.5339192766216376\n",
      "Epoch 5, Loss: 1.5073629972247944\n",
      "Epoch 6, Loss: 1.4864669747877457\n",
      "Epoch 7, Loss: 1.4718741073820574\n",
      "Epoch 8, Loss: 1.458632116435004\n",
      "Epoch 9, Loss: 1.4457591772079468\n",
      "Epoch 10, Loss: 1.4347688692515013\n",
      "Epoch 11, Loss: 1.4188985853898721\n",
      "Epoch 12, Loss: 1.4141240750877864\n",
      "Epoch 13, Loss: 1.403741406612709\n",
      "Epoch 14, Loss: 1.3983021661883495\n",
      "Epoch 15, Loss: 1.3862218030442677\n",
      "Epoch 16, Loss: 1.3817402683460183\n",
      "Epoch 17, Loss: 1.3725943127756097\n",
      "Epoch 18, Loss: 1.366009218491771\n",
      "Epoch 19, Loss: 1.357849935667297\n",
      "Epoch 20, Loss: 1.3535859801171815\n",
      "Epoch 21, Loss: 1.3468883182042097\n",
      "Epoch 22, Loss: 1.3464042877285487\n",
      "Epoch 23, Loss: 1.3397634887164873\n",
      "Epoch 24, Loss: 1.3354763323724688\n",
      "Epoch 25, Loss: 1.3315461633914527\n",
      "Epoch 26, Loss: 1.3257412916742946\n",
      "Epoch 27, Loss: 1.319815563653057\n",
      "Epoch 28, Loss: 1.3166840548258476\n",
      "Epoch 29, Loss: 1.3128380619809554\n",
      "Epoch 30, Loss: 1.3076807210959094\n",
      "Epoch 31, Loss: 1.309854656876669\n",
      "Epoch 32, Loss: 1.3040566895270516\n",
      "Epoch 33, Loss: 1.301301263813671\n",
      "Epoch 34, Loss: 1.2958165862242008\n",
      "Epoch 35, Loss: 1.2931053570757427\n",
      "Epoch 36, Loss: 1.2932923217009604\n",
      "Epoch 37, Loss: 1.287164144689082\n",
      "Epoch 38, Loss: 1.286904123055572\n",
      "Epoch 39, Loss: 1.2835008070675495\n",
      "Epoch 40, Loss: 1.281376288841703\n",
      "Epoch 41, Loss: 1.2770639271311794\n",
      "Epoch 42, Loss: 1.2773392998223003\n",
      "Epoch 43, Loss: 1.274175746449263\n",
      "Epoch 44, Loss: 1.2722663429916883\n",
      "Epoch 45, Loss: 1.2669687342308724\n",
      "Epoch 46, Loss: 1.2679665219867537\n",
      "Epoch 47, Loss: 1.2629050015705252\n",
      "Epoch 48, Loss: 1.2627243272593764\n",
      "Epoch 49, Loss: 1.2589817370268443\n",
      "Epoch 50, Loss: 1.2587675651147159\n",
      "Epoch 51, Loss: 1.2604363745632439\n",
      "Epoch 52, Loss: 1.2588237373276114\n",
      "Epoch 53, Loss: 1.253818347387068\n",
      "Epoch 54, Loss: 1.2472741280004067\n",
      "Epoch 55, Loss: 1.2492831720680486\n",
      "Epoch 56, Loss: 1.2524089233936695\n",
      "Epoch 57, Loss: 1.2493950425880576\n",
      "Epoch 58, Loss: 1.2453824851914925\n",
      "Epoch 59, Loss: 1.2467306865601684\n",
      "Epoch 60, Loss: 1.2410501728152783\n",
      "Epoch 61, Loss: 1.2413156103054868\n",
      "Epoch 62, Loss: 1.2378479073421738\n",
      "Epoch 63, Loss: 1.2389275022636252\n",
      "Epoch 64, Loss: 1.2372942992619105\n",
      "Epoch 65, Loss: 1.236172821887483\n",
      "Epoch 66, Loss: 1.2338298414713884\n",
      "Epoch 67, Loss: 1.2311595864681226\n",
      "Epoch 68, Loss: 1.2318714879435733\n",
      "Epoch 69, Loss: 1.2314242296252373\n",
      "Epoch 70, Loss: 1.2251553561285453\n",
      "Epoch 71, Loss: 1.228307086075776\n",
      "Epoch 72, Loss: 1.2284488224313186\n",
      "Epoch 73, Loss: 1.223923253301156\n",
      "Epoch 74, Loss: 1.2232134213771417\n",
      "Epoch 75, Loss: 1.223567797651894\n",
      "Epoch 76, Loss: 1.2206947873989926\n",
      "Epoch 77, Loss: 1.2186617606975993\n",
      "Epoch 78, Loss: 1.2200872477937916\n",
      "Epoch 79, Loss: 1.217731337078282\n",
      "Epoch 80, Loss: 1.218122986705856\n",
      "Epoch 81, Loss: 1.216863859662965\n",
      "Epoch 82, Loss: 1.2159491272106662\n",
      "Epoch 83, Loss: 1.215088136372019\n",
      "Epoch 84, Loss: 1.2113655942385313\n",
      "Epoch 85, Loss: 1.2123043360559387\n",
      "Epoch 86, Loss: 1.2115900866181286\n",
      "Epoch 87, Loss: 1.2099737423086054\n",
      "Epoch 88, Loss: 1.212558688338523\n",
      "Epoch 89, Loss: 1.2107639287618062\n",
      "Epoch 90, Loss: 1.2106011410786899\n",
      "Epoch 91, Loss: 1.2101878216730069\n",
      "Epoch 92, Loss: 1.2084168086146863\n",
      "Epoch 93, Loss: 1.2080939382105298\n",
      "Epoch 94, Loss: 1.2058200852932361\n",
      "Epoch 95, Loss: 1.2058669607170294\n",
      "Epoch 96, Loss: 1.199363872513559\n",
      "Epoch 97, Loss: 1.2026347893462528\n",
      "Epoch 98, Loss: 1.2020413288606693\n",
      "Epoch 99, Loss: 1.203767089779539\n",
      "Epoch 100, Loss: 1.1997930887711412\n",
      "Epoch 101, Loss: 1.1995803937141454\n",
      "Epoch 102, Loss: 1.198864191072607\n",
      "Epoch 103, Loss: 1.2021510028029494\n",
      "Epoch 104, Loss: 1.1971123206671284\n",
      "Epoch 105, Loss: 1.195626336531561\n",
      "Epoch 106, Loss: 1.194244069642708\n",
      "Epoch 107, Loss: 1.1983973292472492\n",
      "Epoch 108, Loss: 1.1983232732679023\n",
      "Epoch 109, Loss: 1.1974276892614029\n",
      "Epoch 110, Loss: 1.1918408067360415\n",
      "Epoch 111, Loss: 1.194536984246006\n",
      "Epoch 112, Loss: 1.191708984573217\n",
      "Epoch 113, Loss: 1.1928465457794537\n",
      "Epoch 114, Loss: 1.1916593640554147\n",
      "Epoch 115, Loss: 1.1919668568101922\n",
      "Epoch 116, Loss: 1.1908200495555752\n",
      "Epoch 117, Loss: 1.1882946383757669\n",
      "Epoch 118, Loss: 1.190932456308003\n",
      "Epoch 119, Loss: 1.1884858222979293\n",
      "Epoch 120, Loss: 1.1886467572816362\n",
      "Epoch 121, Loss: 1.1863322882657867\n",
      "Epoch 122, Loss: 1.1890420688957464\n",
      "Epoch 123, Loss: 1.1870002594429658\n",
      "Epoch 124, Loss: 1.186804855176939\n",
      "Epoch 125, Loss: 1.188755317440636\n",
      "Epoch 126, Loss: 1.1839158358423156\n",
      "Epoch 127, Loss: 1.1828269134221088\n",
      "Epoch 128, Loss: 1.1819892387479474\n",
      "Epoch 129, Loss: 1.1843169599562116\n",
      "Epoch 130, Loss: 1.181224738546501\n",
      "Epoch 131, Loss: 1.1819709970046541\n",
      "Epoch 132, Loss: 1.1824961126688214\n",
      "Epoch 133, Loss: 1.1833058595657349\n",
      "Epoch 134, Loss: 1.1844404248359333\n",
      "Epoch 135, Loss: 1.1785651601728846\n",
      "Epoch 136, Loss: 1.1788807449212397\n",
      "Epoch 137, Loss: 1.1795145281583979\n",
      "Epoch 138, Loss: 1.1769905501422615\n",
      "Epoch 139, Loss: 1.177810728410368\n",
      "Epoch 140, Loss: 1.1795355179968707\n",
      "Epoch 141, Loss: 1.1793984070036394\n",
      "Epoch 142, Loss: 1.1748701835823283\n",
      "Epoch 143, Loss: 1.1761234644844045\n",
      "Epoch 144, Loss: 1.1773323349009075\n",
      "Epoch 145, Loss: 1.1770721577648815\n",
      "Epoch 146, Loss: 1.1769177583537\n",
      "Epoch 147, Loss: 1.1764810761606945\n",
      "Epoch 148, Loss: 1.1804311507898415\n",
      "Epoch 149, Loss: 1.17549494250876\n",
      "Epoch 150, Loss: 1.1716790879079833\n",
      "Epoch 151, Loss: 1.1720039162619051\n",
      "Epoch 152, Loss: 1.17614154800319\n",
      "Epoch 153, Loss: 1.1730540483422245\n",
      "Epoch 154, Loss: 1.1750044990898016\n",
      "Epoch 155, Loss: 1.172540500306413\n",
      "Epoch 156, Loss: 1.171026013215755\n",
      "Epoch 157, Loss: 1.169173094162617\n",
      "Epoch 158, Loss: 1.1693016068019688\n",
      "Epoch 159, Loss: 1.1688008276305097\n",
      "Epoch 160, Loss: 1.1715297731080156\n",
      "Epoch 161, Loss: 1.1689457180070095\n",
      "Epoch 162, Loss: 1.1668890153496272\n",
      "Epoch 163, Loss: 1.1700582239750676\n",
      "Epoch 164, Loss: 1.1674730093054806\n",
      "Epoch 165, Loss: 1.1664145403221005\n",
      "Epoch 166, Loss: 1.1656621815309591\n",
      "Epoch 167, Loss: 1.1685174734307675\n",
      "Epoch 168, Loss: 1.1680838002951976\n",
      "Epoch 169, Loss: 1.1663667852761315\n",
      "Epoch 170, Loss: 1.1658707688228866\n",
      "Epoch 171, Loss: 1.1694194374374818\n",
      "Epoch 172, Loss: 1.1671729446574173\n",
      "Epoch 173, Loss: 1.1664170865013113\n",
      "Epoch 174, Loss: 1.1642119233306734\n",
      "Epoch 175, Loss: 1.169406644633559\n",
      "Epoch 176, Loss: 1.1689204645519793\n",
      "Epoch 177, Loss: 1.1602477750956872\n",
      "Epoch 178, Loss: 1.162859913685841\n",
      "Epoch 179, Loss: 1.161079698270601\n",
      "Epoch 180, Loss: 1.1654437074756177\n",
      "Epoch 181, Loss: 1.165246721592664\n",
      "Epoch 182, Loss: 1.1633680952795775\n",
      "Epoch 183, Loss: 1.1619426608783578\n",
      "Epoch 184, Loss: 1.1590576192115454\n",
      "Epoch 185, Loss: 1.1606087158379566\n",
      "Epoch 186, Loss: 1.160223463729059\n",
      "Epoch 187, Loss: 1.1597336946661634\n",
      "Epoch 188, Loss: 1.1604488161883253\n",
      "Epoch 189, Loss: 1.1597148681133636\n",
      "Epoch 190, Loss: 1.158818921802753\n",
      "Epoch 191, Loss: 1.160061932559315\n",
      "Epoch 192, Loss: 1.1599141994460684\n",
      "Epoch 193, Loss: 1.1571009316126133\n",
      "Epoch 194, Loss: 1.1578776157293162\n",
      "Epoch 195, Loss: 1.1565548046132161\n",
      "Epoch 196, Loss: 1.1561883787081448\n",
      "Epoch 197, Loss: 1.161462490326906\n",
      "Epoch 198, Loss: 1.1563878205956006\n",
      "Epoch 199, Loss: 1.155800849827447\n",
      "Epoch 200, Loss: 1.1552002875252128\n",
      "Epoch 201, Loss: 1.1613572920373787\n",
      "Epoch 202, Loss: 1.1529708870400868\n",
      "Epoch 203, Loss: 1.1594963886140381\n",
      "Epoch 204, Loss: 1.1561708220692932\n",
      "Epoch 205, Loss: 1.1547811060655313\n",
      "Epoch 206, Loss: 1.1534584503123575\n",
      "Epoch 207, Loss: 1.1553578665719937\n",
      "Epoch 208, Loss: 1.1518997691693853\n",
      "Epoch 209, Loss: 1.156635582237668\n",
      "Epoch 210, Loss: 1.156118283855273\n",
      "Epoch 211, Loss: 1.1525278984104443\n",
      "Epoch 212, Loss: 1.15306575655658\n",
      "Epoch 213, Loss: 1.1538174438532398\n",
      "Epoch 214, Loss: 1.1537306721232814\n",
      "Epoch 215, Loss: 1.1530350564654035\n",
      "Epoch 216, Loss: 1.1531766172175664\n",
      "Epoch 217, Loss: 1.1538777276699101\n",
      "Epoch 218, Loss: 1.155356535587713\n",
      "Epoch 219, Loss: 1.1523092749945174\n",
      "Epoch 220, Loss: 1.1543388681473163\n",
      "Epoch 221, Loss: 1.1498270038977718\n",
      "Epoch 222, Loss: 1.150649843366699\n",
      "Epoch 223, Loss: 1.152531024722919\n",
      "Epoch 224, Loss: 1.1535408304223411\n",
      "Epoch 225, Loss: 1.1522039851343884\n",
      "Epoch 226, Loss: 1.1498660345406946\n",
      "Epoch 227, Loss: 1.1513127531044935\n",
      "Epoch 228, Loss: 1.1471444230866934\n",
      "Epoch 229, Loss: 1.1501739875912946\n",
      "Epoch 230, Loss: 1.1475771225168778\n",
      "Epoch 231, Loss: 1.150245656104501\n",
      "Epoch 232, Loss: 1.147660888399955\n",
      "Epoch 233, Loss: 1.1473959179058566\n",
      "Epoch 234, Loss: 1.1471326324643798\n",
      "Epoch 235, Loss: 1.147577801409594\n",
      "Epoch 236, Loss: 1.150151043362584\n",
      "Epoch 237, Loss: 1.1469039022922516\n",
      "Epoch 238, Loss: 1.1489915704001308\n",
      "Epoch 239, Loss: 1.1459277154969387\n",
      "Epoch 240, Loss: 1.147183368929097\n",
      "Epoch 241, Loss: 1.1468945888920188\n",
      "Epoch 242, Loss: 1.1493227078428871\n",
      "Epoch 243, Loss: 1.1490318378743298\n",
      "Epoch 244, Loss: 1.1450191416561744\n",
      "Epoch 245, Loss: 1.145125981795425\n",
      "Epoch 246, Loss: 1.1477819381050538\n",
      "Epoch 247, Loss: 1.1460979171882468\n",
      "Epoch 248, Loss: 1.141765907720883\n",
      "Epoch 249, Loss: 1.1458273998328619\n",
      "Epoch 250, Loss: 1.1447642055412086\n",
      "Epoch 251, Loss: 1.1458492930236968\n",
      "Epoch 252, Loss: 1.141597890602621\n",
      "Epoch 253, Loss: 1.1435231193027675\n",
      "Epoch 254, Loss: 1.1429023582845996\n",
      "Epoch 255, Loss: 1.14383322740327\n",
      "Epoch 256, Loss: 1.1418982928474837\n",
      "Epoch 257, Loss: 1.1407236733955857\n",
      "Epoch 258, Loss: 1.1423265617122695\n",
      "Epoch 259, Loss: 1.140365017242119\n",
      "Epoch 260, Loss: 1.1441427770766497\n",
      "Epoch 261, Loss: 1.1422842510690174\n",
      "Epoch 262, Loss: 1.1454472074882767\n",
      "Epoch 263, Loss: 1.1439291004274712\n",
      "Epoch 264, Loss: 1.1432331303522794\n",
      "Epoch 265, Loss: 1.1442357381975903\n",
      "Epoch 266, Loss: 1.138825328274689\n",
      "Epoch 267, Loss: 1.141477098998197\n",
      "Epoch 268, Loss: 1.1422233643660222\n",
      "Epoch 269, Loss: 1.1409091432284415\n",
      "Epoch 270, Loss: 1.1389562220288663\n",
      "Epoch 271, Loss: 1.139560396135272\n",
      "Epoch 272, Loss: 1.1389003882503064\n",
      "Epoch 273, Loss: 1.1419262072241558\n",
      "Epoch 274, Loss: 1.140181084427398\n",
      "Epoch 275, Loss: 1.1435272531012461\n",
      "Epoch 276, Loss: 1.140283140002704\n",
      "Epoch 277, Loss: 1.1421658761049043\n",
      "Epoch 278, Loss: 1.140536796502263\n",
      "Epoch 279, Loss: 1.1419022555094414\n",
      "Epoch 280, Loss: 1.1446496678878328\n",
      "Epoch 281, Loss: 1.142503334501588\n",
      "Epoch 282, Loss: 1.1370595528872844\n",
      "Epoch 283, Loss: 1.1372699080781021\n",
      "Epoch 284, Loss: 1.1412659707616588\n",
      "Epoch 285, Loss: 1.140742516559516\n",
      "Epoch 286, Loss: 1.1356804188018101\n",
      "Epoch 287, Loss: 1.1397922976374346\n",
      "Epoch 288, Loss: 1.1432220503094603\n",
      "Epoch 289, Loss: 1.1366067140666327\n",
      "Epoch 290, Loss: 1.1382368740907038\n",
      "Epoch 291, Loss: 1.1364472223668243\n",
      "Epoch 292, Loss: 1.1329870085805585\n",
      "Epoch 293, Loss: 1.1347525709546422\n",
      "Epoch 294, Loss: 1.137578194677411\n",
      "Epoch 295, Loss: 1.1382829329866995\n",
      "Epoch 296, Loss: 1.1346910966503536\n",
      "Epoch 297, Loss: 1.1342491847430236\n",
      "Epoch 298, Loss: 1.141444484160153\n",
      "Epoch 299, Loss: 1.1359190797777867\n",
      "Epoch 300, Loss: 1.136821093548098\n",
      "Epoch 301, Loss: 1.1333969771443262\n",
      "Epoch 302, Loss: 1.1356187672888647\n",
      "Epoch 303, Loss: 1.1364859969331174\n",
      "Epoch 304, Loss: 1.1341348730149816\n",
      "Epoch 305, Loss: 1.133559336288193\n",
      "Epoch 306, Loss: 1.139142810321245\n",
      "Epoch 307, Loss: 1.1351622277456368\n",
      "Epoch 308, Loss: 1.135881293224786\n",
      "Epoch 309, Loss: 1.1354421641005845\n",
      "Epoch 310, Loss: 1.1367589501223463\n",
      "Epoch 311, Loss: 1.133271907057081\n",
      "Epoch 312, Loss: 1.13257834001224\n",
      "Epoch 313, Loss: 1.1332342124934498\n",
      "Epoch 314, Loss: 1.1345417934363005\n",
      "Epoch 315, Loss: 1.1364142223320186\n",
      "Epoch 316, Loss: 1.1346635576991901\n",
      "Epoch 317, Loss: 1.1315029798123541\n",
      "Epoch 318, Loss: 1.1340370537665185\n",
      "Epoch 319, Loss: 1.1308923930418295\n",
      "Epoch 320, Loss: 1.132728934497409\n",
      "Epoch 321, Loss: 1.132668137550354\n",
      "Epoch 322, Loss: 1.1363618614662447\n",
      "Epoch 323, Loss: 1.1324655557404637\n",
      "Epoch 324, Loss: 1.1339020412895104\n",
      "Epoch 325, Loss: 1.1347360381337463\n",
      "Epoch 326, Loss: 1.1313942204593774\n",
      "Epoch 327, Loss: 1.1320882427050303\n",
      "Epoch 328, Loss: 1.1304594818546285\n",
      "Epoch 329, Loss: 1.1328543973192398\n",
      "Epoch 330, Loss: 1.134517233600661\n",
      "Epoch 331, Loss: 1.132087963526366\n",
      "Epoch 332, Loss: 1.1287749456438025\n",
      "Epoch 333, Loss: 1.1276852540165814\n",
      "Epoch 334, Loss: 1.1287037994738764\n",
      "Epoch 335, Loss: 1.1335987663659892\n",
      "Epoch 336, Loss: 1.1314387999178375\n",
      "Epoch 337, Loss: 1.130343218877109\n",
      "Epoch 338, Loss: 1.1317746451504058\n",
      "Epoch 339, Loss: 1.1311965235083667\n",
      "Epoch 340, Loss: 1.1302019967686656\n",
      "Epoch 341, Loss: 1.1306729436758252\n",
      "Epoch 342, Loss: 1.1316850503657965\n",
      "Epoch 343, Loss: 1.1318264041069799\n",
      "Epoch 344, Loss: 1.1274146059357868\n",
      "Epoch 345, Loss: 1.1291558198124798\n",
      "Epoch 346, Loss: 1.1304469368915646\n",
      "Epoch 347, Loss: 1.1274579771787836\n",
      "Epoch 348, Loss: 1.1344260303281788\n",
      "Epoch 349, Loss: 1.1313563063915217\n",
      "Epoch 350, Loss: 1.1283855630167754\n",
      "Epoch 351, Loss: 1.1289417098780148\n",
      "Epoch 352, Loss: 1.1305548655484263\n",
      "Epoch 353, Loss: 1.131591122518937\n",
      "Epoch 354, Loss: 1.1257968829024312\n",
      "Epoch 355, Loss: 1.1258476095958951\n",
      "Epoch 356, Loss: 1.1294109200845\n",
      "Epoch 357, Loss: 1.1282574306885587\n",
      "Epoch 358, Loss: 1.1249884829727772\n",
      "Epoch 359, Loss: 1.1292167110521285\n",
      "Epoch 360, Loss: 1.1288068140278935\n",
      "Epoch 361, Loss: 1.1270702602712555\n",
      "Epoch 362, Loss: 1.1296615571272177\n",
      "Epoch 363, Loss: 1.1310046524577175\n",
      "Epoch 364, Loss: 1.1279318080713374\n",
      "Epoch 365, Loss: 1.130084474067219\n",
      "Epoch 366, Loss: 1.129315913630872\n",
      "Epoch 367, Loss: 1.1265607295466251\n",
      "Epoch 368, Loss: 1.1243238856697528\n",
      "Epoch 369, Loss: 1.1250931989811623\n",
      "Epoch 370, Loss: 1.1284290994637465\n",
      "Epoch 371, Loss: 1.1247131788200182\n",
      "Epoch 372, Loss: 1.1292546400560428\n",
      "Epoch 373, Loss: 1.1269844672021039\n",
      "Epoch 374, Loss: 1.1276432008458523\n",
      "Epoch 375, Loss: 1.1275103469782746\n",
      "Epoch 376, Loss: 1.1289086124098553\n",
      "Epoch 377, Loss: 1.1271700305598122\n",
      "Epoch 378, Loss: 1.1284224441235742\n",
      "Epoch 379, Loss: 1.1253284270366963\n",
      "Epoch 380, Loss: 1.124046346970967\n",
      "Epoch 381, Loss: 1.1253099482707174\n",
      "Epoch 382, Loss: 1.121652600218038\n",
      "Epoch 383, Loss: 1.1274380796966286\n",
      "Epoch 384, Loss: 1.122642631971864\n",
      "Epoch 385, Loss: 1.1221242518419403\n",
      "Epoch 386, Loss: 1.1255746411216343\n",
      "Epoch 387, Loss: 1.1260069109656492\n",
      "Epoch 388, Loss: 1.1287187418139233\n",
      "Epoch 389, Loss: 1.1254496842413373\n",
      "Epoch 390, Loss: 1.128449129136999\n",
      "Epoch 391, Loss: 1.1261537711570078\n",
      "Epoch 392, Loss: 1.1235234717155786\n",
      "Epoch 393, Loss: 1.1230772034345802\n",
      "Epoch 394, Loss: 1.1264688401227814\n",
      "Epoch 395, Loss: 1.1239011389589422\n",
      "Epoch 396, Loss: 1.119328843695777\n",
      "Epoch 397, Loss: 1.1269773621051038\n",
      "Epoch 398, Loss: 1.1291993168952594\n",
      "Epoch 399, Loss: 1.1199497439543034\n",
      "Epoch 400, Loss: 1.1229564001046521\n",
      "Epoch 401, Loss: 1.1253258275343607\n",
      "Epoch 402, Loss: 1.1241647645796211\n",
      "Epoch 403, Loss: 1.1220693674104276\n",
      "Epoch 404, Loss: 1.1237982411714014\n",
      "Epoch 405, Loss: 1.126457693914619\n",
      "Epoch 406, Loss: 1.1186119961515244\n",
      "Epoch 407, Loss: 1.1237266852369912\n",
      "Epoch 408, Loss: 1.1198981592052155\n",
      "Epoch 409, Loss: 1.1234192203302853\n",
      "Epoch 410, Loss: 1.122168080519178\n",
      "Epoch 411, Loss: 1.1193765878537778\n",
      "Epoch 412, Loss: 1.1222307915849485\n",
      "Epoch 413, Loss: 1.1217275381925793\n",
      "Epoch 414, Loss: 1.1193734244803355\n",
      "Epoch 415, Loss: 1.1185218314236725\n",
      "Epoch 416, Loss: 1.1242360491523697\n",
      "Epoch 417, Loss: 1.1221530455616096\n",
      "Epoch 418, Loss: 1.121484897036184\n",
      "Epoch 419, Loss: 1.1211689504024853\n",
      "Epoch 420, Loss: 1.12081620271647\n",
      "Epoch 421, Loss: 1.121320046083151\n",
      "Epoch 422, Loss: 1.1233921651259517\n",
      "Epoch 423, Loss: 1.1214308900632122\n",
      "Epoch 424, Loss: 1.1240264134049696\n",
      "Epoch 425, Loss: 1.1200730842505462\n",
      "Epoch 426, Loss: 1.1176894491394453\n",
      "Epoch 427, Loss: 1.1230530410795636\n",
      "Epoch 428, Loss: 1.1172142743505973\n",
      "Epoch 429, Loss: 1.119212830024804\n",
      "Epoch 430, Loss: 1.1168040692527066\n",
      "Epoch 431, Loss: 1.1197311478978855\n",
      "Epoch 432, Loss: 1.1232028997893635\n",
      "Epoch 433, Loss: 1.1184616731676063\n",
      "Epoch 434, Loss: 1.117921239249321\n",
      "Epoch 435, Loss: 1.1207225798025064\n",
      "Epoch 436, Loss: 1.1188159707837697\n",
      "Epoch 437, Loss: 1.1201061079457437\n",
      "Epoch 438, Loss: 1.120924262587304\n",
      "Epoch 439, Loss: 1.1191132436451923\n",
      "Epoch 440, Loss: 1.1168900608876828\n",
      "Epoch 441, Loss: 1.1176169222216417\n",
      "Epoch 442, Loss: 1.1202345616783973\n",
      "Epoch 443, Loss: 1.1225231076989854\n",
      "Epoch 444, Loss: 1.1197354980598289\n",
      "Epoch 445, Loss: 1.1202346090689754\n",
      "Epoch 446, Loss: 1.1185379351469615\n",
      "Epoch 447, Loss: 1.1211092487431242\n",
      "Epoch 448, Loss: 1.1195768954044762\n",
      "Epoch 449, Loss: 1.1195853464916103\n",
      "Epoch 450, Loss: 1.1228809323188014\n",
      "Epoch 451, Loss: 1.1229348029129957\n",
      "Epoch 452, Loss: 1.116228172455236\n",
      "Epoch 453, Loss: 1.1187003698784517\n",
      "Epoch 454, Loss: 1.1186669156897542\n",
      "Epoch 455, Loss: 1.118357519076077\n",
      "Epoch 456, Loss: 1.1222639847415952\n",
      "Epoch 457, Loss: 1.1177003863823778\n",
      "Epoch 458, Loss: 1.117296021213576\n",
      "Epoch 459, Loss: 1.1174764124375596\n",
      "Epoch 460, Loss: 1.1177730455610735\n",
      "Epoch 461, Loss: 1.1202561698278164\n",
      "Epoch 462, Loss: 1.1213719529346224\n",
      "Epoch 463, Loss: 1.1186743015706957\n",
      "Epoch 464, Loss: 1.1176654504529207\n",
      "Epoch 465, Loss: 1.1209276427429788\n",
      "Epoch 466, Loss: 1.1197150676953989\n",
      "Epoch 467, Loss: 1.1208722952936516\n",
      "Epoch 468, Loss: 1.1159285440936302\n",
      "Epoch 469, Loss: 1.1143607354136205\n",
      "Epoch 470, Loss: 1.1200092754542688\n",
      "Epoch 471, Loss: 1.1203535534877689\n",
      "Epoch 472, Loss: 1.1169318367642038\n",
      "Epoch 473, Loss: 1.1193942212667622\n",
      "Epoch 474, Loss: 1.1190851374029833\n",
      "Epoch 475, Loss: 1.118631652562903\n",
      "Epoch 476, Loss: 1.114308286118005\n",
      "Epoch 477, Loss: 1.1167137231285176\n",
      "Epoch 478, Loss: 1.1182675707116898\n",
      "Epoch 479, Loss: 1.1146502470383879\n",
      "Epoch 480, Loss: 1.1112496673502463\n",
      "Epoch 481, Loss: 1.1121021495909547\n",
      "Epoch 482, Loss: 1.1179040875591215\n",
      "Epoch 483, Loss: 1.1160784016867153\n",
      "Epoch 484, Loss: 1.111360088235042\n",
      "Epoch 485, Loss: 1.1187870243533713\n",
      "Epoch 486, Loss: 1.11727439575508\n",
      "Epoch 487, Loss: 1.1174163709479696\n",
      "Epoch 488, Loss: 1.1166749105241316\n",
      "Epoch 489, Loss: 1.1178350078696668\n",
      "Epoch 490, Loss: 1.1140734574973443\n",
      "Epoch 491, Loss: 1.1113944921895547\n",
      "Epoch 492, Loss: 1.1183271766127691\n",
      "Epoch 493, Loss: 1.1153091105700097\n",
      "Epoch 494, Loss: 1.1189757048804532\n",
      "Epoch 495, Loss: 1.1164231164254406\n",
      "Epoch 496, Loss: 1.116718431476687\n",
      "Epoch 497, Loss: 1.1121439985424908\n",
      "Epoch 498, Loss: 1.1122107539997725\n",
      "Epoch 499, Loss: 1.1170336209080538\n",
      "Epoch 500, Loss: 1.1116451652463202\n",
      "Epoch 501, Loss: 1.1158859391960663\n",
      "Epoch 502, Loss: 1.112660251191405\n",
      "Epoch 503, Loss: 1.1190621137479428\n",
      "Epoch 504, Loss: 1.1134889407794426\n",
      "Epoch 505, Loss: 1.1130110613774917\n",
      "Epoch 506, Loss: 1.1170764402148317\n",
      "Epoch 507, Loss: 1.1130982920073793\n",
      "Epoch 508, Loss: 1.1166389270465324\n",
      "Epoch 509, Loss: 1.118129696653375\n",
      "Epoch 510, Loss: 1.1154075532244296\n",
      "Epoch 511, Loss: 1.1150042754565246\n",
      "Epoch 512, Loss: 1.1143785483384858\n",
      "Epoch 513, Loss: 1.1111457080556302\n",
      "Epoch 514, Loss: 1.1144947741154485\n",
      "Epoch 515, Loss: 1.1167173789731233\n",
      "Epoch 516, Loss: 1.1147321995862474\n",
      "Epoch 517, Loss: 1.1135727748519084\n",
      "Epoch 518, Loss: 1.1171201455648945\n",
      "Epoch 519, Loss: 1.1119305093617853\n",
      "Epoch 520, Loss: 1.1119927768126583\n",
      "Epoch 521, Loss: 1.1182293857009404\n",
      "Epoch 522, Loss: 1.1113295663296479\n",
      "Epoch 523, Loss: 1.112456827378664\n",
      "Epoch 524, Loss: 1.110117038672646\n",
      "Epoch 525, Loss: 1.1172241220289985\n",
      "Epoch 526, Loss: 1.1147233655357807\n",
      "Epoch 527, Loss: 1.1095950056294925\n",
      "Epoch 528, Loss: 1.1132745344968256\n",
      "Epoch 529, Loss: 1.1111885227559601\n",
      "Epoch 530, Loss: 1.1131867298756049\n",
      "Epoch 531, Loss: 1.1154064362305947\n",
      "Epoch 532, Loss: 1.117441720091487\n",
      "Epoch 533, Loss: 1.1143876305089901\n",
      "Epoch 534, Loss: 1.1141019351169712\n",
      "Epoch 535, Loss: 1.113189422902793\n",
      "Epoch 536, Loss: 1.1125556316392484\n",
      "Epoch 537, Loss: 1.1121289201028453\n",
      "Epoch 538, Loss: 1.1086138322844719\n",
      "Epoch 539, Loss: 1.112753276802617\n",
      "Epoch 540, Loss: 1.1084428213938058\n",
      "Epoch 541, Loss: 1.1109720578098743\n",
      "Epoch 542, Loss: 1.107941079474724\n",
      "Epoch 543, Loss: 1.1102524600766024\n",
      "Epoch 544, Loss: 1.1153757093731638\n",
      "Epoch 545, Loss: 1.1061095052357302\n",
      "Epoch 546, Loss: 1.1105869165349063\n",
      "Epoch 547, Loss: 1.106015739242701\n",
      "Epoch 548, Loss: 1.111434351504547\n",
      "Epoch 549, Loss: 1.1106794787095358\n",
      "Epoch 550, Loss: 1.1117552745677268\n",
      "Epoch 551, Loss: 1.1123349875979458\n",
      "Epoch 552, Loss: 1.1109603894678155\n",
      "Epoch 553, Loss: 1.1096737398755077\n",
      "Epoch 554, Loss: 1.1083064411507277\n",
      "Epoch 555, Loss: 1.1086956550840472\n",
      "Epoch 556, Loss: 1.1102641158556212\n",
      "Epoch 557, Loss: 1.1088122949527632\n",
      "Epoch 558, Loss: 1.1109156595320557\n",
      "Epoch 559, Loss: 1.1113617850829622\n",
      "Epoch 560, Loss: 1.104760466121678\n",
      "Epoch 561, Loss: 1.1095047676172414\n",
      "Epoch 562, Loss: 1.1095382554469677\n",
      "Epoch 563, Loss: 1.1125130941633319\n",
      "Epoch 564, Loss: 1.1107104490456592\n",
      "Epoch 565, Loss: 1.1092677722211743\n",
      "Epoch 566, Loss: 1.1089764331626668\n",
      "Epoch 567, Loss: 1.1085836732415462\n",
      "Epoch 568, Loss: 1.111159849152911\n",
      "Epoch 569, Loss: 1.11346699273\n",
      "Epoch 570, Loss: 1.1072724278693455\n",
      "Epoch 571, Loss: 1.1050001749947702\n",
      "Epoch 572, Loss: 1.1127772215378648\n",
      "Epoch 573, Loss: 1.1107510414140287\n",
      "Epoch 574, Loss: 1.1092583163002336\n",
      "Epoch 575, Loss: 1.10807389293119\n",
      "Epoch 576, Loss: 1.1091819457203778\n",
      "Epoch 577, Loss: 1.1088243692903943\n",
      "Epoch 578, Loss: 1.1107403183011317\n",
      "Epoch 579, Loss: 1.1075222976593\n",
      "Epoch 580, Loss: 1.1094859393893695\n",
      "Epoch 581, Loss: 1.1055045743457605\n",
      "Epoch 582, Loss: 1.1089102146357508\n",
      "Epoch 583, Loss: 1.1089987673162018\n",
      "Epoch 584, Loss: 1.110546360320174\n",
      "Epoch 585, Loss: 1.1128234796278371\n",
      "Epoch 586, Loss: 1.1176768893799123\n",
      "Epoch 587, Loss: 1.1093838408205492\n",
      "Epoch 588, Loss: 1.1128616626843357\n",
      "Epoch 589, Loss: 1.1108724160830925\n",
      "Epoch 590, Loss: 1.1066741255183967\n",
      "Epoch 591, Loss: 1.1050465436394934\n",
      "Epoch 592, Loss: 1.113653219834982\n",
      "Epoch 593, Loss: 1.104727755804531\n",
      "Epoch 594, Loss: 1.1092783243371396\n",
      "Epoch 595, Loss: 1.1081501842940997\n",
      "Epoch 596, Loss: 1.1063319011929442\n",
      "Epoch 597, Loss: 1.1051528823738634\n",
      "Epoch 598, Loss: 1.1079656611560937\n",
      "Epoch 599, Loss: 1.1089119314449454\n",
      "Epoch 600, Loss: 1.1066114441851542\n",
      "Epoch 601, Loss: 1.107669431096776\n",
      "Epoch 602, Loss: 1.109247305354134\n",
      "Epoch 603, Loss: 1.1040155144290567\n",
      "Epoch 604, Loss: 1.1090219605722806\n",
      "Epoch 605, Loss: 1.1096300826837642\n",
      "Epoch 606, Loss: 1.1069281388780832\n",
      "Epoch 607, Loss: 1.105761246672838\n",
      "Epoch 608, Loss: 1.1063837307119258\n",
      "Epoch 609, Loss: 1.1112659036136063\n",
      "Epoch 610, Loss: 1.1078399409315347\n",
      "Epoch 611, Loss: 1.1054645926109243\n",
      "Epoch 612, Loss: 1.108468471282539\n",
      "Epoch 613, Loss: 1.1068387550129544\n",
      "Epoch 614, Loss: 1.1074466547586321\n",
      "Epoch 615, Loss: 1.1095802025298045\n",
      "Epoch 616, Loss: 1.1041928194027035\n",
      "Epoch 617, Loss: 1.1105694930642773\n",
      "Epoch 618, Loss: 1.107783274293225\n",
      "Epoch 619, Loss: 1.1099877512427068\n",
      "Epoch 620, Loss: 1.1084953482312956\n",
      "Epoch 621, Loss: 1.1130855752098476\n",
      "Epoch 622, Loss: 1.110419645521624\n",
      "Epoch 623, Loss: 1.1068253619749038\n",
      "Epoch 624, Loss: 1.1057778694590583\n",
      "Epoch 625, Loss: 1.1099148276120214\n",
      "Epoch 626, Loss: 1.109100631863507\n",
      "Epoch 627, Loss: 1.1043848843429351\n",
      "Epoch 628, Loss: 1.1052768309306205\n",
      "Epoch 629, Loss: 1.1042069027100012\n",
      "Epoch 630, Loss: 1.1082684537984728\n",
      "Epoch 631, Loss: 1.1047542215929098\n",
      "Epoch 632, Loss: 1.1055766717471898\n",
      "Epoch 633, Loss: 1.1049726215961109\n",
      "Epoch 634, Loss: 1.1064661396471063\n",
      "Epoch 635, Loss: 1.1033605644239475\n",
      "Epoch 636, Loss: 1.1061293902246399\n",
      "Epoch 637, Loss: 1.107372206812441\n",
      "Epoch 638, Loss: 1.1019345857639224\n",
      "Epoch 639, Loss: 1.102818069887943\n",
      "Epoch 640, Loss: 1.105915147331336\n",
      "Epoch 641, Loss: 1.1032021511913184\n",
      "Epoch 642, Loss: 1.1097448977709374\n",
      "Epoch 643, Loss: 1.1089640293942122\n",
      "Epoch 644, Loss: 1.1065192880758916\n",
      "Epoch 645, Loss: 1.1063322910659485\n",
      "Epoch 646, Loss: 1.10479252343993\n",
      "Epoch 647, Loss: 1.103029460482631\n",
      "Epoch 648, Loss: 1.108006724778048\n",
      "Epoch 649, Loss: 1.1058656703113672\n",
      "Epoch 650, Loss: 1.1039120402771638\n",
      "Epoch 651, Loss: 1.1058554211042524\n",
      "Epoch 652, Loss: 1.105130060146229\n",
      "Epoch 653, Loss: 1.1056104700933853\n",
      "Epoch 654, Loss: 1.106155343161813\n",
      "Epoch 655, Loss: 1.1080205541723507\n",
      "Epoch 656, Loss: 1.1037002061373735\n",
      "Epoch 657, Loss: 1.1069627777614415\n",
      "Epoch 658, Loss: 1.1028456198666636\n",
      "Epoch 659, Loss: 1.1053234694713172\n",
      "Epoch 660, Loss: 1.1019989757403836\n",
      "Epoch 661, Loss: 1.106331631227176\n",
      "Epoch 662, Loss: 1.100748156216999\n",
      "Epoch 663, Loss: 1.1033781093372952\n",
      "Epoch 664, Loss: 1.1039648611595816\n",
      "Epoch 665, Loss: 1.1069983403772046\n",
      "Epoch 666, Loss: 1.10327917253664\n",
      "Epoch 667, Loss: 1.1041008788193696\n",
      "Epoch 668, Loss: 1.106963629256367\n",
      "Epoch 669, Loss: 1.1030637048167422\n",
      "Epoch 670, Loss: 1.103429204058033\n",
      "Epoch 671, Loss: 1.1010161377925785\n",
      "Epoch 672, Loss: 1.105601572459978\n",
      "Epoch 673, Loss: 1.1062069029244104\n",
      "Epoch 674, Loss: 1.107964682704671\n",
      "Epoch 675, Loss: 1.1017803803819124\n",
      "Epoch 676, Loss: 1.106733430744055\n",
      "Epoch 677, Loss: 1.10157410538727\n",
      "Epoch 678, Loss: 1.1074153799781754\n",
      "Epoch 679, Loss: 1.1011835329705715\n",
      "Epoch 680, Loss: 1.1032940712550205\n",
      "Epoch 681, Loss: 1.1030609611884212\n",
      "Epoch 682, Loss: 1.1043788578527036\n",
      "Epoch 683, Loss: 1.1087335743167082\n",
      "Epoch 684, Loss: 1.1047721694308645\n",
      "Epoch 685, Loss: 1.1016132188066665\n",
      "Epoch 686, Loss: 1.1050686097117162\n",
      "Epoch 687, Loss: 1.1053463373446633\n",
      "Epoch 688, Loss: 1.104151594973839\n",
      "Epoch 689, Loss: 1.1024401481034325\n",
      "Epoch 690, Loss: 1.1055702882572416\n",
      "Epoch 691, Loss: 1.106729317116235\n",
      "Epoch 692, Loss: 1.106669060379895\n",
      "Epoch 693, Loss: 1.1018694165300151\n",
      "Epoch 694, Loss: 1.100191699746621\n",
      "Epoch 695, Loss: 1.1027436458115276\n",
      "Epoch 696, Loss: 1.100372430870628\n",
      "Epoch 697, Loss: 1.1030621063095065\n",
      "Epoch 698, Loss: 1.1036052732473236\n",
      "Epoch 699, Loss: 1.105354582467738\n",
      "Epoch 700, Loss: 1.1036001948478351\n",
      "Epoch 701, Loss: 1.103732991623376\n",
      "Epoch 702, Loss: 1.1022555933484428\n",
      "Epoch 703, Loss: 1.1043554779656877\n",
      "Epoch 704, Loss: 1.1009406390178957\n",
      "Epoch 705, Loss: 1.1030743892633943\n",
      "Epoch 706, Loss: 1.1076479354563586\n",
      "Epoch 707, Loss: 1.104366383452047\n",
      "Epoch 708, Loss: 1.1020515004142386\n",
      "Epoch 709, Loss: 1.105722755263505\n",
      "Epoch 710, Loss: 1.1037888284729014\n",
      "Epoch 711, Loss: 1.1023517001847751\n",
      "Epoch 712, Loss: 1.101670653256097\n",
      "Epoch 713, Loss: 1.1075625533382005\n",
      "Epoch 714, Loss: 1.1028791366611768\n",
      "Epoch 715, Loss: 1.10062958910817\n",
      "Epoch 716, Loss: 1.1028513215325197\n",
      "Epoch 717, Loss: 1.1009094567851663\n",
      "Epoch 718, Loss: 1.1059519534088689\n",
      "Epoch 719, Loss: 1.1026854847298293\n",
      "Epoch 720, Loss: 1.1004299270883378\n",
      "Epoch 721, Loss: 1.1016458506048143\n",
      "Epoch 722, Loss: 1.102838446370891\n",
      "Epoch 723, Loss: 1.1006351534181233\n",
      "Epoch 724, Loss: 1.1042934030085034\n",
      "Epoch 725, Loss: 1.1033030826537336\n",
      "Epoch 726, Loss: 1.1027981484662175\n",
      "Epoch 727, Loss: 1.101479310830248\n",
      "Epoch 728, Loss: 1.102574110240512\n",
      "Epoch 729, Loss: 1.1055599043813187\n",
      "Epoch 730, Loss: 1.1015594664446364\n",
      "Epoch 731, Loss: 1.101477431748455\n",
      "Epoch 732, Loss: 1.0984680394378143\n",
      "Epoch 733, Loss: 1.099573986870902\n",
      "Epoch 734, Loss: 1.1016591382529195\n",
      "Epoch 735, Loss: 1.105684917551014\n",
      "Epoch 736, Loss: 1.1050709862898886\n",
      "Epoch 737, Loss: 1.1001497802326774\n",
      "Epoch 738, Loss: 1.1032136578889307\n",
      "Epoch 739, Loss: 1.0978158073765891\n",
      "Epoch 740, Loss: 1.1010710812703788\n",
      "Epoch 741, Loss: 1.1041408232140597\n",
      "Epoch 742, Loss: 1.0988060834815407\n",
      "Epoch 743, Loss: 1.10234839631467\n",
      "Epoch 744, Loss: 1.105441728366901\n",
      "Epoch 745, Loss: 1.103332563641479\n",
      "Epoch 746, Loss: 1.0952994128300937\n",
      "Epoch 747, Loss: 1.0964189228324757\n",
      "Epoch 748, Loss: 1.10433479215278\n",
      "Epoch 749, Loss: 1.103869378776126\n",
      "Epoch 750, Loss: 1.1008165258155216\n",
      "Epoch 751, Loss: 1.099611689600509\n",
      "Epoch 752, Loss: 1.1054916944380946\n",
      "Epoch 753, Loss: 1.0995080313302874\n",
      "Epoch 754, Loss: 1.1029958949016463\n",
      "Epoch 755, Loss: 1.1015191196836966\n",
      "Epoch 756, Loss: 1.0999881409509957\n",
      "Epoch 757, Loss: 1.102659304471429\n",
      "Epoch 758, Loss: 1.0985317095520903\n",
      "Epoch 759, Loss: 1.102088172416218\n",
      "Epoch 760, Loss: 1.102805036990369\n",
      "Epoch 761, Loss: 1.1024242211002377\n",
      "Epoch 762, Loss: 1.103169858665042\n",
      "Epoch 763, Loss: 1.0973312801722899\n",
      "Epoch 764, Loss: 1.1012313337320465\n",
      "Epoch 765, Loss: 1.1033925860073304\n",
      "Epoch 766, Loss: 1.1028590224665835\n",
      "Epoch 767, Loss: 1.0989548885012679\n",
      "Epoch 768, Loss: 1.0989304789335443\n",
      "Epoch 769, Loss: 1.100797321813168\n",
      "Epoch 770, Loss: 1.1023939288890892\n",
      "Epoch 771, Loss: 1.0954651385196756\n",
      "Epoch 772, Loss: 1.0986029656486154\n",
      "Epoch 773, Loss: 1.1027457180849563\n",
      "Epoch 774, Loss: 1.1034738444472365\n",
      "Epoch 775, Loss: 1.0981268080112805\n",
      "Epoch 776, Loss: 1.100952415332303\n",
      "Epoch 777, Loss: 1.1006852217385026\n",
      "Epoch 778, Loss: 1.1006236020519247\n",
      "Epoch 779, Loss: 1.0993586505045656\n",
      "Epoch 780, Loss: 1.0970883097246604\n",
      "Epoch 781, Loss: 1.0981378465262732\n",
      "Epoch 782, Loss: 1.0996943979548068\n",
      "Epoch 783, Loss: 1.1029070595527979\n",
      "Epoch 784, Loss: 1.1025890749846465\n",
      "Epoch 785, Loss: 1.099124823925925\n",
      "Epoch 786, Loss: 1.1009974647182492\n",
      "Epoch 787, Loss: 1.0978305797666241\n",
      "Epoch 788, Loss: 1.0974044384526425\n",
      "Epoch 789, Loss: 1.0980742585603191\n",
      "Epoch 790, Loss: 1.099647844284424\n",
      "Epoch 791, Loss: 1.10061465898219\n",
      "Epoch 792, Loss: 1.1014261436964925\n",
      "Epoch 793, Loss: 1.1049982074831353\n",
      "Epoch 794, Loss: 1.1008591062151576\n",
      "Epoch 795, Loss: 1.0994543835904615\n",
      "Epoch 796, Loss: 1.0988878713139885\n",
      "Epoch 797, Loss: 1.0972704191537317\n",
      "Epoch 798, Loss: 1.1019221122705964\n",
      "Epoch 799, Loss: 1.0987289048888365\n",
      "Epoch 800, Loss: 1.0975693806970985\n",
      "Epoch 801, Loss: 1.1021738940156316\n",
      "Epoch 802, Loss: 1.0998261612109335\n",
      "Epoch 803, Loss: 1.0969101274320616\n",
      "Epoch 804, Loss: 1.0997596605739772\n",
      "Epoch 805, Loss: 1.0955829424238317\n",
      "Epoch 806, Loss: 1.099452587145553\n",
      "Epoch 807, Loss: 1.0966046611654117\n",
      "Epoch 808, Loss: 1.0976621704023393\n",
      "Epoch 809, Loss: 1.1021602802170523\n",
      "Epoch 810, Loss: 1.1042158586219546\n",
      "Epoch 811, Loss: 1.09768282424929\n",
      "Epoch 812, Loss: 1.0993581700380848\n",
      "Epoch 813, Loss: 1.0969673887907203\n",
      "Epoch 814, Loss: 1.097492517715874\n",
      "Epoch 815, Loss: 1.097824437417247\n",
      "Epoch 816, Loss: 1.097197222486313\n",
      "Epoch 817, Loss: 1.0982664087896326\n",
      "Epoch 818, Loss: 1.1039202509914685\n",
      "Epoch 819, Loss: 1.0970994818964384\n",
      "Epoch 820, Loss: 1.0988833960102091\n",
      "Epoch 821, Loss: 1.0979805040136155\n",
      "Epoch 822, Loss: 1.0956703050354326\n",
      "Epoch 823, Loss: 1.0969554437826055\n",
      "Epoch 824, Loss: 1.103610772718032\n",
      "Epoch 825, Loss: 1.1036595953432122\n",
      "Epoch 826, Loss: 1.0991873565267345\n",
      "Epoch 827, Loss: 1.103784948517623\n",
      "Epoch 828, Loss: 1.0962956514235682\n",
      "Epoch 829, Loss: 1.099805441477818\n",
      "Epoch 830, Loss: 1.0952580675168675\n",
      "Epoch 831, Loss: 1.1013431505799574\n",
      "Epoch 832, Loss: 1.0991370379226828\n",
      "Epoch 833, Loss: 1.0960008719765888\n",
      "Epoch 834, Loss: 1.0962901231974573\n",
      "Epoch 835, Loss: 1.0983039352877078\n",
      "Epoch 836, Loss: 1.0993579093550072\n",
      "Epoch 837, Loss: 1.101029312443119\n",
      "Epoch 838, Loss: 1.1025503418763851\n",
      "Epoch 839, Loss: 1.0988312440398706\n",
      "Epoch 840, Loss: 1.0969942703459246\n",
      "Epoch 841, Loss: 1.0981209019168479\n",
      "Epoch 842, Loss: 1.1035542797986462\n",
      "Epoch 843, Loss: 1.1021585360483486\n",
      "Epoch 844, Loss: 1.099878000291784\n",
      "Epoch 845, Loss: 1.1022820191444782\n",
      "Epoch 846, Loss: 1.0934328837472884\n",
      "Epoch 847, Loss: 1.101457522540796\n",
      "Epoch 848, Loss: 1.0965703984055084\n",
      "Epoch 849, Loss: 1.097936829512795\n",
      "Epoch 850, Loss: 1.0998500949884187\n",
      "Epoch 851, Loss: 1.1003141499514881\n",
      "Epoch 852, Loss: 1.0980190580287639\n",
      "Epoch 853, Loss: 1.0948098328409486\n",
      "Epoch 854, Loss: 1.098594192179919\n",
      "Epoch 855, Loss: 1.0990562099762766\n",
      "Epoch 856, Loss: 1.0961668213580755\n",
      "Epoch 857, Loss: 1.0970432270466584\n",
      "Epoch 858, Loss: 1.0961600984566664\n",
      "Epoch 859, Loss: 1.0977105043252682\n",
      "Epoch 860, Loss: 1.0990101357952493\n",
      "Epoch 861, Loss: 1.0980868321391961\n",
      "Epoch 862, Loss: 1.0968700530099087\n",
      "Epoch 863, Loss: 1.099881684542819\n",
      "Epoch 864, Loss: 1.096630205943378\n",
      "Epoch 865, Loss: 1.0964804681877343\n",
      "Epoch 866, Loss: 1.0988028341908644\n",
      "Epoch 867, Loss: 1.099514325901831\n",
      "Epoch 868, Loss: 1.0925860529900715\n",
      "Epoch 869, Loss: 1.0980180721791064\n",
      "Epoch 870, Loss: 1.097296201931509\n",
      "Epoch 871, Loss: 1.102538100799297\n",
      "Epoch 872, Loss: 1.0997859059508008\n",
      "Epoch 873, Loss: 1.0990996644145152\n",
      "Epoch 874, Loss: 1.094596589197878\n",
      "Epoch 875, Loss: 1.0970596347955128\n",
      "Epoch 876, Loss: 1.1006832262392066\n",
      "Epoch 877, Loss: 1.09329597069173\n",
      "Epoch 878, Loss: 1.097268534976928\n",
      "Epoch 879, Loss: 1.0992142010907657\n",
      "Epoch 880, Loss: 1.0989781847742737\n",
      "Epoch 881, Loss: 1.096729366156759\n",
      "Epoch 882, Loss: 1.1004373451446203\n",
      "Epoch 883, Loss: 1.0963780616848475\n",
      "Epoch 884, Loss: 1.0959745667857363\n",
      "Epoch 885, Loss: 1.0980421874227233\n",
      "Epoch 886, Loss: 1.0930769181781965\n",
      "Epoch 887, Loss: 1.0965509906725246\n",
      "Epoch 888, Loss: 1.0994831111447874\n",
      "Epoch 889, Loss: 1.0946227107589641\n",
      "Epoch 890, Loss: 1.0951019859146458\n",
      "Epoch 891, Loss: 1.0975775091932864\n",
      "Epoch 892, Loss: 1.0946521082722889\n",
      "Epoch 893, Loss: 1.0939173311064896\n",
      "Epoch 894, Loss: 1.0957396241205917\n",
      "Epoch 895, Loss: 1.0935587268802545\n",
      "Epoch 896, Loss: 1.093317887961725\n",
      "Epoch 897, Loss: 1.096094975426828\n",
      "Epoch 898, Loss: 1.0983569749066087\n",
      "Epoch 899, Loss: 1.09604091645683\n",
      "Epoch 900, Loss: 1.1019009577865064\n",
      "Epoch 901, Loss: 1.0963589928049673\n",
      "Epoch 902, Loss: 1.094031070797449\n",
      "Epoch 903, Loss: 1.0948745635549693\n",
      "Epoch 904, Loss: 1.094625212409178\n",
      "Epoch 905, Loss: 1.0951523705444515\n",
      "Epoch 906, Loss: 1.0993841054567968\n",
      "Epoch 907, Loss: 1.0964444985992736\n",
      "Epoch 908, Loss: 1.0944563798100384\n",
      "Epoch 909, Loss: 1.0969087407516371\n",
      "Epoch 910, Loss: 1.096305226693388\n",
      "Epoch 911, Loss: 1.099286268550283\n",
      "Epoch 912, Loss: 1.0953967347915614\n",
      "Epoch 913, Loss: 1.0988018620209616\n",
      "Epoch 914, Loss: 1.0940676309883735\n",
      "Epoch 915, Loss: 1.091834309020143\n",
      "Epoch 916, Loss: 1.0966982129586107\n",
      "Epoch 917, Loss: 1.0990985436517684\n",
      "Epoch 918, Loss: 1.0963372930849464\n",
      "Epoch 919, Loss: 1.0905609631985076\n",
      "Epoch 920, Loss: 1.094006176924538\n",
      "Epoch 921, Loss: 1.0984158986346224\n",
      "Epoch 922, Loss: 1.0965371291028811\n",
      "Epoch 923, Loss: 1.09295669344605\n",
      "Epoch 924, Loss: 1.099059598646901\n",
      "Epoch 925, Loss: 1.097610173864722\n",
      "Epoch 926, Loss: 1.097432582174587\n",
      "Epoch 927, Loss: 1.0980891091203802\n",
      "Epoch 928, Loss: 1.0961812553835697\n",
      "Epoch 929, Loss: 1.093387277050934\n",
      "Epoch 930, Loss: 1.098955877352096\n",
      "Epoch 931, Loss: 1.098772754713858\n",
      "Epoch 932, Loss: 1.0965876259625098\n",
      "Epoch 933, Loss: 1.0952093626352886\n",
      "Epoch 934, Loss: 1.0986786469363496\n",
      "Epoch 935, Loss: 1.09548250552642\n",
      "Epoch 936, Loss: 1.09485511415457\n",
      "Epoch 937, Loss: 1.1012495403686229\n",
      "Epoch 938, Loss: 1.0965043563195078\n",
      "Epoch 939, Loss: 1.0950830268217753\n",
      "Epoch 940, Loss: 1.0964444895259668\n",
      "Epoch 941, Loss: 1.0979705360790046\n",
      "Epoch 942, Loss: 1.0992813802016703\n",
      "Epoch 943, Loss: 1.0977368532773761\n",
      "Epoch 944, Loss: 1.099367428998478\n",
      "Epoch 945, Loss: 1.0961055994312991\n",
      "Epoch 946, Loss: 1.0954568338617507\n",
      "Epoch 947, Loss: 1.0959224651373523\n",
      "Epoch 948, Loss: 1.0942057116388995\n",
      "Epoch 949, Loss: 1.0957538190993548\n",
      "Epoch 950, Loss: 1.0951061745717319\n",
      "Epoch 951, Loss: 1.094066986574222\n",
      "Epoch 952, Loss: 1.0964829465265296\n",
      "Epoch 953, Loss: 1.095776407514858\n",
      "Epoch 954, Loss: 1.0931414417416485\n",
      "Epoch 955, Loss: 1.0985544041252806\n",
      "Epoch 956, Loss: 1.0964941395669128\n",
      "Epoch 957, Loss: 1.0898976354604584\n",
      "Epoch 958, Loss: 1.0943751425877108\n",
      "Epoch 959, Loss: 1.0891485850062805\n",
      "Epoch 960, Loss: 1.0942279887003976\n",
      "Epoch 961, Loss: 1.0977906911378723\n",
      "Epoch 962, Loss: 1.0992402773551138\n",
      "Epoch 963, Loss: 1.0910986941787622\n",
      "Epoch 964, Loss: 1.0904774148654044\n",
      "Epoch 965, Loss: 1.0928983675093507\n",
      "Epoch 966, Loss: 1.09623463574003\n",
      "Epoch 967, Loss: 1.0928235883874693\n",
      "Epoch 968, Loss: 1.092988504179747\n",
      "Epoch 969, Loss: 1.0976759618981382\n",
      "Epoch 970, Loss: 1.0968817297273274\n",
      "Epoch 971, Loss: 1.093968543989597\n",
      "Epoch 972, Loss: 1.0964797385542957\n",
      "Epoch 973, Loss: 1.0989678252915867\n",
      "Epoch 974, Loss: 1.0957049707897375\n",
      "Epoch 975, Loss: 1.0904958287921387\n",
      "Epoch 976, Loss: 1.0975058447281705\n",
      "Epoch 977, Loss: 1.0994940498534076\n",
      "Epoch 978, Loss: 1.0922703505679092\n",
      "Epoch 979, Loss: 1.0994541017596002\n",
      "Epoch 980, Loss: 1.0952799681757317\n",
      "Epoch 981, Loss: 1.092101626988038\n",
      "Epoch 982, Loss: 1.0947860129683582\n",
      "Epoch 983, Loss: 1.093907996349089\n",
      "Epoch 984, Loss: 1.0924280974010674\n",
      "Epoch 985, Loss: 1.0938930424929223\n",
      "Epoch 986, Loss: 1.0952541116947871\n",
      "Epoch 987, Loss: 1.09629323631874\n",
      "Epoch 988, Loss: 1.097829977717835\n",
      "Epoch 989, Loss: 1.094254908921847\n",
      "Epoch 990, Loss: 1.09608550952525\n",
      "Epoch 991, Loss: 1.090213359518967\n",
      "Epoch 992, Loss: 1.0915382234357838\n",
      "Epoch 993, Loss: 1.0934427640895932\n",
      "Epoch 994, Loss: 1.0925106380387826\n",
      "Epoch 995, Loss: 1.0932483769412342\n",
      "Epoch 996, Loss: 1.0940193928237263\n",
      "Epoch 997, Loss: 1.097593180887593\n",
      "Epoch 998, Loss: 1.091883684419078\n",
      "Epoch 999, Loss: 1.0933147199818345\n",
      "Epoch 1000, Loss: 1.0966022465491463\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T00:40:33.459949Z",
     "start_time": "2024-08-14T00:40:32.411002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "# loader = test_loader\n",
    "loader = train_loader\n",
    "results = []\n",
    "results_x = []\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU\n",
    "        outputs = model(inputs)\n",
    "        results.append(outputs)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class (highest log-probability)\n",
    "        x, predicted = torch.max(outputs, 1)\n",
    "        results_x.append((x, predicted))\n",
    "        \n",
    "        # print(outputs)\n",
    "        # Calculate the number of correct predictions\n",
    "        correct += (predicted == labels.argmax(dim=1)).sum().item()  # labels.argmax(dim=1) for one-hot encoded labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "avg_test_loss = test_loss / len(loader)\n",
    "accuracy = correct / total * 100\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n"
   ],
   "id": "74630e8d1ef4e7fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9828, Test Accuracy: 62.11%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T04:48:42.334539Z",
     "start_time": "2024-08-11T04:48:41.953256Z"
    }
   },
   "cell_type": "code",
   "source": "results_x",
   "id": "632b280a3df30a21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([-6.5484e-04, -8.1538e-01, -4.7827e-04, -4.9135e-01, -7.4117e-01,\n",
       "          -4.1964e-01, -8.2496e-01, -6.0348e-01, -1.2153e+00, -9.5400e-01,\n",
       "          -2.2187e-01, -1.1991e-02, -1.0737e+00, -1.1345e+00, -1.2075e-03,\n",
       "          -4.2074e-01, -5.6550e-03, -1.4195e+00, -3.9013e-01, -1.0258e+00,\n",
       "          -6.8798e-01, -8.3966e-01, -8.8595e-01, -1.0810e+00, -8.2226e-01,\n",
       "          -4.6659e-01, -1.1365e+00, -4.3930e-02, -1.1526e+00, -8.1432e-01,\n",
       "          -4.7135e-01, -2.0064e-03, -9.6952e-01, -8.3103e-01, -1.0798e-02,\n",
       "          -5.0635e-01, -9.8217e-01, -6.7467e-01, -9.1014e-01, -1.0901e+00,\n",
       "          -8.0565e-04, -1.1948e+00, -2.5822e-03, -8.4242e-01, -2.4506e-04,\n",
       "          -1.7021e-03, -8.8014e-01, -1.0128e+00, -1.2652e+00, -4.0420e-03,\n",
       "          -1.8199e-03, -5.9337e-01, -8.3482e-01, -1.0430e+00, -9.6519e-01,\n",
       "          -1.1471e+00, -1.2616e+00, -2.7833e-01, -4.7737e-01, -1.2679e+00,\n",
       "          -4.3825e-01, -3.9098e-01, -8.5959e-01, -1.3095e+00], device='cuda:0'),\n",
       "  tensor([4, 2, 2, 4, 5, 5, 5, 4, 4, 5, 0, 0, 4, 4, 3, 3, 2, 4, 3, 6, 5, 5, 1, 4,\n",
       "          5, 4, 1, 2, 2, 4, 0, 3, 3, 3, 5, 5, 4, 5, 4, 5, 6, 4, 1, 1, 4, 6, 3, 1,\n",
       "          3, 3, 5, 4, 5, 5, 4, 4, 4, 0, 5, 1, 4, 1, 2, 0], device='cuda:0')),\n",
       " (tensor([-3.8436e-02, -1.1923e-01, -4.6193e-01, -7.9507e-01, -5.4245e-01,\n",
       "          -1.0060e+00, -5.8181e-04, -9.5458e-01, -4.2996e-01, -9.9718e-01,\n",
       "          -1.7641e-04, -1.0365e-01, -1.9068e-01, -9.8611e-01, -1.1839e+00,\n",
       "          -3.9309e-01, -1.1386e+00, -9.6296e-01, -3.5652e-01, -1.6032e-04,\n",
       "          -4.7481e-01, -2.5052e-01, -8.1084e-01, -1.7321e-01, -1.0303e+00,\n",
       "          -5.7933e-01, -1.3902e+00, -1.1109e+00, -8.8519e-01, -1.1645e+00,\n",
       "          -1.3192e+00, -2.3440e-03, -1.2488e+00, -3.3295e-03, -1.0711e-01,\n",
       "          -1.1696e+00, -2.8612e-01, -2.7748e-04, -1.2006e+00, -1.0888e+00,\n",
       "          -7.0588e-01, -4.2081e-02, -1.4579e-01, -1.6968e-02, -1.1039e+00,\n",
       "          -7.6459e-01, -1.0641e+00, -1.2957e-02, -9.0700e-01, -1.1603e+00,\n",
       "          -1.1341e+00, -1.3558e+00, -7.3122e-03, -9.1226e-01, -4.6171e-04,\n",
       "          -1.1735e+00, -4.8165e-01, -2.0580e-02, -1.1560e+00, -4.5950e-01,\n",
       "          -8.4062e-01, -2.7164e-04, -2.2753e-03, -4.1523e-01], device='cuda:0'),\n",
       "  tensor([5, 6, 5, 4, 6, 3, 4, 4, 3, 5, 2, 0, 4, 1, 4, 1, 3, 5, 0, 4, 4, 6, 4, 5,\n",
       "          4, 4, 1, 4, 4, 3, 3, 3, 4, 5, 6, 5, 1, 6, 5, 1, 3, 6, 3, 6, 3, 1, 4, 6,\n",
       "          4, 4, 1, 5, 0, 3, 5, 4, 2, 6, 1, 5, 6, 6, 5, 2], device='cuda:0')),\n",
       " (tensor([-1.0613e+00, -4.5214e-01, -2.4569e-03, -8.6132e-01, -1.5822e+00,\n",
       "          -3.6666e-01, -1.2679e-01, -1.1903e+00, -1.2636e-01, -3.6358e-01,\n",
       "          -4.1576e-01, -9.9966e-02, -5.3740e-03, -1.1975e+00, -1.5329e-03,\n",
       "          -1.3930e+00, -9.8369e-01, -1.0539e+00, -1.1230e+00, -1.0472e+00,\n",
       "          -1.1476e+00, -9.4786e-04, -1.2558e+00, -5.1881e-01, -5.8350e-01,\n",
       "          -8.3267e-01, -1.3645e+00, -1.0267e+00, -9.5208e-02, -1.2403e+00,\n",
       "          -4.1961e-05, -5.5431e-01, -5.0249e-01, -1.3594e-03, -7.7091e-01,\n",
       "          -7.1083e-04, -1.1614e+00, -6.0683e-01, -7.3572e-03, -9.8142e-03,\n",
       "          -1.8394e-03, -3.5524e-01, -8.3230e-03, -9.5376e-01, -4.1615e-03,\n",
       "          -6.4333e-01, -1.0487e+00, -2.3739e-01, -1.0200e+00, -1.0762e+00,\n",
       "          -5.4801e-02, -1.5234e-04, -4.0758e-01, -8.4722e-01, -7.6108e-01,\n",
       "          -4.1597e-01, -1.0971e+00, -1.4566e-01, -1.1610e+00, -5.4845e-02,\n",
       "          -1.0174e+00, -1.0027e+00, -4.8297e-01, -1.0494e+00], device='cuda:0'),\n",
       "  tensor([0, 0, 6, 2, 4, 3, 6, 1, 6, 2, 4, 5, 6, 3, 2, 3, 1, 5, 0, 3, 4, 6, 2, 0,\n",
       "          4, 4, 4, 0, 0, 2, 6, 1, 5, 6, 1, 4, 0, 4, 6, 5, 6, 0, 6, 0, 5, 0, 2, 0,\n",
       "          4, 4, 6, 4, 0, 2, 3, 5, 4, 6, 4, 0, 0, 1, 6, 4], device='cuda:0')),\n",
       " (tensor([-1.1545e+00, -4.9961e-01, -6.7402e-01, -2.4133e-03, -6.9237e-04,\n",
       "          -1.1683e+00, -6.9255e-02, -8.2357e-01, -8.2920e-01, -5.1549e-01,\n",
       "          -1.0365e+00, -1.2342e+00, -1.2116e+00, -2.6932e-03, -1.1755e+00,\n",
       "          -5.7523e-01, -1.3126e+00, -6.2386e-03, -1.1512e+00, -8.4373e-01,\n",
       "          -7.6132e-01, -4.2430e-04, -1.3647e+00, -1.1552e+00, -2.0510e-01,\n",
       "          -6.8718e-01, -1.3178e+00, -6.8351e-01, -4.3345e-03, -8.9403e-01,\n",
       "          -2.4079e-03, -2.5742e-03, -1.3434e+00, -1.1841e+00, -9.0933e-01,\n",
       "          -9.5891e-01, -1.0673e-03, -2.0525e-03, -1.0908e+00, -1.8594e-03,\n",
       "          -9.1395e-01, -8.6800e-01, -1.0328e+00, -9.5348e-01, -8.6795e-01,\n",
       "          -8.8089e-01, -8.6037e-01, -1.4714e-01, -1.6797e-02, -7.4967e-03,\n",
       "          -1.2276e+00, -8.1240e-01, -7.7569e-01, -2.6909e-03, -6.1604e-01,\n",
       "          -1.0373e+00, -1.5446e-03, -1.1162e+00, -7.0899e-01, -4.3877e-01,\n",
       "          -1.1960e+00, -1.0723e+00, -4.8261e-03, -8.0958e-04], device='cuda:0'),\n",
       "  tensor([1, 2, 5, 6, 4, 4, 0, 5, 4, 5, 4, 4, 3, 6, 3, 5, 4, 6, 4, 1, 0, 4, 3, 4,\n",
       "          4, 4, 4, 5, 0, 1, 1, 6, 3, 3, 5, 4, 5, 6, 1, 4, 5, 1, 4, 3, 2, 4, 2, 6,\n",
       "          6, 1, 4, 3, 0, 2, 5, 3, 1, 4, 0, 4, 4, 2, 5, 6], device='cuda:0')),\n",
       " (tensor([-1.0865e+00, -2.0947e-01, -3.2023e-01, -5.8267e-03, -3.3647e-01,\n",
       "          -3.8502e-01, -3.1234e-01, -8.8605e-01, -1.8896e-03, -3.1602e-02,\n",
       "          -5.8923e-01, -1.0606e-01, -2.7317e-01, -6.0656e-01, -1.1854e-03,\n",
       "          -7.1538e-01, -8.3217e-01, -4.2956e-01, -5.6271e-01, -5.6986e-01,\n",
       "          -3.9470e-01, -9.9037e-01, -1.1856e+00, -5.5507e-01, -9.7388e-01,\n",
       "          -2.0304e-02, -9.0405e-01, -6.5973e-01, -7.9873e-01, -1.0920e+00,\n",
       "          -1.2516e+00, -7.5916e-01, -1.5684e-02, -7.0710e-01, -5.3803e-01,\n",
       "          -9.6248e-01, -1.0114e+00, -5.3860e-01, -9.2449e-01, -1.6728e-02,\n",
       "          -5.1630e-01, -1.0488e+00, -5.9726e-01, -6.3636e-01, -1.0313e+00,\n",
       "          -8.4048e-01, -1.0758e+00, -5.9410e-02, -1.1789e+00, -4.5176e-01,\n",
       "          -9.8624e-01, -8.7253e-01, -1.4425e-01, -1.1488e+00, -9.0573e-01,\n",
       "          -1.0851e-01, -7.0719e-01, -6.5251e-01, -5.3744e-01, -1.2088e+00,\n",
       "          -6.4076e-01, -1.2122e+00, -5.9956e-01, -5.0939e-01], device='cuda:0'),\n",
       "  tensor([5, 0, 1, 0, 4, 6, 5, 3, 0, 1, 0, 0, 0, 3, 6, 1, 0, 3, 3, 4, 6, 5, 3, 3,\n",
       "          4, 3, 4, 4, 4, 3, 1, 5, 6, 1, 4, 6, 4, 5, 4, 4, 4, 4, 5, 1, 1, 6, 1, 6,\n",
       "          2, 0, 4, 1, 4, 4, 4, 4, 5, 0, 5, 1, 2, 5, 5, 3], device='cuda:0')),\n",
       " (tensor([-5.1612e-01, -6.2780e-01, -1.9258e-03, -2.5132e-01, -6.3173e-01,\n",
       "          -5.5096e-01, -3.2086e-04, -1.2030e+00, -3.0069e-01, -9.7412e-01,\n",
       "          -7.5544e-01, -9.8879e-02, -1.7288e-02, -2.3432e-03, -1.0724e+00,\n",
       "          -8.6050e-01, -9.5682e-02, -1.0621e+00, -9.7409e-01, -8.3351e-01,\n",
       "          -1.3308e+00, -3.4388e-01, -6.5152e-01, -1.5281e-04, -4.6783e-01,\n",
       "          -3.7845e-03, -1.1014e+00, -3.8905e-01, -8.9629e-01, -2.2038e-02,\n",
       "          -1.1696e+00, -9.6208e-01, -9.7763e-01, -1.0905e+00, -9.9950e-01,\n",
       "          -1.1706e+00, -5.1485e-01, -1.2241e+00, -8.4202e-01, -2.7574e-03,\n",
       "          -1.3766e+00, -7.8514e-01, -1.3335e+00, -3.8076e-01, -7.8585e-01,\n",
       "          -1.0760e-03, -1.0675e-03, -1.2249e+00, -1.0853e+00, -1.1381e+00,\n",
       "          -1.0693e+00, -3.0048e-02, -3.5470e-04, -6.7110e-01, -5.3799e-01,\n",
       "          -1.4840e-01, -9.7804e-01, -8.7032e-01, -8.6568e-02, -7.0461e-01,\n",
       "          -3.3766e-04, -1.4475e+00, -7.3349e-01, -5.6824e-01], device='cuda:0'),\n",
       "  tensor([1, 0, 4, 5, 5, 3, 4, 2, 0, 4, 4, 6, 5, 6, 5, 3, 1, 4, 4, 4, 4, 5, 5, 6,\n",
       "          4, 6, 6, 4, 3, 6, 4, 6, 2, 4, 4, 2, 0, 1, 0, 1, 4, 5, 0, 0, 4, 6, 3, 5,\n",
       "          5, 4, 4, 4, 4, 3, 5, 1, 5, 6, 5, 5, 4, 4, 3, 5], device='cuda:0')),\n",
       " (tensor([-8.9945e-01, -9.2815e-01, -1.2985e+00, -7.3450e-03, -7.3021e-01,\n",
       "          -2.9811e-01, -9.7681e-03, -1.0123e+00, -1.1865e+00, -1.2236e+00,\n",
       "          -1.0863e+00, -3.8055e-01, -1.1684e+00, -1.2895e-03, -1.3568e-01,\n",
       "          -5.5964e-01, -9.9815e-01, -2.8649e-01, -1.1191e+00, -1.1758e+00,\n",
       "          -2.2000e-03, -1.1743e+00, -9.9517e-01, -2.1955e-01, -1.0379e+00,\n",
       "          -1.1944e+00, -1.0892e+00, -4.4979e-01, -5.1352e-03, -4.0995e-01,\n",
       "          -6.2550e-01, -9.0479e-01, -5.1391e-01, -9.0797e-01, -1.3836e+00,\n",
       "          -1.3546e+00, -6.8848e-01, -1.0273e+00, -2.8174e-01, -5.1319e-01,\n",
       "          -1.1791e+00, -4.7900e-01, -1.1168e+00, -1.2764e+00, -4.9734e-01,\n",
       "          -6.7247e-04, -6.9539e-01, -1.4078e+00, -1.0706e-02, -9.5338e-01,\n",
       "          -7.5245e-01, -1.1345e+00, -9.8378e-01, -1.3720e-02, -1.3777e-02,\n",
       "          -8.6627e-01, -1.6404e-03, -3.3241e-01, -1.2826e-03, -5.8694e-01,\n",
       "          -3.9282e-03, -2.3728e-03, -1.0786e+00, -5.7259e-01], device='cuda:0'),\n",
       "  tensor([4, 0, 3, 5, 4, 5, 2, 0, 2, 3, 4, 3, 2, 2, 6, 3, 4, 0, 4, 4, 5, 2, 1, 6,\n",
       "          1, 4, 3, 4, 0, 0, 2, 4, 4, 5, 1, 0, 4, 2, 1, 3, 4, 3, 5, 4, 5, 6, 0, 4,\n",
       "          6, 4, 2, 4, 5, 6, 6, 6, 6, 0, 6, 4, 6, 0, 0, 4], device='cuda:0')),\n",
       " (tensor([-6.9296e-04, -1.2266e+00, -7.1309e-01, -1.0428e+00, -5.9340e-01,\n",
       "          -5.5957e-01, -9.6470e-01, -7.2453e-01, -8.3632e-01, -9.0379e-04,\n",
       "          -1.0729e+00, -9.2103e-01, -1.4884e+00, -1.1522e+00, -1.3078e+00,\n",
       "          -1.2482e+00, -9.6695e-01, -3.9522e-01, -3.4801e-01, -8.2128e-01,\n",
       "          -8.9182e-01, -2.2487e-01, -9.3474e-01, -3.4288e-01, -4.4172e-01,\n",
       "          -1.4654e+00, -1.0038e+00, -6.0417e-03, -5.9711e-01, -1.1434e+00,\n",
       "          -8.7193e-01, -8.8392e-01, -8.0339e-01, -1.2886e+00, -2.2258e-03,\n",
       "          -4.3487e-03, -7.1647e-02, -2.1073e-03, -8.2866e-02, -9.6517e-03,\n",
       "          -5.6955e-01, -5.6050e-02, -8.2799e-01, -6.7254e-02, -6.0811e-01,\n",
       "          -1.4575e-01, -1.1812e+00, -1.0073e+00, -1.2403e+00, -6.1358e-01,\n",
       "          -6.2790e-01, -4.7369e-02, -4.8709e-03, -1.0590e+00, -5.0354e-01,\n",
       "          -1.3213e+00, -1.2658e+00, -3.4682e-01, -9.5791e-01, -4.3225e-01,\n",
       "          -5.3413e-01, -2.2140e-01, -1.4378e+00, -8.3049e-01], device='cuda:0'),\n",
       "  tensor([5, 4, 1, 5, 5, 5, 2, 4, 1, 6, 2, 6, 2, 5, 3, 1, 4, 4, 0, 0, 0, 5, 4, 5,\n",
       "          4, 4, 1, 6, 0, 6, 2, 4, 1, 5, 0, 1, 3, 6, 4, 6, 4, 6, 1, 1, 4, 6, 1, 0,\n",
       "          1, 3, 4, 0, 6, 4, 4, 3, 5, 5, 5, 5, 0, 0, 3, 0], device='cuda:0')),\n",
       " (tensor([-1.2153e+00, -1.1329e+00, -1.0666e+00, -1.1023e+00, -5.7602e-01,\n",
       "          -8.1475e-01, -1.2546e+00, -5.1089e-01, -1.8868e-02, -5.1323e-01,\n",
       "          -2.2561e-01, -1.4397e-03, -7.7183e-01, -7.4059e-01, -1.1523e+00,\n",
       "          -9.8488e-02, -1.5240e-02, -1.0303e+00, -6.5197e-01, -1.1615e+00,\n",
       "          -8.3885e-01, -9.7293e-01, -6.2623e-01, -1.2262e+00, -3.0119e-03,\n",
       "          -1.0437e+00, -9.0039e-01, -7.7463e-01, -7.9648e-01, -4.9626e-04,\n",
       "          -4.4087e-01, -1.1450e+00, -6.2196e-04, -1.0479e+00, -5.2822e-01,\n",
       "          -4.1836e-01, -7.0688e-01, -5.3861e-01, -8.4576e-01, -1.0368e+00,\n",
       "          -2.7222e-01, -1.0990e+00, -6.1022e-01, -1.0685e+00, -1.9332e-02,\n",
       "          -3.0884e-01, -2.6082e-02, -4.6325e-01, -5.0393e-01, -2.1002e-01,\n",
       "          -9.3010e-01, -6.5026e-01, -4.1900e-01, -1.1032e+00, -8.7097e-01,\n",
       "          -7.5314e-01, -8.9224e-01, -1.2642e+00, -2.5748e-01, -9.3195e-01,\n",
       "          -8.2247e-01, -7.5215e-01, -1.0261e+00, -1.2957e+00], device='cuda:0'),\n",
       "  tensor([5, 4, 2, 6, 5, 4, 5, 2, 3, 6, 0, 0, 5, 4, 4, 5, 0, 4, 4, 2, 4, 2, 5, 5,\n",
       "          5, 6, 2, 4, 2, 4, 5, 4, 0, 4, 1, 0, 5, 4, 5, 2, 0, 1, 0, 5, 3, 5, 0, 4,\n",
       "          1, 6, 1, 4, 4, 3, 4, 0, 3, 4, 1, 4, 1, 1, 1, 6], device='cuda:0')),\n",
       " (tensor([-1.2975e+00, -2.5824e-01, -3.3873e-03, -5.3943e-01, -5.0142e-01,\n",
       "          -5.1734e-01, -1.3552e+00, -4.8681e-01, -2.9882e-02, -3.1589e-01,\n",
       "          -8.1685e-04, -1.2108e+00, -6.3244e-04, -9.5202e-01, -1.1973e-03,\n",
       "          -7.9506e-01, -1.0548e+00, -9.8831e-01, -7.4384e-01, -9.4567e-01,\n",
       "          -4.0749e-04, -6.5930e-01, -7.2804e-01, -1.3104e+00, -6.7695e-01,\n",
       "          -7.1766e-01, -3.6619e-01, -1.1152e+00, -5.3230e-01, -1.6193e-03,\n",
       "          -6.4770e-01, -8.6891e-01, -1.3815e-02, -8.7244e-01, -7.4225e-01,\n",
       "          -8.1594e-01, -7.2783e-01, -4.7513e-01, -3.6150e-04, -8.3923e-01,\n",
       "          -4.3407e-04, -3.4043e-01, -5.9552e-03, -5.6143e-01, -6.3013e-01,\n",
       "          -8.7569e-01, -1.4257e+00, -5.4025e-01, -6.3929e-02, -1.1806e+00,\n",
       "          -1.3520e+00, -7.8252e-01, -5.0109e-01, -8.8440e-01, -3.2820e-03,\n",
       "          -8.0969e-02, -7.4629e-01, -8.4165e-01, -8.1448e-01, -1.5714e-01,\n",
       "          -2.1004e-02, -8.2635e-01, -3.9170e-03, -7.5164e-01], device='cuda:0'),\n",
       "  tensor([1, 3, 5, 5, 3, 5, 6, 2, 0, 6, 6, 0, 5, 3, 5, 4, 4, 4, 1, 3, 4, 5, 1, 1,\n",
       "          5, 3, 5, 5, 1, 5, 6, 3, 1, 5, 2, 4, 4, 3, 6, 4, 6, 4, 0, 6, 5, 5, 5, 6,\n",
       "          6, 2, 2, 0, 4, 1, 6, 0, 3, 2, 6, 0, 5, 5, 2, 5], device='cuda:0')),\n",
       " (tensor([-1.1059e+00, -1.2850e-04, -9.4074e-01, -2.0628e-03, -1.3412e+00,\n",
       "          -1.0608e+00, -1.3770e+00, -5.1461e-01, -7.8857e-01, -1.8464e-01,\n",
       "          -9.3162e-01, -1.0419e+00, -2.7553e-03, -3.7163e-02, -8.5409e-01,\n",
       "          -7.9174e-01, -3.4886e-03, -3.5184e-01, -8.0301e-01, -4.8706e-02,\n",
       "          -8.5727e-01, -9.1389e-02, -3.4685e-02, -1.8462e-02, -8.7087e-01,\n",
       "          -4.3127e-01, -5.5223e-02, -2.7112e-02, -5.7816e-01, -2.8333e-01,\n",
       "          -1.0349e+00, -9.8093e-01, -1.3086e+00, -4.2355e-01, -3.2163e-02,\n",
       "          -7.4601e-03, -6.0826e-04, -6.4991e-01, -8.9214e-01, -6.3978e-01,\n",
       "          -8.5859e-01, -1.4407e+00, -7.3574e-01, -1.3285e-01, -3.2205e-01,\n",
       "          -8.6506e-01, -5.9539e-04, -5.5574e-01, -8.8781e-01, -3.9082e-02,\n",
       "          -7.1129e-03, -1.1341e+00, -5.0103e-01, -1.1956e+00, -5.7251e-01,\n",
       "          -1.1189e+00, -2.8422e-01, -1.0794e-02, -3.8547e-01, -8.4313e-01,\n",
       "          -1.0061e+00, -9.7494e-01, -6.4319e-01, -1.1284e-02], device='cuda:0'),\n",
       "  tensor([4, 2, 5, 2, 0, 1, 3, 0, 5, 6, 5, 5, 6, 0, 3, 5, 2, 4, 4, 5, 4, 6, 6, 6,\n",
       "          0, 4, 0, 3, 5, 0, 4, 2, 4, 0, 3, 5, 4, 0, 5, 0, 3, 4, 4, 0, 6, 4, 2, 5,\n",
       "          6, 0, 0, 1, 6, 1, 0, 0, 5, 6, 0, 4, 3, 4, 5, 6], device='cuda:0')),\n",
       " (tensor([-3.1625e-01, -1.1711e+00, -2.5863e-01, -7.7658e-01, -8.1413e-01,\n",
       "          -1.2721e+00, -1.1163e+00, -1.6356e-01, -9.8127e-01, -4.9648e-03,\n",
       "          -1.3298e+00, -1.3771e-03, -4.6700e-01, -8.1533e-01, -5.7428e-01,\n",
       "          -1.8578e-01, -7.9095e-01, -2.7703e-01, -5.0924e-02, -1.2354e+00,\n",
       "          -4.2220e-02, -7.2229e-02, -5.4655e-01, -7.4506e-01, -5.8798e-01,\n",
       "          -1.0098e+00, -1.4289e-03, -1.2497e+00, -1.1046e+00, -5.2593e-04,\n",
       "          -1.0761e+00, -7.8876e-01, -7.3452e-01, -1.1235e+00, -1.2662e+00,\n",
       "          -5.7488e-01, -7.6778e-03, -4.6302e-01, -1.3545e-01, -1.0001e+00,\n",
       "          -1.6037e-02, -7.7548e-01, -9.8197e-01, -8.0044e-01, -4.5134e-04,\n",
       "          -8.9669e-01, -1.3053e+00, -3.2753e-04, -1.2127e+00, -1.1987e+00,\n",
       "          -1.6317e-01, -7.7755e-01, -5.7481e-01, -1.1439e+00, -6.5083e-01,\n",
       "          -5.1805e-03, -4.5057e-01, -7.0710e-01, -5.9644e-01, -1.0298e+00,\n",
       "          -6.2210e-01, -2.3264e-01, -9.3551e-01, -1.1282e-02], device='cuda:0'),\n",
       "  tensor([0, 3, 4, 5, 1, 1, 6, 6, 4, 6, 4, 6, 0, 5, 4, 0, 0, 0, 4, 3, 1, 0, 5, 4,\n",
       "          0, 4, 5, 4, 4, 6, 1, 4, 2, 1, 2, 0, 6, 0, 0, 4, 6, 0, 0, 3, 4, 3, 4, 6,\n",
       "          0, 3, 1, 0, 1, 4, 5, 1, 5, 5, 0, 4, 0, 0, 5, 3], device='cuda:0')),\n",
       " (tensor([-1.1957e+00, -3.6147e-01, -1.0698e+00, -2.0907e-01, -8.8660e-01,\n",
       "          -1.0887e+00, -4.5878e-03, -7.7255e-01, -7.6334e-01, -4.0246e-01,\n",
       "          -1.1925e+00, -5.8687e-01, -2.4259e-03, -7.4669e-04, -8.3191e-01,\n",
       "          -1.3595e+00, -7.2215e-04, -1.1791e-03, -1.1409e+00, -1.2888e+00,\n",
       "          -5.8803e-01, -1.5589e+00, -1.0818e+00, -3.3409e-04, -8.2358e-01,\n",
       "          -1.1447e-02, -2.4999e-03, -1.1813e+00, -2.6204e-03, -4.6463e-01,\n",
       "          -3.1681e-04, -1.1342e+00, -3.3829e-01, -3.1993e-01, -1.4841e+00,\n",
       "          -7.1111e-01, -5.7532e-01, -6.1943e-03, -4.0608e-01, -1.1055e+00,\n",
       "          -3.0749e-01, -6.2288e-01, -6.5005e-01, -2.9772e-01, -6.7561e-01,\n",
       "          -8.9239e-01, -1.4366e+00, -5.1785e-01, -1.2277e+00, -1.2339e+00,\n",
       "          -5.2569e-04, -1.3810e+00, -4.7432e-01, -4.2418e-02, -1.3827e-03,\n",
       "          -3.9916e-01, -6.6527e-03, -7.2375e-01, -8.1120e-01, -9.3921e-01,\n",
       "          -1.0062e+00, -8.7765e-03, -8.6121e-01, -9.5054e-02], device='cuda:0'),\n",
       "  tensor([4, 5, 3, 6, 6, 4, 6, 3, 1, 3, 0, 3, 5, 6, 5, 4, 4, 2, 2, 4, 4, 4, 1, 4,\n",
       "          4, 0, 6, 2, 4, 1, 4, 6, 6, 4, 4, 6, 0, 1, 0, 6, 4, 1, 0, 1, 0, 5, 4, 0,\n",
       "          1, 1, 5, 6, 4, 0, 6, 4, 4, 2, 5, 0, 6, 6, 1, 6], device='cuda:0')),\n",
       " (tensor([-3.5361e-02, -1.6801e-01, -2.6760e-01, -6.5967e-01, -1.2908e+00,\n",
       "          -4.1027e-03, -4.8109e-01, -7.6431e-01, -1.0748e+00, -5.5458e-01,\n",
       "          -8.4269e-01, -1.1438e+00, -5.8809e-01, -5.7638e-01, -2.5850e-01,\n",
       "          -2.4051e-01, -3.3802e-04, -8.1065e-03, -1.3008e+00, -9.0691e-01,\n",
       "          -8.2802e-01, -7.2142e-01, -6.6700e-01, -4.2906e-04, -1.1101e+00,\n",
       "          -7.1806e-01, -1.4161e+00, -6.5155e-01, -8.0743e-01, -4.8855e-01,\n",
       "          -7.5696e-01, -5.1949e-03, -1.0282e-02, -1.2706e+00, -7.0832e-01,\n",
       "          -7.8249e-01, -1.1772e+00, -3.5564e-03, -9.7112e-01, -8.8320e-01,\n",
       "          -3.5758e-01, -1.4295e-03, -6.0174e-01, -6.7057e-04, -6.8752e-01,\n",
       "          -1.5340e+00, -1.0025e+00, -9.0027e-01, -1.2023e+00, -6.8641e-01,\n",
       "          -1.2737e-02, -1.0728e+00, -1.0172e+00, -1.1669e+00, -1.0029e+00,\n",
       "          -1.0742e-03, -7.4575e-01, -6.6769e-01, -1.1880e+00, -4.9904e-01,\n",
       "          -4.5319e-01, -1.1405e-03, -1.2286e+00, -1.2281e+00], device='cuda:0'),\n",
       "  tensor([0, 1, 3, 5, 5, 4, 4, 3, 3, 1, 5, 1, 1, 5, 5, 0, 2, 5, 5, 4, 2, 2, 1, 6,\n",
       "          1, 1, 4, 6, 4, 1, 4, 6, 0, 6, 1, 4, 3, 3, 4, 6, 5, 0, 6, 5, 1, 0, 0, 2,\n",
       "          1, 6, 6, 3, 4, 3, 4, 4, 1, 0, 4, 0, 3, 0, 1, 4], device='cuda:0')),\n",
       " (tensor([-1.1253e+00, -1.8644e-01, -3.5881e-02, -8.4088e-01, -1.1743e+00,\n",
       "          -1.2373e+00, -1.2098e+00, -9.6773e-03, -3.6867e-03, -7.8425e-01,\n",
       "          -6.9689e-01, -1.9639e-01, -9.7675e-01, -3.7426e-01, -7.0260e-01,\n",
       "          -3.1876e-01, -9.0055e-01, -7.8582e-01, -8.7306e-01, -1.0392e-02,\n",
       "          -9.2516e-01, -8.2817e-01, -2.5856e-02, -9.4930e-01, -1.4640e+00,\n",
       "          -3.4176e-03, -5.2378e-03, -1.1892e+00, -5.5271e-01, -1.2869e+00,\n",
       "          -8.2616e-01, -3.0990e-01, -1.1266e+00, -1.3014e+00, -1.0568e+00,\n",
       "          -6.8783e-01, -5.0246e-04, -9.5943e-01, -5.3905e-01, -5.4526e-01,\n",
       "          -5.9430e-01, -8.6846e-01, -6.8306e-01, -7.9484e-01, -3.9719e-03,\n",
       "          -1.2725e+00, -5.2831e-01, -1.6131e-03, -2.2375e-01, -1.0734e+00,\n",
       "          -7.8658e-01, -7.4779e-01, -8.8690e-01, -1.0650e+00, -5.7944e-01,\n",
       "          -8.6460e-01, -3.4403e-03, -3.3480e-04, -8.1303e-01, -8.7715e-01,\n",
       "          -2.0487e-02, -1.4725e+00, -4.8005e-03, -2.6223e-03], device='cuda:0'),\n",
       "  tensor([3, 1, 6, 5, 4, 1, 1, 1, 1, 0, 1, 0, 1, 5, 0, 5, 2, 1, 1, 6, 4, 4, 6, 3,\n",
       "          6, 6, 2, 4, 1, 4, 5, 0, 3, 4, 3, 4, 6, 4, 0, 2, 1, 0, 4, 3, 6, 4, 1, 4,\n",
       "          4, 0, 4, 2, 2, 4, 5, 5, 2, 5, 5, 6, 1, 6, 3, 5], device='cuda:0')),\n",
       " (tensor([-7.3225e-01, -3.9619e-01, -4.9351e-01, -7.6545e-01, -5.9091e-01,\n",
       "          -8.6783e-01, -9.3815e-01, -7.7156e-01, -4.1908e-03, -4.0255e-01,\n",
       "          -4.0904e-04, -1.3860e+00, -1.2383e+00, -3.4613e-01, -6.4731e-01,\n",
       "          -7.8674e-01, -8.1126e-01, -2.9850e-03, -4.8101e-01, -1.1346e+00,\n",
       "          -2.4531e-01, -8.4979e-01, -1.1982e+00, -2.8934e-01, -3.4466e-02,\n",
       "          -5.0017e-03, -9.9207e-03, -8.2435e-01, -1.7885e-02, -2.2757e-01,\n",
       "          -1.0843e+00, -9.1439e-01, -1.1228e-01, -8.3720e-01, -7.9908e-01,\n",
       "          -7.4681e-04, -1.0710e+00, -3.0194e-01, -1.9215e-01, -3.0290e-03,\n",
       "          -2.9428e-02, -7.9995e-01, -8.7718e-01, -1.0598e+00, -8.3427e-01,\n",
       "          -1.2459e-01, -1.2960e+00, -1.1185e+00, -7.2403e-01, -5.3281e-01,\n",
       "          -5.8706e-01, -1.7383e-03, -1.1351e+00, -3.9619e-01, -5.6116e-01,\n",
       "          -4.1584e-03, -1.6994e-03, -4.0080e-01, -7.7750e-03, -1.1963e+00,\n",
       "          -9.7273e-01, -1.0712e+00, -9.7293e-01, -8.8395e-01], device='cuda:0'),\n",
       "  tensor([3, 3, 0, 2, 2, 4, 1, 5, 2, 4, 5, 4, 0, 0, 0, 1, 5, 3, 4, 4, 3, 0, 5, 0,\n",
       "          3, 0, 1, 4, 0, 6, 3, 3, 6, 0, 4, 6, 4, 5, 1, 6, 6, 4, 2, 1, 0, 6, 4, 1,\n",
       "          2, 0, 5, 6, 5, 3, 5, 0, 0, 5, 3, 1, 0, 3, 4, 2], device='cuda:0')),\n",
       " (tensor([-3.4649e-01, -1.1680e+00, -2.6641e-03, -5.8840e-02, -7.8797e-01,\n",
       "          -4.8300e-01, -1.0259e+00, -1.0978e+00, -6.6365e-01, -7.6149e-01,\n",
       "          -9.9344e-01, -6.7797e-01, -4.8379e-01, -1.2248e+00, -1.4249e+00,\n",
       "          -2.2959e-01, -2.9365e-01, -3.5655e-01, -4.4249e-01, -6.6381e-01,\n",
       "          -5.2018e-01, -1.2288e+00, -9.2553e-01, -9.4836e-01, -9.1129e-01,\n",
       "          -1.0670e+00, -1.1000e+00, -4.4647e-01, -5.0587e-01, -5.8896e-01,\n",
       "          -1.0219e-01, -9.8432e-01, -6.6423e-01, -1.2817e+00, -5.9429e-03,\n",
       "          -9.4431e-01, -9.7095e-01, -9.5784e-01, -2.5430e-01, -3.2252e-02,\n",
       "          -2.7852e-01, -5.4892e-01, -4.5811e-02, -4.5216e-01, -5.9480e-01,\n",
       "          -1.4284e-03, -1.2086e+00, -3.3953e-03, -3.2276e-01, -1.1925e+00,\n",
       "          -4.6219e-01, -1.1936e+00, -1.0237e+00, -5.3494e-01, -1.0432e+00,\n",
       "          -6.7545e-04, -3.5627e-03, -7.7397e-01, -5.4956e-01, -1.1670e+00,\n",
       "          -1.1551e+00, -1.4222e+00, -1.0281e+00, -3.5927e-03], device='cuda:0'),\n",
       "  tensor([6, 1, 6, 6, 6, 2, 3, 4, 2, 3, 4, 2, 5, 4, 6, 1, 0, 6, 1, 4, 0, 2, 3, 0,\n",
       "          5, 5, 1, 5, 4, 4, 6, 1, 6, 4, 0, 3, 4, 4, 2, 5, 3, 6, 6, 6, 5, 2, 1, 6,\n",
       "          1, 5, 0, 4, 4, 6, 4, 6, 6, 4, 1, 1, 4, 4, 4, 0], device='cuda:0')),\n",
       " (tensor([-5.3016e-01, -3.9327e-01, -9.3192e-01, -4.6447e-01, -1.8644e-03,\n",
       "          -7.5483e-01, -7.8913e-03, -1.4720e+00, -6.5365e-01, -1.1596e+00,\n",
       "          -1.2562e+00, -6.1759e-01, -1.2621e+00, -2.7291e-03, -8.3372e-01,\n",
       "          -1.2055e+00, -3.4183e-04, -6.9597e-01, -8.5142e-01, -1.0639e+00,\n",
       "          -7.9161e-01, -6.8432e-01, -8.2963e-01, -9.6902e-01, -1.0904e+00,\n",
       "          -1.1148e-03, -9.3200e-01, -3.0707e-02, -1.4546e+00, -1.3824e+00,\n",
       "          -1.2790e+00, -9.9688e-01, -2.9536e-01, -8.5184e-01, -1.0075e-01,\n",
       "          -9.9959e-01, -1.4703e+00, -9.5653e-01, -1.0752e+00, -1.4224e-02,\n",
       "          -3.6767e-01, -7.4722e-01, -1.9728e-03, -3.1609e-04, -8.5179e-01,\n",
       "          -3.5047e-01, -5.3709e-01, -9.1465e-01, -7.1243e-01, -9.1176e-03,\n",
       "          -1.0101e+00, -1.4742e+00, -1.2075e+00, -8.4850e-01, -9.1434e-01,\n",
       "          -1.0048e+00, -6.4911e-01, -9.0716e-01, -4.8319e-01, -1.2316e+00,\n",
       "          -6.4216e-03, -6.1235e-01, -1.0799e+00, -6.8798e-01], device='cuda:0'),\n",
       "  tensor([0, 0, 3, 5, 6, 5, 6, 1, 5, 0, 5, 1, 4, 5, 4, 3, 6, 4, 3, 0, 4, 4, 4, 5,\n",
       "          5, 6, 2, 6, 1, 4, 4, 4, 1, 4, 6, 4, 1, 3, 4, 6, 4, 3, 5, 5, 1, 0, 5, 2,\n",
       "          5, 6, 3, 5, 1, 4, 2, 6, 2, 3, 5, 1, 2, 4, 1, 4], device='cuda:0')),\n",
       " (tensor([-8.3906e-01, -1.1000e+00, -1.1666e+00, -9.9703e-01, -8.1161e-01,\n",
       "          -1.3164e-03, -4.4349e-01, -6.6896e-02, -3.9089e-01, -1.0945e+00,\n",
       "          -5.8319e-01, -8.7381e-01, -5.3078e-01, -1.1385e+00, -9.9012e-01,\n",
       "          -3.9548e-01, -8.7310e-01, -2.6621e-03, -1.1328e+00, -3.5594e-01,\n",
       "          -1.2320e+00, -8.9702e-01, -1.4469e-01, -1.1052e+00, -1.1849e+00,\n",
       "          -7.0368e-04, -1.0565e+00, -9.3060e-01, -9.3621e-01, -2.3239e-03,\n",
       "          -5.3220e-01, -1.9295e-02, -4.5892e-02, -7.9097e-01, -1.3332e-03,\n",
       "          -2.2408e-01, -7.7447e-01, -6.3807e-01, -1.0135e+00, -2.7898e-01,\n",
       "          -1.0986e+00, -9.1182e-01, -1.2003e+00, -8.7946e-01, -1.1728e-02,\n",
       "          -4.8566e-01, -7.1180e-01, -9.7893e-01, -3.1242e-03, -1.7903e-01,\n",
       "          -1.4077e+00, -6.1016e-01, -1.1618e+00, -8.2219e-01, -5.5918e-01,\n",
       "          -5.4168e-03, -1.5173e+00, -1.3108e+00, -1.0776e+00, -8.9671e-01,\n",
       "          -9.7622e-01, -7.7336e-01, -1.9087e-02, -1.2029e+00], device='cuda:0'),\n",
       "  tensor([3, 4, 5, 2, 2, 1, 6, 4, 0, 4, 0, 5, 6, 0, 3, 5, 4, 1, 4, 1, 3, 4, 6, 4,\n",
       "          4, 2, 1, 3, 1, 3, 0, 6, 6, 5, 5, 6, 6, 0, 2, 4, 3, 5, 2, 1, 0, 5, 1, 4,\n",
       "          1, 4, 4, 1, 4, 4, 5, 1, 4, 2, 1, 5, 1, 4, 0, 4], device='cuda:0')),\n",
       " (tensor([-2.1810e-02, -5.0187e-01, -1.2726e+00, -4.6207e-04, -2.2147e-01,\n",
       "          -1.1504e+00, -7.8733e-01, -9.2487e-01, -6.4253e-01, -2.0707e-02,\n",
       "          -8.0467e-01, -1.2382e+00, -7.8411e-01, -1.4342e-02, -5.2611e-01,\n",
       "          -3.4166e-02, -6.8492e-01, -6.0645e-01, -6.9675e-01, -1.2150e+00,\n",
       "          -1.0490e+00, -2.1546e-01, -3.0104e-03, -8.8019e-01, -4.7367e-02,\n",
       "          -9.5701e-01, -7.7969e-01, -1.1946e+00, -1.0150e+00, -4.1704e-01,\n",
       "          -5.5892e-02, -5.3002e-01, -7.6752e-02, -8.6720e-01, -4.9998e-01,\n",
       "          -1.0696e+00, -6.6937e-01, -1.0971e-01, -1.3258e-01, -1.1604e+00,\n",
       "          -9.9474e-01, -1.4740e+00, -1.0435e+00, -1.2828e+00, -7.1426e-01,\n",
       "          -5.7086e-01, -9.4585e-01, -1.0236e+00, -7.1024e-04, -5.3737e-04,\n",
       "          -6.1158e-01, -6.3610e-01, -5.3536e-01, -1.4423e-04, -1.3717e+00,\n",
       "          -6.7718e-01, -1.1585e+00, -5.7072e-03, -9.7275e-01, -9.3130e-01,\n",
       "          -8.1599e-01, -8.4149e-01, -1.1262e+00, -2.7467e-02], device='cuda:0'),\n",
       "  tensor([3, 5, 4, 6, 6, 4, 0, 5, 5, 6, 0, 4, 1, 4, 5, 6, 4, 5, 0, 2, 3, 1, 6, 3,\n",
       "          0, 4, 4, 1, 5, 5, 6, 4, 0, 4, 5, 4, 5, 0, 6, 4, 3, 3, 1, 5, 5, 3, 5, 4,\n",
       "          5, 5, 2, 5, 4, 6, 4, 1, 6, 4, 4, 4, 0, 4, 5, 6], device='cuda:0')),\n",
       " (tensor([-1.0285e+00, -1.7222e-03, -1.0053e+00, -8.5709e-01, -9.4779e-03,\n",
       "          -1.2482e+00, -8.0628e-01, -1.1892e+00, -1.0672e+00, -3.8419e-01,\n",
       "          -3.8407e-01, -9.5123e-01, -1.3872e-03, -1.1198e+00, -8.5551e-01,\n",
       "          -7.3163e-03, -1.0232e+00, -6.3258e-01, -4.5229e-01, -4.4069e-01,\n",
       "          -1.0215e+00, -5.0913e-01, -1.5470e-03, -1.0963e+00, -2.9920e-03,\n",
       "          -4.2336e-03, -6.4383e-01, -4.4519e-01, -6.4577e-01, -6.6497e-04,\n",
       "          -4.3639e-01, -9.0596e-01, -6.2301e-01, -1.0454e+00, -1.0561e+00,\n",
       "          -7.2402e-01, -1.1227e+00, -1.9787e-04, -2.2848e-02, -9.8388e-01,\n",
       "          -1.8814e-02, -1.1887e+00, -7.0377e-01, -1.1921e+00, -9.7342e-01,\n",
       "          -5.6504e-01, -4.7867e-01, -7.3882e-03, -6.8705e-01, -6.9325e-01,\n",
       "          -1.2995e-01, -1.1831e+00, -8.0303e-01, -7.7995e-01, -9.6504e-01,\n",
       "          -9.7405e-01, -1.4345e+00, -1.3362e-04, -1.2396e+00, -3.4361e-01,\n",
       "          -1.0056e+00, -1.0498e+00, -4.7222e-02, -1.3750e+00], device='cuda:0'),\n",
       "  tensor([4, 6, 2, 1, 5, 3, 1, 0, 6, 4, 6, 4, 6, 4, 4, 6, 2, 4, 3, 5, 0, 4, 5, 4,\n",
       "          1, 4, 1, 4, 5, 4, 5, 4, 5, 3, 0, 1, 2, 2, 0, 0, 6, 3, 5, 3, 3, 5, 1, 5,\n",
       "          2, 3, 0, 0, 4, 5, 0, 2, 4, 6, 5, 4, 3, 3, 6, 4], device='cuda:0')),\n",
       " (tensor([-9.4318e-01, -1.4761e+00, -9.2546e-01, -5.6427e-01, -5.5226e-01,\n",
       "          -1.1798e-02, -6.3172e-01, -1.7356e-02, -8.0978e-01, -9.5306e-01,\n",
       "          -1.3553e-04, -1.4493e+00, -1.2223e+00, -5.3511e-01, -3.5757e-03,\n",
       "          -1.5771e-01, -9.1157e-01, -4.7469e-01, -7.4059e-01, -6.6036e-01,\n",
       "          -6.6237e-01, -9.3830e-01, -7.4386e-01, -1.2152e-01, -3.0667e-01,\n",
       "          -2.1030e-03, -6.1733e-01, -1.5704e-01, -9.3575e-01, -1.0526e-04,\n",
       "          -7.6452e-01, -7.9218e-01, -1.1009e+00, -8.7425e-01, -9.6751e-01,\n",
       "          -8.3080e-01, -1.1757e+00, -8.3757e-04, -3.3349e-04, -1.1466e+00,\n",
       "          -1.0850e-01, -7.9415e-01, -6.9134e-01, -4.6636e-01, -5.4402e-01,\n",
       "          -1.1282e+00, -8.7275e-01, -1.7100e-01, -2.9876e-02, -6.8235e-01,\n",
       "          -1.4594e+00, -2.4301e-01, -1.2368e+00, -1.1734e+00, -4.5514e-01,\n",
       "          -1.3020e+00, -3.1883e-02, -7.0241e-01, -1.9503e-03, -1.0607e+00,\n",
       "          -1.9199e-01, -9.0112e-01, -1.5655e-03, -1.1683e+00], device='cuda:0'),\n",
       "  tensor([4, 2, 3, 5, 2, 0, 3, 0, 4, 2, 4, 3, 4, 0, 2, 4, 5, 1, 1, 3, 0, 3, 4, 0,\n",
       "          6, 5, 5, 6, 4, 2, 3, 4, 4, 5, 4, 0, 0, 5, 6, 1, 0, 3, 5, 1, 4, 3, 6, 0,\n",
       "          1, 1, 1, 0, 4, 1, 0, 4, 2, 1, 3, 1, 4, 4, 6, 4], device='cuda:0')),\n",
       " (tensor([-2.1049e-02, -8.1036e-01, -8.6287e-01, -3.4894e-03, -1.4001e-02,\n",
       "          -7.5054e-02, -3.3410e-03, -6.2118e-01, -1.2369e+00, -1.0001e+00,\n",
       "          -1.1598e+00, -1.2102e+00, -9.2187e-01, -1.2685e+00, -3.9284e-04,\n",
       "          -3.8757e-02, -1.1778e+00, -8.6529e-01, -7.6443e-01, -1.0652e+00,\n",
       "          -9.3897e-01, -7.3078e-01, -8.1852e-01, -5.1504e-01, -5.6954e-01,\n",
       "          -9.1695e-01, -1.0562e+00, -3.6288e-01, -9.5643e-01, -1.1104e+00,\n",
       "          -1.1461e+00, -1.2784e+00, -4.1159e-03, -8.4317e-01, -1.3048e-02,\n",
       "          -1.2756e+00, -6.1598e-01, -6.8950e-01, -5.1767e-01, -7.5785e-01,\n",
       "          -9.3682e-01, -5.0856e-02, -1.0013e+00, -1.1342e+00, -9.6340e-01,\n",
       "          -1.1455e+00, -9.4948e-01, -5.4876e-03, -7.9897e-01, -7.3593e-01,\n",
       "          -7.8269e-03, -8.9209e-01, -4.0405e-01, -5.2493e-01, -1.9190e-01,\n",
       "          -9.4281e-01, -1.0998e+00, -8.9660e-01, -3.6438e-01, -6.2109e-01,\n",
       "          -3.7130e-03, -1.1419e+00, -1.1825e+00, -5.0542e-01], device='cuda:0'),\n",
       "  tensor([6, 3, 0, 1, 3, 1, 0, 1, 1, 2, 4, 6, 1, 1, 4, 0, 1, 4, 1, 4, 1, 1, 3, 0,\n",
       "          1, 1, 4, 6, 4, 1, 5, 6, 0, 4, 3, 2, 6, 4, 1, 1, 0, 0, 1, 6, 4, 3, 1, 3,\n",
       "          2, 4, 0, 4, 4, 3, 6, 4, 5, 4, 6, 5, 6, 5, 4, 1], device='cuda:0')),\n",
       " (tensor([-2.5710e-04, -3.2522e-01, -7.1235e-01, -1.0681e+00, -9.8882e-02,\n",
       "          -2.8679e-03, -1.6748e-02, -8.0269e-01, -6.0249e-01, -1.4170e-03,\n",
       "          -7.6501e-01, -3.0406e-02, -6.3822e-01, -1.0840e+00, -1.0165e+00,\n",
       "          -1.1611e+00, -5.7859e-04, -3.3177e-01, -1.0778e+00, -3.3749e-01,\n",
       "          -6.6580e-03, -7.1750e-01, -7.8500e-01, -7.3159e-01, -1.2663e+00,\n",
       "          -3.1218e-01, -1.5060e-02, -8.9309e-01, -4.5087e-04, -4.9296e-02,\n",
       "          -1.1930e+00, -1.6729e-02, -9.4967e-01, -5.6697e-01, -1.1065e+00,\n",
       "          -4.3004e-02, -8.9294e-01, -1.1402e+00, -7.3444e-01, -6.8780e-01,\n",
       "          -3.7916e-01, -1.5009e+00, -1.0308e+00, -1.0977e+00, -1.1896e-04,\n",
       "          -1.1014e+00, -2.8698e-01, -1.4047e+00, -7.4970e-01, -1.0661e+00,\n",
       "          -1.2826e+00, -6.0106e-01, -9.8634e-01, -1.3001e+00, -4.2328e-01,\n",
       "          -3.0155e-01, -9.7417e-01, -1.2503e+00, -7.6830e-01, -9.3626e-01,\n",
       "          -1.1444e+00, -8.5904e-01, -1.0011e+00, -6.5624e-01], device='cuda:0'),\n",
       "  tensor([6, 0, 5, 4, 0, 2, 1, 4, 1, 0, 1, 6, 1, 2, 0, 2, 4, 4, 1, 6, 1, 1, 4, 4,\n",
       "          5, 0, 3, 0, 2, 0, 3, 3, 3, 5, 0, 6, 1, 3, 2, 1, 4, 0, 4, 4, 6, 1, 0, 1,\n",
       "          4, 1, 1, 3, 4, 1, 3, 0, 4, 4, 4, 5, 4, 1, 6, 0], device='cuda:0')),\n",
       " (tensor([-9.5221e-01, -7.8253e-03, -1.3486e+00, -5.3326e-01, -1.0217e+00,\n",
       "          -1.3732e+00, -1.2051e+00, -1.2641e+00, -9.1109e-01, -8.5806e-04,\n",
       "          -1.4015e+00, -8.4351e-01, -9.5684e-01, -1.1576e+00, -1.1615e+00,\n",
       "          -1.3216e+00, -1.4057e-03, -9.8476e-01, -8.2789e-01, -4.8062e-01,\n",
       "          -8.1078e-01, -7.9392e-01, -1.0907e+00, -3.6862e-01, -6.7643e-01,\n",
       "          -1.9785e-02, -5.8393e-01, -9.5966e-01, -5.4789e-01, -7.4160e-01,\n",
       "          -1.1083e+00, -1.7544e-03, -7.8951e-01, -8.1833e-01, -9.1970e-01,\n",
       "          -7.4441e-01, -1.7779e-01, -1.2616e+00, -9.4357e-04, -1.0424e+00,\n",
       "          -2.8031e-01, -9.7723e-01, -8.1235e-01, -8.5153e-01, -1.1778e+00,\n",
       "          -4.5167e-01, -1.0976e+00, -1.2403e+00, -2.4919e-01, -6.4079e-01,\n",
       "          -1.1717e+00, -5.9549e-01, -4.4504e-01, -1.2856e+00, -1.2340e+00,\n",
       "          -3.3415e-01, -1.0189e+00, -6.7078e-01, -8.7915e-01, -9.3008e-01,\n",
       "          -5.0520e-01, -5.1597e-01, -7.7834e-01, -4.2600e-01], device='cuda:0'),\n",
       "  tensor([5, 4, 1, 4, 3, 1, 1, 1, 1, 5, 6, 1, 2, 4, 1, 3, 4, 0, 5, 4, 4, 4, 4, 1,\n",
       "          5, 1, 5, 2, 6, 0, 4, 6, 5, 2, 4, 1, 0, 1, 4, 4, 0, 4, 1, 5, 2, 5, 4, 1,\n",
       "          4, 0, 1, 0, 4, 1, 3, 0, 4, 4, 4, 5, 0, 0, 3, 0], device='cuda:0')),\n",
       " (tensor([-7.3159e-01, -6.3973e-01, -8.6766e-01, -9.3190e-04, -7.1348e-01,\n",
       "          -2.1616e-01, -7.5434e-01, -3.4827e-02, -1.0475e+00, -5.8597e-01,\n",
       "          -3.7460e-01, -8.5565e-01, -4.9462e-01, -2.8658e-02, -4.2872e-01,\n",
       "          -7.3510e-01, -7.4951e-01, -3.1442e-01, -1.0590e-02, -1.0906e+00,\n",
       "          -8.4078e-01, -2.8417e-01, -1.0528e-03, -9.3039e-02, -1.0315e-02,\n",
       "          -1.2021e+00, -1.3114e+00, -4.2787e-04, -9.1020e-01, -7.3792e-01,\n",
       "          -7.3000e-01, -4.9695e-02, -7.8529e-01, -4.1101e-03, -2.5216e-01,\n",
       "          -4.6105e-02, -1.1183e+00, -2.5786e-01, -1.7974e-01, -8.7026e-01,\n",
       "          -1.5067e-03, -1.2960e+00, -7.0238e-01, -6.9700e-01, -1.1905e-01,\n",
       "          -1.0734e+00, -2.1463e-03, -4.6832e-01, -1.0613e+00, -6.6710e-01,\n",
       "          -2.8225e-04, -1.1629e+00, -5.4504e-01, -1.0706e+00, -5.6730e-01,\n",
       "          -1.2459e+00, -4.0285e-04, -2.4082e-01, -7.8962e-01, -1.0240e-04,\n",
       "          -7.7872e-01, -7.9342e-01, -1.2385e+00, -6.6185e-01], device='cuda:0'),\n",
       "  tensor([1, 4, 1, 6, 5, 0, 5, 1, 1, 4, 0, 1, 0, 6, 5, 5, 4, 5, 6, 1, 3, 0, 6, 6,\n",
       "          5, 5, 1, 4, 5, 2, 1, 3, 2, 6, 0, 3, 1, 2, 0, 1, 2, 1, 4, 5, 6, 0, 3, 0,\n",
       "          4, 4, 4, 2, 6, 1, 4, 4, 4, 4, 0, 4, 5, 5, 2, 0], device='cuda:0')),\n",
       " (tensor([-5.7014e-01, -1.0798e+00, -1.0542e+00, -1.4803e+00, -6.4488e-03,\n",
       "          -4.7859e-01, -1.6144e-01, -2.9998e-01, -1.3565e+00, -1.9222e-01,\n",
       "          -3.3008e-02, -7.5173e-01, -9.0430e-01, -8.9697e-01, -2.2394e-01,\n",
       "          -2.9750e-01, -1.0718e+00, -5.8125e-01, -1.1525e+00, -1.0171e+00,\n",
       "          -5.2353e-01, -6.8012e-01, -7.6503e-01, -3.5004e-03, -9.8181e-01,\n",
       "          -1.2476e+00, -6.3164e-01, -4.3637e-02, -3.1937e-01, -1.5949e-01,\n",
       "          -3.1158e-01, -7.6895e-01, -7.6340e-01, -1.1762e-02, -1.1943e+00,\n",
       "          -6.4493e-02, -2.0270e-02, -6.8762e-01, -2.5234e-01, -1.0308e+00,\n",
       "          -9.3708e-01, -9.0721e-01, -7.6990e-01, -9.5531e-01, -1.4214e+00,\n",
       "          -1.0947e+00, -9.6595e-01, -1.2198e-01, -1.4777e-03, -6.2645e-01,\n",
       "          -1.2598e+00, -6.4387e-01, -7.2594e-01, -4.0482e-01, -4.9793e-01,\n",
       "          -1.1538e+00, -1.4973e-01, -8.4994e-01, -9.1201e-01, -9.8730e-01,\n",
       "          -2.4614e-02, -7.0271e-01, -1.1346e-01, -5.1493e-01], device='cuda:0'),\n",
       "  tensor([4, 2, 4, 1, 0, 0, 1, 6, 4, 0, 3, 1, 2, 5, 4, 2, 1, 6, 1, 2, 0, 4, 3, 6,\n",
       "          3, 4, 0, 5, 5, 6, 2, 3, 1, 2, 0, 6, 6, 0, 0, 4, 3, 2, 0, 2, 3, 3, 2, 6,\n",
       "          1, 4, 4, 4, 2, 4, 4, 3, 0, 3, 1, 5, 6, 5, 6, 5], device='cuda:0')),\n",
       " (tensor([-5.7344e-01, -5.0129e-03, -1.2729e+00, -1.7118e-02, -6.1747e-01,\n",
       "          -6.8707e-01, -1.4097e-01, -6.8174e-01, -8.4829e-01, -3.3381e-01,\n",
       "          -7.6076e-01, -1.1431e+00, -7.1719e-01, -3.7592e-01, -8.7082e-01,\n",
       "          -8.0477e-01, -4.3249e-01, -4.1412e-03, -1.0895e+00, -8.0174e-01,\n",
       "          -2.9092e-03, -1.5513e-03, -1.0789e-03, -8.4781e-01, -7.1881e-05,\n",
       "          -6.5801e-05, -1.1435e+00, -4.2772e-01, -1.0815e+00, -8.2839e-02,\n",
       "          -1.0126e-01, -1.0561e+00, -5.5602e-01, -5.2755e-01, -5.1010e-03,\n",
       "          -5.3499e-04, -7.6956e-04, -8.1171e-02, -5.7319e-01, -7.9921e-01,\n",
       "          -1.8724e-01, -1.0140e+00, -8.8476e-01, -1.0889e+00, -1.0503e+00,\n",
       "          -5.3606e-01, -1.6439e-03, -1.2066e+00, -7.4184e-01, -9.0452e-01,\n",
       "          -9.3300e-01, -6.0278e-01, -2.5803e-01, -1.4390e+00, -8.2702e-02,\n",
       "          -1.5422e-02, -8.2840e-01, -8.5018e-03, -1.1275e+00, -7.3462e-01,\n",
       "          -8.6093e-01, -1.2601e+00, -1.1056e+00, -1.3169e+00], device='cuda:0'),\n",
       "  tensor([5, 6, 4, 5, 6, 2, 0, 2, 1, 0, 5, 2, 1, 4, 4, 5, 1, 2, 1, 4, 1, 5, 2, 6,\n",
       "          6, 6, 4, 0, 6, 6, 0, 5, 5, 4, 6, 6, 4, 6, 4, 3, 6, 1, 4, 3, 4, 4, 6, 4,\n",
       "          5, 4, 1, 4, 6, 1, 6, 2, 4, 6, 4, 4, 3, 3, 4, 1], device='cuda:0')),\n",
       " (tensor([-1.2410e+00, -1.3105e+00, -4.7274e-01, -9.1731e-01, -1.0663e+00,\n",
       "          -8.9609e-03, -1.0839e+00, -8.3565e-01, -2.8949e-01, -8.6013e-03,\n",
       "          -1.6996e-02, -6.7726e-01, -2.6604e-04, -8.0310e-03, -2.4136e-02,\n",
       "          -7.4228e-04, -2.8782e-03, -6.7778e-01, -1.3175e+00, -1.2521e+00,\n",
       "          -2.4030e-02, -9.7908e-01, -3.7399e-01, -1.0933e+00, -4.0538e-03,\n",
       "          -9.2228e-01, -1.7221e-01, -6.3432e-02, -2.4806e-03, -1.9361e-02,\n",
       "          -2.8042e-03, -7.6817e-01, -7.4728e-04, -1.0407e+00, -6.0555e-01,\n",
       "          -5.7512e-01, -6.7905e-01, -1.1269e+00, -1.9305e-03, -8.5425e-01,\n",
       "          -9.9704e-01, -7.8632e-01, -1.1352e+00, -7.6994e-01, -1.3247e+00,\n",
       "          -8.4520e-01, -1.0006e+00, -1.2664e+00, -9.4847e-01, -1.5413e-02,\n",
       "          -3.5776e-03, -1.1194e+00, -1.0025e+00, -6.8834e-01, -1.1825e+00,\n",
       "          -1.2039e+00, -6.2977e-01, -9.6552e-01, -6.9379e-01, -3.6602e-04,\n",
       "          -1.2472e+00, -1.6102e-01, -4.6404e-01, -4.1649e-01], device='cuda:0'),\n",
       "  tensor([1, 5, 0, 5, 3, 3, 4, 5, 2, 1, 6, 4, 4, 6, 0, 4, 6, 3, 4, 1, 1, 6, 3, 4,\n",
       "          1, 4, 6, 6, 1, 6, 5, 5, 2, 3, 0, 5, 1, 4, 6, 0, 5, 6, 4, 2, 4, 5, 5, 5,\n",
       "          4, 4, 6, 4, 0, 4, 0, 5, 5, 2, 0, 5, 4, 1, 3, 0], device='cuda:0')),\n",
       " (tensor([-7.4452e-01, -9.3300e-01, -9.5483e-01, -7.9951e-01, -3.8699e-03,\n",
       "          -3.3155e-01, -9.6462e-01, -5.6850e-01, -5.2372e-03, -5.4137e-01,\n",
       "          -5.7931e-01, -6.5444e-05, -1.4307e-01, -3.2615e-03, -7.5624e-01,\n",
       "          -8.1703e-01, -7.7876e-01, -7.1485e-01, -1.1800e+00, -8.9995e-01,\n",
       "          -9.4573e-01, -1.0364e+00, -1.1132e+00, -8.5807e-02, -1.2083e+00,\n",
       "          -1.3730e+00, -3.5409e-01, -5.9601e-01, -5.4113e-01, -4.9573e-02,\n",
       "          -4.3381e-03, -1.1318e+00, -3.5488e-02, -9.3934e-01, -5.0709e-01,\n",
       "          -1.5228e-01, -1.0794e+00, -4.1786e-04, -2.3680e-01, -7.8394e-01,\n",
       "          -4.3704e-04, -2.5246e-03, -2.6802e-01, -7.7949e-02, -1.0138e+00,\n",
       "          -9.9511e-01, -3.0259e-02, -1.3352e-01, -5.8859e-01, -1.1607e+00,\n",
       "          -1.1243e-02, -1.2691e+00, -4.7181e-01, -4.7792e-04, -9.4444e-01,\n",
       "          -9.0790e-01, -9.4625e-01, -1.2913e+00, -3.2708e-01, -1.0816e+00,\n",
       "          -5.9353e-01, -2.0646e-01, -5.5061e-01, -8.2267e-01], device='cuda:0'),\n",
       "  tensor([5, 1, 4, 4, 3, 0, 3, 6, 1, 4, 5, 6, 6, 4, 1, 2, 4, 0, 0, 5, 5, 1, 3, 4,\n",
       "          1, 4, 3, 5, 5, 0, 2, 5, 2, 5, 4, 1, 1, 4, 6, 5, 4, 6, 4, 6, 4, 4, 3, 0,\n",
       "          4, 3, 0, 2, 5, 4, 1, 4, 5, 4, 0, 2, 5, 0, 5, 5], device='cuda:0')),\n",
       " (tensor([-2.8724e-01, -7.3792e-02, -9.9455e-01, -7.6082e-01, -1.0565e+00,\n",
       "          -2.3993e-03, -9.2207e-01, -3.5341e-01, -5.3765e-01, -9.5687e-01,\n",
       "          -9.0325e-01, -1.0298e+00, -9.0206e-01, -5.2416e-01, -1.4347e-02,\n",
       "          -1.0686e+00, -7.3909e-01, -8.5019e-01, -1.8910e-03, -1.2317e+00,\n",
       "          -1.6571e-01, -5.9365e-01, -1.1003e+00, -8.5070e-01, -8.7889e-01,\n",
       "          -6.8661e-01, -3.5605e-01, -9.8348e-01, -7.0852e-01, -1.5592e-02,\n",
       "          -8.7662e-01, -9.0563e-01, -1.2639e+00, -1.5162e-02, -1.1101e+00,\n",
       "          -1.5116e-03, -2.1289e-01, -7.7190e-01, -3.7031e-04, -1.4718e+00,\n",
       "          -7.6788e-01, -1.1675e+00, -7.3741e-01, -7.6051e-01, -8.8868e-01,\n",
       "          -8.8244e-03, -2.7929e-01, -1.8229e-02, -9.1078e-01, -1.0436e+00,\n",
       "          -1.2038e+00, -1.0681e+00, -1.1361e+00, -1.5588e-03, -2.5814e-02,\n",
       "          -5.1227e-02, -6.6116e-01, -8.4473e-01, -5.0073e-01, -9.2573e-01,\n",
       "          -1.7619e-01, -7.2719e-01, -5.7168e-01, -2.8355e-01], device='cuda:0'),\n",
       "  tensor([4, 1, 4, 5, 5, 5, 4, 0, 2, 3, 5, 1, 5, 3, 4, 4, 1, 4, 5, 2, 0, 4, 2, 5,\n",
       "          5, 3, 5, 1, 2, 6, 0, 4, 3, 0, 3, 0, 0, 4, 4, 4, 0, 1, 5, 5, 5, 4, 0, 0,\n",
       "          2, 4, 3, 0, 3, 5, 1, 1, 4, 0, 5, 4, 2, 5, 4, 0], device='cuda:0')),\n",
       " (tensor([-1.0207e+00, -1.4028e+00, -8.8577e-01, -4.6034e-01, -3.5908e-03,\n",
       "          -1.1336e-03, -1.0067e+00, -8.5968e-01, -1.0154e+00, -1.4398e+00,\n",
       "          -1.3493e+00, -1.1881e+00, -1.0655e+00, -1.0166e-02, -1.2150e+00,\n",
       "          -1.3505e+00, -1.0191e-01, -9.1180e-01, -7.6252e-01, -6.5820e-01,\n",
       "          -1.1913e+00, -2.1821e-02, -1.0408e+00, -5.9429e-01, -9.7713e-01,\n",
       "          -8.8743e-01, -1.2739e+00, -8.0741e-01, -7.0296e-03, -9.2071e-04,\n",
       "          -1.1392e+00, -9.7148e-01, -1.1580e+00, -5.8937e-01, -1.1729e+00,\n",
       "          -9.3229e-01, -2.5066e-03, -1.0372e+00, -1.1563e+00, -6.0780e-02,\n",
       "          -3.3841e-02, -4.1116e-01, -7.4460e-01, -1.3002e+00, -1.0171e+00,\n",
       "          -1.1031e+00, -4.1221e-01, -4.3546e-03, -7.9914e-01, -7.6117e-01,\n",
       "          -6.1723e-01, -2.4733e-04, -9.8809e-01, -1.0176e+00, -1.0405e+00,\n",
       "          -1.0911e-01, -1.5812e-02, -3.7696e-01, -1.1130e+00, -2.4372e-03,\n",
       "          -9.5778e-03, -4.1832e-01, -4.3997e-01, -9.1486e-01], device='cuda:0'),\n",
       "  tensor([1, 4, 0, 3, 2, 6, 4, 1, 2, 4, 1, 5, 2, 6, 4, 6, 0, 4, 1, 1, 1, 6, 2, 0,\n",
       "          3, 4, 5, 5, 6, 4, 4, 3, 0, 2, 2, 4, 6, 6, 4, 5, 6, 1, 0, 3, 4, 1, 4, 6,\n",
       "          3, 0, 5, 4, 4, 5, 5, 3, 0, 0, 3, 6, 6, 0, 0, 4], device='cuda:0')),\n",
       " (tensor([-6.9661e-01, -1.2311e+00, -6.2172e-01, -3.2075e-01, -1.0108e+00,\n",
       "          -1.0628e+00, -1.0171e+00, -3.8088e-02, -1.1570e+00, -8.2607e-01,\n",
       "          -2.9393e-03, -5.1370e-01, -1.0664e+00, -1.0276e+00, -3.8586e-01,\n",
       "          -9.6022e-01, -8.7964e-01, -9.5421e-01, -1.0660e+00, -4.4108e-01,\n",
       "          -1.0511e+00, -2.1153e-03, -1.2317e+00, -1.1575e+00, -1.7034e-04,\n",
       "          -8.1865e-01, -7.4963e-01, -1.0742e+00, -3.4278e-01, -6.9330e-01,\n",
       "          -5.2310e-01, -1.2309e-01, -6.6889e-01, -9.3942e-01, -2.7855e-04,\n",
       "          -5.3809e-04, -7.2913e-01, -3.4229e-01, -8.2539e-01, -2.0745e-01,\n",
       "          -7.1382e-01, -7.6963e-02, -1.3694e+00, -4.7883e-02, -4.3254e-01,\n",
       "          -1.0862e+00, -1.1491e+00, -1.1682e+00, -1.2719e+00, -8.6855e-03,\n",
       "          -6.0899e-01, -6.5520e-04, -1.2195e+00, -9.1927e-01, -7.1952e-02,\n",
       "          -3.3409e-04, -1.4020e+00, -1.0953e+00, -5.4291e-01, -6.7855e-01,\n",
       "          -4.8041e-01, -7.2401e-02, -8.3393e-03, -4.5835e-01], device='cuda:0'),\n",
       "  tensor([4, 4, 0, 1, 4, 3, 4, 6, 4, 0, 6, 3, 1, 1, 1, 3, 6, 5, 4, 5, 4, 5, 1, 0,\n",
       "          4, 1, 5, 6, 1, 5, 0, 1, 1, 5, 6, 4, 3, 4, 6, 0, 5, 1, 4, 6, 5, 4, 6, 4,\n",
       "          3, 0, 0, 5, 2, 1, 6, 6, 3, 1, 4, 4, 0, 2, 1, 0], device='cuda:0')),\n",
       " (tensor([-1.0509, -0.7728, -0.0860, -1.1738, -1.2642, -1.3161, -0.7534, -0.3164,\n",
       "          -0.9200, -0.6764, -0.0015, -0.9899, -0.2011, -1.1194, -1.1040, -0.9380,\n",
       "          -0.5521, -1.2967, -0.0128, -1.0099, -0.9055, -0.2686, -1.1105, -0.6077,\n",
       "          -0.4910, -0.0015, -0.7745, -0.5897, -1.2067, -1.1172, -0.8884, -1.0027,\n",
       "          -1.1401, -1.0250, -0.0029, -1.1295, -0.0126, -1.0646, -1.0629, -0.5574,\n",
       "          -1.0014, -0.4351, -0.9592, -0.9608, -0.6359, -0.2274, -1.1564, -1.3187,\n",
       "          -0.8790, -0.5259, -1.1121, -0.5660, -0.0904, -0.0018, -1.0674, -0.0015,\n",
       "          -1.2052, -0.0015, -0.9518, -0.2990, -0.1224, -0.6018, -0.9954, -1.1276],\n",
       "         device='cuda:0'),\n",
       "  tensor([0, 1, 0, 4, 0, 4, 4, 1, 1, 2, 2, 2, 0, 5, 4, 1, 2, 2, 6, 4, 5, 0, 1, 4,\n",
       "          5, 6, 0, 4, 5, 1, 4, 0, 1, 2, 2, 1, 5, 6, 3, 2, 4, 0, 4, 1, 3, 6, 3, 4,\n",
       "          5, 2, 1, 0, 4, 6, 2, 6, 4, 6, 4, 0, 4, 0, 4, 4], device='cuda:0')),\n",
       " (tensor([-4.8498e-03, -2.5785e-01, -7.3096e-04, -9.7449e-01, -7.7294e-01,\n",
       "          -1.7153e-01, -1.3972e+00, -1.4528e+00, -1.0669e-04, -8.9649e-01,\n",
       "          -3.6087e-01, -1.2239e+00, -7.6727e-01, -7.9510e-01, -5.3193e-01,\n",
       "          -1.7881e-02, -8.4606e-01, -1.4737e-03, -8.0249e-01, -2.0080e-01,\n",
       "          -4.3062e-01, -1.1348e+00, -1.0819e-02, -6.6441e-01, -7.9296e-01,\n",
       "          -4.5121e-01, -5.9813e-03, -5.9636e-01, -6.5282e-04, -1.6192e-01,\n",
       "          -1.1940e+00, -1.0284e+00, -5.9266e-01, -1.6642e-03, -1.2469e-04,\n",
       "          -7.8379e-01, -1.7525e-02, -1.0927e+00, -1.0404e+00, -1.3074e+00,\n",
       "          -9.0917e-02, -9.7281e-01, -5.0253e-01, -8.9045e-05, -5.8957e-01,\n",
       "          -1.7198e-03, -1.8891e-02, -4.7451e-01, -9.6521e-01, -2.7094e-01,\n",
       "          -6.4589e-01, -1.0996e+00, -5.0872e-01, -2.6170e-01, -1.0393e+00,\n",
       "          -8.2386e-03, -9.1228e-01, -1.3876e+00, -9.6191e-02, -1.0455e+00,\n",
       "          -1.3396e+00, -1.3094e+00, -4.1882e-01, -3.5156e-01], device='cuda:0'),\n",
       "  tensor([1, 6, 5, 1, 4, 6, 1, 4, 6, 0, 6, 4, 0, 5, 0, 1, 3, 6, 4, 6, 5, 4, 1, 5,\n",
       "          5, 5, 1, 5, 6, 0, 2, 6, 5, 5, 4, 0, 6, 3, 1, 3, 3, 0, 2, 6, 0, 1, 2, 3,\n",
       "          2, 5, 2, 0, 0, 0, 4, 6, 4, 4, 6, 4, 4, 3, 4, 4], device='cuda:0')),\n",
       " (tensor([-9.9629e-01, -5.7448e-01, -1.0102e+00, -3.8015e-03, -2.7032e-02,\n",
       "          -1.0459e-01, -8.0730e-01, -3.3418e-01, -8.4990e-01, -3.5556e-01,\n",
       "          -2.9512e-02, -1.2086e+00, -4.2655e-01, -8.7707e-01, -7.9317e-01,\n",
       "          -1.2032e+00, -1.1187e+00, -9.5619e-01, -3.3166e-03, -9.6847e-01,\n",
       "          -5.1018e-01, -2.4141e-03, -6.8533e-01, -1.3863e+00, -7.4566e-01,\n",
       "          -6.1485e-01, -1.3968e+00, -1.2047e+00, -4.9438e-01, -1.0272e+00,\n",
       "          -6.5394e-01, -9.3184e-02, -1.1100e+00, -1.4255e+00, -1.2524e+00,\n",
       "          -5.1505e-01, -6.7606e-01, -2.3243e-04, -1.1277e-04, -1.1679e+00,\n",
       "          -1.0111e+00, -1.0283e+00, -1.0581e+00, -5.9343e-01, -2.4494e-03,\n",
       "          -1.1330e-03, -8.4722e-01, -5.5904e-01, -1.0979e+00, -9.9762e-01,\n",
       "          -8.9262e-02, -8.0483e-01, -1.4585e+00, -9.9264e-01, -1.0212e+00,\n",
       "          -9.2929e-01, -6.7252e-01, -8.6968e-01, -9.7305e-03, -1.1484e-02,\n",
       "          -1.8193e-01, -9.0948e-01, -1.0124e+00, -1.2420e+00], device='cuda:0'),\n",
       "  tensor([2, 5, 0, 2, 1, 6, 3, 6, 4, 5, 6, 2, 0, 0, 4, 4, 2, 4, 2, 1, 2, 6, 1, 4,\n",
       "          5, 1, 3, 1, 1, 5, 6, 6, 1, 6, 1, 5, 4, 4, 2, 4, 1, 5, 0, 0, 4, 6, 3, 4,\n",
       "          2, 2, 5, 5, 6, 4, 6, 1, 1, 3, 0, 6, 0, 3, 1, 5], device='cuda:0')),\n",
       " (tensor([-1.1870e+00, -6.6470e-01, -9.3215e-02, -6.4039e-01, -1.0094e+00,\n",
       "          -8.9789e-01, -4.0422e-01, -1.0507e+00, -1.0574e+00, -1.7022e-01,\n",
       "          -1.8451e-01, -8.3846e-01, -1.1113e+00, -1.5063e-01, -4.0015e-01,\n",
       "          -4.3688e-01, -3.7209e-01, -7.2161e-01, -9.2769e-01, -9.8922e-02,\n",
       "          -6.6586e-01, -1.8215e-03, -3.7488e-03, -1.3308e+00, -2.4494e-01,\n",
       "          -5.1803e-01, -6.3915e-01, -3.3250e-01, -9.5048e-04, -1.1007e+00,\n",
       "          -9.0621e-01, -9.0296e-01, -8.0937e-01, -1.0716e-04, -8.1908e-01,\n",
       "          -1.0462e+00, -1.2016e-04, -3.3459e-01, -4.0288e-01, -1.4192e-01,\n",
       "          -1.2020e+00, -1.3734e+00, -9.8691e-01, -7.8134e-03, -3.7970e-01,\n",
       "          -8.5202e-01, -5.1983e-03, -2.7011e-01, -2.6592e-04, -8.9149e-01,\n",
       "          -7.5005e-01, -1.0790e+00, -6.2683e-01, -4.0958e-01, -3.0331e-01,\n",
       "          -1.4508e+00, -1.0212e+00, -9.4779e-01, -1.0758e+00, -8.7843e-01,\n",
       "          -1.3985e+00, -2.9958e-03, -1.0299e+00, -7.9338e-01], device='cuda:0'),\n",
       "  tensor([5, 5, 0, 3, 2, 1, 4, 1, 4, 1, 0, 0, 4, 6, 5, 4, 0, 4, 5, 6, 2, 2, 6, 1,\n",
       "          1, 0, 4, 2, 6, 4, 4, 3, 6, 2, 4, 3, 2, 4, 1, 0, 3, 1, 4, 6, 5, 1, 4, 0,\n",
       "          4, 4, 0, 0, 5, 6, 6, 3, 2, 3, 5, 0, 1, 6, 0, 4], device='cuda:0')),\n",
       " (tensor([-4.6673e-03, -3.2057e-01, -4.4101e-01, -9.7488e-01, -3.2016e-03,\n",
       "          -1.4328e+00, -1.2645e+00, -7.9755e-01, -9.0777e-01, -2.4674e-03,\n",
       "          -3.2498e-01, -7.4044e-01, -5.8227e-01, -4.1635e-01, -2.4812e-01,\n",
       "          -1.2504e+00, -5.1785e-01, -1.2113e+00, -1.2465e+00, -1.0970e+00,\n",
       "          -7.0684e-01, -9.3143e-03, -1.1885e+00, -1.2826e+00, -1.4587e-03,\n",
       "          -5.6963e-01, -8.5200e-01, -1.1500e+00, -5.3244e-01, -3.6433e-01,\n",
       "          -8.3907e-01, -1.3833e+00, -6.4702e-01, -1.3675e-01, -1.1069e+00,\n",
       "          -1.1202e+00, -1.0944e+00, -7.3922e-01, -1.0516e+00, -1.3019e+00,\n",
       "          -4.7278e-01, -3.1755e-01, -3.8014e-01, -1.7153e-03, -1.3377e+00,\n",
       "          -1.4590e-03, -2.4491e-01, -6.3493e-01, -9.8052e-01, -1.0049e+00,\n",
       "          -1.6383e-03, -1.1313e+00, -6.3973e-01, -7.6667e-01, -1.9459e-03,\n",
       "          -5.4466e-01, -1.0343e+00, -1.2750e+00, -8.1736e-01, -1.0473e+00,\n",
       "          -5.7000e-01, -1.0354e+00, -7.6551e-04, -6.8817e-01], device='cuda:0'),\n",
       "  tensor([6, 4, 0, 4, 1, 4, 4, 1, 1, 5, 0, 0, 5, 0, 4, 1, 4, 1, 3, 1, 1, 6, 4, 4,\n",
       "          3, 1, 5, 4, 4, 5, 1, 4, 0, 6, 1, 0, 3, 3, 4, 3, 0, 5, 4, 5, 1, 2, 0, 5,\n",
       "          3, 4, 6, 0, 4, 4, 3, 5, 4, 1, 0, 1, 0, 3, 5, 3], device='cuda:0')),\n",
       " (tensor([-1.2978e+00, -1.0431e+00, -6.7870e-01, -3.7305e-01, -1.0973e+00,\n",
       "          -1.0346e+00, -5.6734e-01, -1.3394e-01, -1.4305e+00, -1.2281e+00,\n",
       "          -5.6623e-01, -7.1097e-02, -6.3488e-01, -2.5150e-04, -6.2463e-01,\n",
       "          -1.3680e+00, -1.2905e+00, -4.2937e-01, -8.7561e-01, -1.1863e+00,\n",
       "          -9.0782e-01, -3.4076e-04, -3.4749e-01, -3.0565e-03, -1.0816e+00,\n",
       "          -1.0069e+00, -1.0696e+00, -2.4679e-01, -7.0568e-01, -5.1028e-01,\n",
       "          -5.8548e-01, -2.6470e-01, -1.2134e+00, -2.4125e-04, -4.8478e-02,\n",
       "          -4.0554e-01, -2.0418e-03, -4.6253e-01, -1.7400e-01, -1.1400e+00,\n",
       "          -6.1675e-03, -2.5214e-01, -1.1696e+00, -1.3093e+00, -5.2788e-01,\n",
       "          -1.0899e+00, -4.4174e-03, -1.4328e+00, -8.9526e-01, -8.4041e-01,\n",
       "          -3.5477e-03, -1.1625e+00, -9.0579e-01, -1.2395e+00, -6.8146e-01,\n",
       "          -1.2538e+00, -1.1922e+00, -2.9995e-01, -9.9783e-01, -1.1108e+00,\n",
       "          -6.8005e-02, -7.0181e-01, -4.4832e-03, -1.0620e+00], device='cuda:0'),\n",
       "  tensor([3, 6, 2, 0, 5, 0, 1, 6, 3, 0, 0, 6, 2, 4, 4, 3, 3, 0, 0, 0, 4, 4, 5, 1,\n",
       "          1, 0, 4, 3, 2, 4, 5, 0, 3, 4, 3, 6, 5, 5, 4, 2, 6, 0, 1, 6, 5, 4, 3, 4,\n",
       "          1, 2, 1, 4, 6, 1, 5, 5, 4, 6, 3, 3, 3, 5, 6, 4], device='cuda:0')),\n",
       " (tensor([-1.6893e-03, -8.0030e-03, -1.3032e+00, -1.1735e+00, -1.3157e+00,\n",
       "          -1.6254e-02, -5.1217e-01, -5.6012e-01, -1.1395e+00, -5.7997e-01,\n",
       "          -1.4278e-01, -1.2940e-03, -4.1128e-03, -1.5191e+00, -1.1972e+00,\n",
       "          -7.6454e-02, -1.0611e+00, -1.2966e+00, -9.3998e-01, -1.1748e+00,\n",
       "          -1.2588e+00, -1.2666e-03, -6.3453e-02, -5.3093e-01, -1.2553e+00,\n",
       "          -3.7087e-02, -8.0725e-01, -1.0380e+00, -4.5116e-01, -6.7875e-01,\n",
       "          -1.2901e+00, -1.0283e+00, -7.6858e-01, -4.9778e-01, -5.7798e-01,\n",
       "          -6.0859e-01, -5.0670e-01, -4.6633e-03, -1.0308e+00, -8.4143e-01,\n",
       "          -9.2441e-01, -2.2136e-02, -9.7594e-01, -1.0251e+00, -9.7163e-01,\n",
       "          -1.2232e+00, -7.3759e-01, -9.6116e-01, -9.2408e-01, -1.3293e+00,\n",
       "          -3.5034e-03, -1.4355e+00, -7.2662e-02, -9.1018e-01, -1.6502e-02,\n",
       "          -1.1514e+00, -8.4411e-01, -4.3595e-02, -2.0652e-01, -9.8986e-03,\n",
       "          -8.4303e-01, -5.9716e-01, -3.3329e-03, -1.5300e+00], device='cuda:0'),\n",
       "  tensor([5, 6, 0, 5, 3, 6, 0, 5, 4, 5, 3, 6, 6, 3, 6, 0, 3, 3, 5, 2, 3, 5, 6, 5,\n",
       "          3, 2, 4, 4, 6, 1, 0, 4, 4, 4, 1, 3, 1, 6, 4, 4, 2, 6, 2, 3, 3, 4, 2, 1,\n",
       "          5, 3, 3, 2, 6, 6, 6, 2, 3, 5, 6, 5, 0, 5, 0, 4], device='cuda:0')),\n",
       " (tensor([-3.9012e-01, -8.4560e-01, -7.6933e-01, -1.1096e+00, -4.5763e-02,\n",
       "          -1.4078e-04, -1.1083e+00, -3.3337e-04, -1.1023e+00, -6.6741e-01,\n",
       "          -1.0240e-01, -5.1831e-03, -1.5024e+00, -7.1612e-01, -5.4230e-01,\n",
       "          -1.9939e-01, -6.5961e-04, -9.7276e-01, -1.7276e-03, -3.9782e-03,\n",
       "          -1.0951e+00, -9.9811e-01, -5.5259e-01, -9.5629e-01, -8.9384e-01,\n",
       "          -7.0678e-01, -9.5245e-01, -1.1921e-02, -8.1390e-01, -1.0633e+00,\n",
       "          -1.3480e+00, -6.4264e-01, -8.8950e-01, -7.2608e-01, -9.2144e-01,\n",
       "          -7.7355e-01, -1.2752e+00, -8.1266e-01, -3.4183e-01, -1.0410e+00,\n",
       "          -7.0742e-01, -8.0243e-01, -6.1415e-01, -5.8593e-01, -9.1689e-04,\n",
       "          -6.0027e-01, -1.2497e+00, -5.3654e-02, -5.3117e-01, -9.3085e-01,\n",
       "          -8.4269e-01, -1.1116e+00, -1.0533e-02, -4.1673e-01, -9.9895e-01,\n",
       "          -1.1093e+00, -1.0746e+00, -1.0559e+00, -1.3445e+00, -1.3853e+00,\n",
       "          -9.6217e-01, -9.4084e-01, -3.9530e-01, -4.1326e-01], device='cuda:0'),\n",
       "  tensor([5, 4, 5, 6, 6, 6, 4, 6, 4, 4, 6, 5, 4, 6, 5, 0, 6, 1, 0, 6, 5, 2, 2, 4,\n",
       "          1, 1, 1, 3, 0, 4, 4, 5, 2, 1, 0, 1, 3, 1, 4, 4, 6, 4, 4, 4, 6, 2, 4, 0,\n",
       "          5, 4, 4, 3, 6, 4, 4, 5, 6, 4, 4, 3, 5, 0, 0, 4], device='cuda:0')),\n",
       " (tensor([-9.9465e-01, -9.0106e-01, -2.5385e-01, -4.4647e-01, -7.7266e-01,\n",
       "          -5.8020e-01, -9.5565e-01, -9.2139e-01, -4.8385e-01, -3.8496e-03,\n",
       "          -1.2322e+00, -1.6010e-03, -4.5580e-01, -6.9695e-01, -1.4395e-03,\n",
       "          -7.4661e-01, -3.1419e-04, -1.0845e+00, -9.5985e-01, -1.2821e+00,\n",
       "          -1.2172e+00, -1.0718e+00, -1.1183e+00, -1.1690e+00, -2.7384e-01,\n",
       "          -1.2968e+00, -5.0997e-01, -6.9448e-01, -4.4763e-01, -1.2280e+00,\n",
       "          -6.2111e-01, -3.3090e-01, -1.9899e-03, -1.0056e+00, -3.8857e-01,\n",
       "          -3.8450e-04, -1.1574e+00, -9.2474e-01, -1.0850e+00, -7.0000e-01,\n",
       "          -9.1863e-01, -5.0967e-01, -5.2645e-01, -6.3122e-01, -1.1284e+00,\n",
       "          -6.8397e-01, -9.4832e-01, -1.7936e-03, -8.9936e-01, -1.2716e-01,\n",
       "          -6.2268e-02, -2.7341e-01, -9.3053e-01, -4.5905e-01, -9.5766e-01,\n",
       "          -1.1407e+00, -1.1079e+00, -2.5727e-01, -9.7753e-01, -9.2041e-01,\n",
       "          -1.0764e+00, -7.1578e-03, -9.9963e-01, -1.5034e-01], device='cuda:0'),\n",
       "  tensor([2, 0, 4, 0, 5, 0, 2, 1, 5, 1, 4, 0, 5, 1, 2, 1, 4, 5, 4, 3, 1, 4, 3, 5,\n",
       "          4, 5, 2, 0, 2, 1, 1, 0, 3, 4, 4, 6, 4, 4, 5, 1, 4, 5, 0, 4, 2, 4, 0, 1,\n",
       "          3, 6, 6, 0, 0, 0, 5, 1, 4, 0, 3, 4, 5, 6, 4, 6], device='cuda:0')),\n",
       " (tensor([-1.0217e+00, -7.8609e-01, -9.3988e-01, -1.1741e+00, -8.6261e-01,\n",
       "          -1.3622e+00, -9.8717e-01, -1.0750e+00, -2.0082e-03, -8.1137e-01,\n",
       "          -1.1235e+00, -5.5216e-01, -7.9134e-01, -8.7656e-01, -7.0685e-01,\n",
       "          -1.1732e+00, -4.7924e-01, -8.3203e-01, -1.3792e+00, -2.8404e-01,\n",
       "          -8.9356e-01, -5.4009e-01, -7.8401e-01, -1.2034e+00, -7.4370e-01,\n",
       "          -5.6130e-01, -1.0194e+00, -4.6339e-01, -9.3177e-01, -1.2551e+00,\n",
       "          -1.6586e-03, -8.6590e-01, -3.8336e-01, -1.1432e+00, -7.3629e-01,\n",
       "          -2.7125e-01, -1.2391e+00, -3.3403e-01, -1.0406e+00, -5.8678e-01,\n",
       "          -2.2732e-02, -1.4949e+00, -5.5621e-01, -6.5038e-01, -6.5555e-02,\n",
       "          -1.6324e+00, -1.0892e+00, -7.1192e-01, -1.1985e-01, -1.2220e+00,\n",
       "          -5.1164e-01, -5.0931e-03, -1.2312e+00, -7.7935e-01, -5.6913e-01,\n",
       "          -7.1137e-03, -1.2446e+00, -3.8759e-04, -7.3147e-01, -2.8024e-03,\n",
       "          -3.3719e-04, -1.2663e+00, -9.4810e-04, -9.8240e-01], device='cuda:0'),\n",
       "  tensor([1, 2, 0, 1, 5, 1, 1, 4, 4, 6, 4, 0, 4, 0, 4, 1, 5, 3, 4, 6, 5, 0, 1, 4,\n",
       "          0, 5, 2, 0, 1, 0, 6, 4, 0, 3, 5, 6, 6, 0, 1, 5, 6, 5, 6, 0, 6, 3, 5, 4,\n",
       "          6, 3, 4, 6, 3, 4, 1, 6, 4, 6, 5, 6, 2, 2, 5, 3], device='cuda:0')),\n",
       " (tensor([-1.0717e+00, -3.5678e-03, -9.5095e-01, -2.8430e-03, -1.0328e+00,\n",
       "          -5.7693e-04, -5.4738e-01, -7.6609e-01, -7.0998e-01, -3.3697e-01,\n",
       "          -1.7180e-02, -8.4234e-01, -4.4054e-01, -6.6720e-01, -7.7713e-01,\n",
       "          -1.2206e-03, -1.0377e+00, -6.8441e-01, -8.5211e-01, -8.4890e-01,\n",
       "          -9.1147e-01, -9.7524e-01, -7.7617e-01, -4.5229e-03, -1.0587e+00,\n",
       "          -5.1830e-01, -1.6302e-03, -7.3033e-01, -1.7039e-02, -8.6336e-01,\n",
       "          -1.6786e-03, -7.1840e-03, -1.9659e-01, -3.4679e-02, -7.9982e-01,\n",
       "          -6.9055e-02, -3.8586e-01, -1.4017e-01, -4.0778e-01, -1.4408e+00,\n",
       "          -1.3831e+00, -8.3258e-01, -6.0478e-01, -7.9298e-01, -8.8551e-01,\n",
       "          -9.5254e-01, -1.0096e-03, -1.0581e+00, -1.0982e-01, -7.0454e-01,\n",
       "          -1.0738e+00, -1.0444e+00, -6.0469e-01, -5.9730e-01, -5.0309e-01,\n",
       "          -1.5257e+00, -1.4897e+00, -3.6435e-02, -1.1352e-01, -6.4803e-01,\n",
       "          -1.1950e+00, -1.2737e+00, -1.3127e+00, -1.1541e+00], device='cuda:0'),\n",
       "  tensor([4, 6, 1, 2, 3, 5, 3, 4, 5, 3, 4, 0, 4, 2, 5, 5, 2, 4, 0, 5, 5, 1, 2, 1,\n",
       "          4, 5, 2, 1, 1, 1, 4, 6, 5, 6, 5, 6, 4, 6, 0, 0, 4, 0, 6, 5, 3, 0, 6, 3,\n",
       "          6, 4, 3, 5, 6, 5, 2, 2, 4, 5, 0, 4, 6, 1, 4, 3], device='cuda:0')),\n",
       " (tensor([-7.4888e-01, -1.0142e+00, -9.7978e-01, -1.1720e+00, -1.1581e+00,\n",
       "          -7.3422e-01, -1.3530e+00, -1.2311e+00, -9.0042e-01, -1.6955e-03,\n",
       "          -1.1359e+00, -1.1176e+00, -1.0180e+00, -1.0434e-02, -5.8655e-01,\n",
       "          -1.5737e-02, -7.7106e-01, -2.9905e-04, -1.3275e+00, -8.6750e-01,\n",
       "          -1.6232e-01, -7.7977e-01, -1.0235e+00, -2.5761e-01, -2.6192e-01,\n",
       "          -2.5541e-03, -5.4032e-01, -1.4863e-03, -9.3706e-01, -6.4050e-01,\n",
       "          -1.1841e+00, -4.1736e-02, -5.1191e-01, -6.8194e-02, -4.9224e-01,\n",
       "          -5.0338e-01, -1.2092e-03, -7.6039e-04, -1.1846e+00, -1.2379e+00,\n",
       "          -1.0244e+00, -9.1187e-01, -1.2079e+00, -8.6402e-02, -1.1678e+00,\n",
       "          -1.0581e+00, -9.1387e-01, -1.1036e+00, -3.7670e-02, -6.9880e-04,\n",
       "          -8.2605e-02, -1.0827e+00, -5.3816e-01, -5.7526e-01, -4.4907e-01,\n",
       "          -5.9100e-01, -8.9167e-01, -4.1775e-01, -7.0642e-04, -1.0347e+00,\n",
       "          -9.5687e-01, -3.6328e-01, -1.4360e+00, -8.5609e-01], device='cuda:0'),\n",
       "  tensor([1, 4, 0, 3, 3, 6, 2, 4, 3, 5, 4, 1, 4, 2, 4, 6, 4, 5, 1, 3, 0, 1, 1, 0,\n",
       "          0, 6, 6, 3, 4, 5, 4, 0, 2, 6, 1, 6, 5, 6, 4, 2, 1, 1, 1, 0, 2, 4, 3, 1,\n",
       "          6, 6, 0, 4, 1, 0, 4, 5, 1, 5, 6, 2, 1, 0, 3, 4], device='cuda:0')),\n",
       " (tensor([-1.4171e+00, -1.1076e+00, -4.8159e-01, -7.3900e-01, -1.4389e+00,\n",
       "          -1.9078e-01, -1.0935e+00, -1.4117e+00, -2.6210e-01, -7.3146e-01,\n",
       "          -8.8530e-01, -1.7097e-01, -9.1059e-01, -1.2595e+00, -1.8345e-04,\n",
       "          -1.0732e+00, -1.0454e+00, -9.7857e-01, -7.1141e-02, -2.8725e-01,\n",
       "          -1.1231e-02, -5.3665e-01, -1.2655e-01, -4.9758e-01, -6.0064e-01,\n",
       "          -9.6731e-01, -9.3766e-01, -5.4988e-01, -7.5007e-01, -2.2895e-01,\n",
       "          -6.4878e-01, -1.4575e+00, -1.9477e-04, -1.1028e+00, -4.2043e-01,\n",
       "          -8.3412e-01, -3.2041e-03, -1.2300e+00, -6.7839e-01, -5.9330e-01,\n",
       "          -9.3550e-01, -3.5629e-02, -5.7553e-01, -5.2403e-03, -4.4696e-03,\n",
       "          -1.0006e+00, -1.2406e+00, -7.4812e-01, -1.2579e+00, -1.3085e-03,\n",
       "          -5.6544e-01, -5.2472e-01, -1.0013e+00, -9.2717e-01, -1.0580e+00,\n",
       "          -3.9992e-01, -1.2985e+00, -1.2765e+00, -8.1362e-01, -6.1057e-01,\n",
       "          -7.1470e-02, -9.9645e-01, -3.7827e-01, -7.5667e-01], device='cuda:0'),\n",
       "  tensor([3, 2, 1, 5, 4, 4, 3, 2, 3, 5, 6, 3, 1, 6, 4, 3, 4, 0, 6, 0, 1, 4, 1, 6,\n",
       "          4, 4, 6, 4, 0, 0, 2, 5, 4, 5, 0, 5, 2, 1, 4, 1, 0, 6, 5, 6, 2, 4, 3, 5,\n",
       "          4, 5, 5, 2, 2, 5, 5, 3, 6, 4, 6, 5, 6, 4, 0, 2], device='cuda:0')),\n",
       " (tensor([-4.9009e-02, -1.1673e-01, -2.7797e-02, -6.5769e-01, -8.9213e-01,\n",
       "          -3.9787e-01, -1.0265e+00, -7.0934e-01, -7.4367e-03, -9.7205e-01,\n",
       "          -7.4420e-01, -1.2086e+00, -7.3001e-04, -1.0311e+00, -4.6565e-03,\n",
       "          -1.0323e-04, -8.7152e-01, -1.0041e-02, -1.4767e-02, -7.3311e-05,\n",
       "          -7.7760e-01, -4.7990e-01, -2.1268e-02, -9.2495e-01, -8.8476e-01,\n",
       "          -9.3119e-01, -9.4311e-01, -1.4628e+00, -6.2063e-01, -7.8666e-01,\n",
       "          -1.3003e+00, -8.0620e-01, -1.0730e+00, -7.9576e-04, -7.1468e-01,\n",
       "          -1.3782e+00, -1.0694e+00, -9.5099e-01, -1.0357e+00, -9.9700e-01,\n",
       "          -1.1242e+00, -4.8337e-02, -8.1679e-01, -2.9023e-04, -1.0921e+00,\n",
       "          -5.0789e-01, -1.0241e+00, -1.4389e+00, -6.2822e-01, -5.7468e-01,\n",
       "          -5.4204e-01, -9.2792e-01, -1.3139e+00, -6.3788e-01, -9.5099e-01,\n",
       "          -5.6016e-01, -1.1475e+00, -1.1508e+00, -7.8288e-01, -1.0371e+00,\n",
       "          -7.7373e-04, -8.9284e-01, -9.6525e-03, -1.4308e-01], device='cuda:0'),\n",
       "  tensor([4, 1, 6, 5, 6, 5, 1, 2, 1, 2, 3, 4, 6, 3, 6, 4, 3, 5, 0, 4, 5, 5, 1, 4,\n",
       "          5, 5, 4, 1, 3, 2, 2, 3, 2, 4, 5, 1, 5, 6, 5, 1, 6, 6, 4, 2, 5, 5, 4, 4,\n",
       "          1, 5, 5, 4, 4, 2, 2, 0, 1, 3, 4, 0, 6, 3, 6, 0], device='cuda:0')),\n",
       " (tensor([-2.9672e-01, -1.2078e+00, -1.0189e+00, -5.8220e-01, -5.6955e-01,\n",
       "          -1.1862e+00, -3.2354e-01, -7.7151e-01, -7.9366e-01, -4.4115e-01,\n",
       "          -6.7180e-01, -1.1684e+00, -4.3689e-03, -1.0726e+00, -1.3632e-01,\n",
       "          -6.0579e-01, -3.9429e-01, -1.1693e+00, -9.4749e-01, -9.9148e-01,\n",
       "          -4.7300e-01, -9.9182e-01, -1.1574e+00, -8.9170e-03, -1.2747e-02,\n",
       "          -9.9145e-01, -4.1240e-01, -1.3307e+00, -4.9216e-01, -1.2168e-02,\n",
       "          -7.2095e-03, -7.5372e-01, -7.1471e-01, -1.1559e+00, -1.3677e+00,\n",
       "          -5.1754e-01, -5.2080e-01, -4.0547e-04, -1.9572e-03, -7.5603e-01,\n",
       "          -2.6407e-01, -4.2667e-02, -7.5593e-01, -8.4119e-01, -3.2864e-01,\n",
       "          -1.4282e+00, -9.0642e-01, -6.7470e-05, -1.0820e+00, -7.1671e-01,\n",
       "          -4.6274e-01, -8.4418e-02, -9.2379e-01, -9.6202e-01, -8.4524e-01,\n",
       "          -9.5466e-01, -5.0355e-01, -2.4876e-04, -3.4100e-01, -8.4098e-01,\n",
       "          -9.5443e-01, -8.3312e-01, -1.1867e+00, -1.7881e-01], device='cuda:0'),\n",
       "  tensor([1, 4, 2, 0, 2, 3, 4, 5, 2, 6, 4, 3, 6, 3, 6, 2, 4, 1, 4, 3, 5, 3, 4, 6,\n",
       "          2, 2, 4, 3, 4, 3, 6, 1, 5, 2, 6, 5, 0, 5, 6, 5, 6, 3, 4, 4, 6, 1, 3, 4,\n",
       "          0, 3, 0, 0, 1, 2, 0, 3, 4, 2, 5, 3, 4, 3, 3, 2], device='cuda:0')),\n",
       " (tensor([-1.8605e-01, -9.2487e-01, -1.2090e-02, -8.3961e-01, -1.0031e+00,\n",
       "          -1.0435e+00, -6.8390e-01, -8.1291e-01, -8.1871e-01, -4.1068e-01,\n",
       "          -1.0423e+00, -9.1136e-01, -2.1443e-04, -2.2935e-01, -6.8426e-01,\n",
       "          -5.8798e-01, -1.0794e+00, -1.1395e+00, -1.1665e-03, -5.0976e-01,\n",
       "          -1.2557e+00, -9.3906e-01, -9.7541e-01, -8.5305e-01, -8.7728e-01,\n",
       "          -4.7527e-01, -4.5086e-01, -1.1586e+00, -8.8652e-04, -1.1485e+00,\n",
       "          -1.1282e+00, -2.9134e-03, -4.9838e-01, -3.7147e-01, -8.0085e-02,\n",
       "          -8.8411e-01, -6.5355e-01, -1.0107e+00, -1.0649e+00, -1.9281e-01,\n",
       "          -1.2861e-01, -1.2303e+00, -5.6388e-01, -1.2840e+00, -8.5512e-01,\n",
       "          -1.2021e+00, -8.4919e-01, -9.5047e-01, -5.7283e-01, -1.1146e+00,\n",
       "          -1.1006e+00, -1.3929e+00, -1.1806e+00, -8.4719e-01, -8.9998e-02,\n",
       "          -3.5873e-01, -1.5185e+00, -1.0722e+00, -6.0653e-01, -1.0151e+00,\n",
       "          -8.5044e-01, -1.1774e+00, -1.3852e+00, -5.7366e-01], device='cuda:0'),\n",
       "  tensor([3, 1, 3, 4, 2, 4, 4, 5, 1, 6, 0, 4, 4, 1, 4, 5, 1, 4, 4, 1, 1, 1, 1, 1,\n",
       "          4, 5, 4, 4, 4, 1, 1, 5, 0, 5, 0, 1, 1, 3, 2, 3, 5, 3, 0, 0, 3, 4, 5, 3,\n",
       "          0, 4, 3, 4, 1, 4, 4, 0, 4, 0, 5, 4, 5, 1, 1, 4], device='cuda:0')),\n",
       " (tensor([-1.0095e+00, -5.4488e-04, -1.1576e+00, -7.1868e-01, -2.9457e-03,\n",
       "          -2.3561e-01, -1.8621e-03, -2.2353e-01, -1.1330e+00, -3.2559e-01,\n",
       "          -1.0993e+00, -4.6951e-01, -4.7282e-03, -1.2909e+00, -1.6534e-03,\n",
       "          -7.6467e-01, -2.3498e-02, -9.9986e-01, -6.2729e-01, -8.5682e-01,\n",
       "          -4.5548e-01, -7.9271e-05, -9.0686e-01, -9.2843e-01, -3.8159e-01,\n",
       "          -1.0867e+00, -1.3400e+00, -6.2901e-01, -5.9607e-02, -8.1144e-01,\n",
       "          -5.3602e-01, -8.9526e-01, -9.0174e-01, -1.9141e-03, -7.9794e-01,\n",
       "          -8.4664e-01, -1.1761e+00, -3.8611e-01, -1.5406e+00, -6.7206e-01,\n",
       "          -4.5271e-01, -4.9932e-01, -3.2002e-01, -4.3169e-01, -6.2340e-01,\n",
       "          -1.8765e-01, -3.9305e-01, -9.9258e-03, -1.1962e+00, -8.1027e-01,\n",
       "          -1.2071e+00, -1.1492e+00, -1.0751e+00, -5.8928e-01, -2.0534e-01,\n",
       "          -1.0716e+00, -9.7282e-01, -6.0899e-01, -5.3914e-01, -5.1461e-04,\n",
       "          -6.9438e-01, -9.6034e-01, -7.9505e-01, -6.0664e-03], device='cuda:0'),\n",
       "  tensor([1, 6, 1, 5, 4, 5, 5, 4, 0, 4, 1, 5, 6, 3, 6, 2, 0, 3, 6, 1, 5, 6, 0, 4,\n",
       "          6, 5, 3, 4, 1, 1, 4, 1, 1, 3, 5, 3, 1, 3, 6, 5, 5, 0, 5, 4, 1, 0, 3, 6,\n",
       "          2, 1, 4, 3, 4, 4, 6, 4, 4, 3, 1, 5, 5, 3, 4, 6], device='cuda:0')),\n",
       " (tensor([-5.1429e-01, -9.0432e-03, -8.6467e-01, -1.0774e+00, -1.1164e+00,\n",
       "          -1.0320e-02, -2.5817e-04, -9.5679e-04, -4.4551e-04, -6.4459e-01,\n",
       "          -7.1989e-01, -6.8267e-01, -6.2528e-03, -4.9153e-01, -1.2020e+00,\n",
       "          -1.2463e-02, -6.8971e-01, -6.0673e-01, -8.7447e-01, -8.1280e-04,\n",
       "          -7.5502e-03, -1.2868e+00, -6.9516e-01, -7.6182e-01, -5.5255e-01,\n",
       "          -1.0749e+00, -8.9476e-01, -7.3314e-01, -5.7612e-03, -8.4470e-01,\n",
       "          -6.8898e-01, -6.9769e-01, -1.2733e-02, -8.8762e-01, -4.4504e-01,\n",
       "          -1.2370e+00, -5.2003e-01, -1.3688e+00, -1.2964e+00, -1.5146e-02,\n",
       "          -1.0863e+00, -8.7711e-01, -7.2073e-01, -7.1527e-01, -1.1067e-01,\n",
       "          -3.2496e-01, -2.1944e-04, -8.3233e-01, -8.9383e-01, -1.4121e-02,\n",
       "          -6.2792e-04, -3.8320e-01, -3.7595e-03, -6.3129e-01, -3.2014e-04,\n",
       "          -7.0471e-01, -4.1281e-01, -1.2071e-02, -9.5278e-03, -1.1513e+00,\n",
       "          -6.2727e-03, -1.0048e-01, -6.6911e-03, -3.5923e-03], device='cuda:0'),\n",
       "  tensor([5, 6, 5, 4, 6, 1, 4, 2, 4, 4, 5, 5, 6, 4, 0, 5, 0, 4, 4, 4, 0, 6, 5, 0,\n",
       "          5, 4, 1, 2, 6, 4, 5, 2, 0, 3, 5, 3, 4, 4, 0, 0, 6, 3, 3, 5, 6, 0, 2, 4,\n",
       "          2, 6, 4, 0, 1, 5, 6, 5, 2, 6, 1, 5, 6, 0, 6, 5], device='cuda:0')),\n",
       " (tensor([-8.9466e-01, -8.7085e-01, -1.0240e+00, -8.2751e-01, -6.1508e-01,\n",
       "          -1.1416e+00, -4.7726e-01, -1.0382e+00, -6.5743e-01, -5.6032e-01,\n",
       "          -3.5173e-02, -1.9763e-03, -4.8089e-01, -9.1193e-01, -9.9025e-01,\n",
       "          -1.1140e+00, -2.0245e-03, -1.1417e+00, -1.6580e-02, -1.9298e-04,\n",
       "          -1.0837e+00, -8.1568e-01, -5.1164e-01, -5.1064e-01, -4.7009e-03,\n",
       "          -9.8536e-01, -5.5950e-01, -4.5739e-01, -9.8953e-01, -3.3798e-01,\n",
       "          -1.1994e+00, -6.7858e-01, -1.3911e+00, -3.2216e-01, -1.1520e+00,\n",
       "          -1.6297e-02, -9.2824e-01, -9.1173e-01, -4.7140e-01, -9.1747e-01,\n",
       "          -4.3572e-01, -5.9505e-01, -9.1070e-01, -7.4736e-01, -1.2010e+00,\n",
       "          -4.3541e-01, -6.5187e-01, -6.6394e-01, -4.0842e-01, -1.9827e-01,\n",
       "          -1.3147e+00, -6.0963e-01, -1.3070e+00, -5.8126e-03, -9.9738e-01,\n",
       "          -3.4210e-02, -9.6998e-01, -1.4154e+00, -1.3244e+00, -2.0748e-01,\n",
       "          -1.0514e+00, -3.0625e-01, -1.1867e-02, -6.8445e-01], device='cuda:0'),\n",
       "  tensor([4, 5, 1, 3, 6, 4, 4, 3, 1, 3, 6, 6, 4, 3, 1, 4, 3, 5, 6, 6, 4, 0, 0, 5,\n",
       "          6, 3, 0, 5, 4, 0, 1, 0, 3, 6, 3, 2, 1, 3, 6, 1, 5, 6, 6, 3, 4, 4, 4, 5,\n",
       "          4, 6, 4, 5, 3, 6, 4, 1, 4, 3, 4, 0, 6, 1, 1, 4], device='cuda:0')),\n",
       " (tensor([-0.4289, -0.0050, -0.4111, -1.0828, -0.7875, -0.0093, -0.9008, -0.9095,\n",
       "          -0.2101, -1.3237, -1.3610, -0.9735, -0.9315, -0.6533, -0.0270, -1.1544,\n",
       "          -0.0090, -0.8870, -0.8131, -1.1843, -1.3539, -0.8734, -1.1635, -0.8758,\n",
       "          -0.9486, -0.0205, -0.0128, -1.3011, -1.1429, -0.4989, -1.2302, -0.5622,\n",
       "          -0.0929, -0.5393, -0.3368, -1.1435, -1.1533, -0.0051, -0.9850, -0.5785,\n",
       "          -0.0269, -0.9575, -0.0066, -1.3619, -0.5831, -0.0033, -0.4339, -0.7361,\n",
       "          -0.9273, -0.9627, -0.8333, -1.1504, -0.6671, -0.0335, -1.2743, -0.9659,\n",
       "          -0.4288, -0.8069, -1.3098, -0.0042, -0.4336, -0.8393, -0.4156, -0.4414],\n",
       "         device='cuda:0'),\n",
       "  tensor([5, 3, 0, 6, 5, 6, 1, 3, 0, 4, 3, 5, 2, 1, 6, 3, 0, 3, 2, 5, 6, 3, 2, 6,\n",
       "          4, 2, 5, 4, 1, 5, 5, 3, 1, 4, 3, 3, 2, 1, 4, 5, 0, 2, 2, 4, 6, 0, 6, 1,\n",
       "          0, 3, 4, 1, 5, 1, 6, 4, 5, 1, 1, 1, 4, 4, 5, 2], device='cuda:0')),\n",
       " (tensor([-1.1581e+00, -4.6452e-01, -9.2179e-01, -1.3105e+00, -4.1566e-03,\n",
       "          -2.7256e-03, -4.5758e-01, -2.7430e-02, -3.3464e-01, -9.2587e-01,\n",
       "          -9.6470e-01, -3.4656e-01, -8.4504e-01, -2.3628e-01, -5.1265e-01,\n",
       "          -2.2713e-03, -2.0261e-03, -2.0752e-03, -3.3341e-02, -1.0263e-01,\n",
       "          -9.3055e-01, -8.5258e-04, -1.1898e+00, -4.0470e-01, -2.8787e-01,\n",
       "          -5.3034e-01, -1.1064e+00, -5.7510e-01, -8.8688e-04, -7.5597e-01,\n",
       "          -8.4070e-01, -9.5526e-01, -2.7647e-01, -6.4663e-01, -1.2717e+00,\n",
       "          -7.9661e-01, -3.4821e-01, -1.1615e+00, -7.2808e-01, -1.0155e+00,\n",
       "          -1.1505e+00, -7.0656e-01, -1.4388e-03, -1.1580e+00, -8.4843e-03,\n",
       "          -5.0041e-02, -6.0373e-01, -9.4473e-01, -6.8346e-01, -8.4859e-01,\n",
       "          -7.1642e-01, -3.2289e-04, -3.3509e-01, -1.6903e-01, -4.3025e-04,\n",
       "          -2.2920e-03, -5.3061e-01, -3.5301e-01, -9.6836e-01, -6.3046e-02,\n",
       "          -1.0090e+00, -1.1636e+00, -4.9307e-03, -5.0239e-01], device='cuda:0'),\n",
       "  tensor([1, 3, 3, 3, 1, 4, 5, 6, 2, 5, 5, 0, 4, 1, 2, 2, 6, 3, 1, 0, 5, 6, 1, 6,\n",
       "          4, 4, 4, 5, 4, 2, 1, 6, 5, 4, 1, 1, 5, 3, 4, 4, 3, 5, 6, 1, 1, 5, 2, 0,\n",
       "          2, 6, 5, 4, 5, 1, 2, 3, 6, 5, 1, 6, 4, 1, 3, 5], device='cuda:0')),\n",
       " (tensor([-0.0291, -1.0476, -0.8475, -0.6168, -0.6932, -1.3124, -1.0175, -0.6363,\n",
       "          -0.0462, -0.7288, -0.3723, -0.0018, -0.4066, -0.9835, -1.1077, -1.0864,\n",
       "          -0.7978, -0.6275, -0.0186, -0.0031, -0.0197, -0.4699, -0.2208, -0.4595,\n",
       "          -0.6242, -1.0134, -1.1164, -0.0194, -0.9994, -0.8951, -1.3417, -0.5384,\n",
       "          -0.5325, -0.8530, -0.8189, -1.0392, -1.4056, -0.7166, -0.1887, -0.8224,\n",
       "          -0.9980, -1.2479, -0.0103, -0.9290, -0.9738, -0.0085, -0.5112, -0.9907,\n",
       "          -0.5707, -1.1174, -1.0016, -0.6234, -1.1133, -1.2299, -1.0015, -0.0151,\n",
       "          -0.8104, -0.3552, -0.6450, -0.1671, -0.9784, -1.3435, -0.0087, -0.7177],\n",
       "         device='cuda:0'),\n",
       "  tensor([3, 0, 0, 0, 6, 0, 2, 5, 0, 0, 4, 2, 0, 4, 2, 2, 5, 1, 1, 6, 0, 5, 1, 0,\n",
       "          0, 1, 1, 1, 5, 2, 6, 4, 5, 2, 5, 3, 0, 5, 5, 2, 0, 2, 4, 4, 5, 1, 0, 3,\n",
       "          5, 3, 6, 0, 0, 1, 3, 6, 5, 5, 4, 0, 3, 1, 1, 4], device='cuda:0')),\n",
       " (tensor([-9.1652e-01, -3.4225e-02, -1.0227e+00, -7.5729e-01, -7.4178e-01,\n",
       "          -1.1892e-03, -9.8793e-01, -6.9755e-01, -9.3460e-01, -4.6218e-02,\n",
       "          -1.0711e+00, -6.5496e-04, -3.0256e-02, -9.2254e-01, -1.4096e+00,\n",
       "          -7.7011e-01, -7.9681e-01, -1.0750e+00, -7.6730e-01, -1.1454e+00,\n",
       "          -1.3934e+00, -9.9318e-01, -2.5751e-01, -5.4281e-03, -1.2019e+00,\n",
       "          -3.5620e-01, -7.6066e-01, -8.0685e-02, -1.1130e+00, -4.7950e-01,\n",
       "          -1.1036e+00, -3.2072e-03, -1.9109e-02, -1.0774e+00, -1.2689e+00,\n",
       "          -8.7508e-01, -8.8091e-01, -1.1615e+00, -4.8427e-01, -3.2983e-03,\n",
       "          -9.6551e-01, -9.5845e-01, -5.4608e-01, -6.3674e-01, -3.6836e-01,\n",
       "          -2.1382e-01, -1.3280e+00, -1.2230e+00, -1.0349e+00, -1.2864e+00,\n",
       "          -1.1910e+00, -1.0459e+00, -7.6672e-01, -3.6189e-01, -3.8937e-02,\n",
       "          -8.2560e-01, -5.3036e-02, -1.7013e-03, -5.7716e-01, -1.4056e+00,\n",
       "          -4.3865e-01, -9.4227e-01, -9.3491e-02, -1.1312e+00], device='cuda:0'),\n",
       "  tensor([2, 0, 4, 2, 5, 5, 4, 3, 5, 2, 4, 2, 6, 1, 3, 0, 5, 3, 0, 4, 3, 6, 5, 3,\n",
       "          5, 5, 3, 6, 2, 4, 0, 3, 0, 1, 3, 3, 4, 5, 5, 1, 6, 1, 4, 4, 1, 4, 3, 2,\n",
       "          3, 1, 4, 4, 5, 6, 1, 5, 6, 3, 4, 3, 4, 4, 0, 4], device='cuda:0')),\n",
       " (tensor([-1.0789e+00, -9.9967e-01, -7.0499e-01, -6.7420e-01, -9.9762e-01,\n",
       "          -2.4771e-03, -8.9413e-01, -7.8901e-01, -1.0233e+00, -1.1921e+00,\n",
       "          -5.5618e-01, -8.3185e-01, -1.1905e+00, -1.2733e+00, -3.2928e-01,\n",
       "          -8.1543e-01, -3.0195e-03, -2.7660e-03, -2.8676e-01, -9.0951e-02,\n",
       "          -3.6553e-01, -5.8855e-01, -1.1034e+00, -2.6344e-03, -1.2890e+00,\n",
       "          -6.2687e-01, -1.0889e-02, -7.8328e-01, -1.3100e-02, -5.9102e-03,\n",
       "          -6.1284e-01, -5.1726e-01, -8.5638e-01, -2.5590e-02, -1.2082e-01,\n",
       "          -1.0352e+00, -6.9372e-01, -9.2136e-01, -1.7131e-01, -1.0743e-01,\n",
       "          -1.4496e-01, -4.2814e-02, -1.0882e+00, -8.4152e-01, -2.3303e-04,\n",
       "          -9.3681e-01, -5.7727e-01, -1.7010e-02, -8.2858e-01, -8.2568e-01,\n",
       "          -3.7966e-01, -9.5129e-01, -1.3162e+00, -1.1000e+00, -9.5431e-01,\n",
       "          -1.1813e+00, -8.9319e-04, -7.7616e-01, -2.5648e-03, -1.0988e+00,\n",
       "          -6.4351e-03, -6.6950e-01, -5.8635e-01, -1.2844e+00], device='cuda:0'),\n",
       "  tensor([1, 1, 4, 5, 3, 1, 1, 0, 0, 2, 0, 4, 2, 4, 6, 4, 6, 5, 6, 6, 0, 0, 0, 6,\n",
       "          5, 0, 3, 5, 1, 4, 2, 0, 3, 0, 0, 2, 4, 0, 4, 0, 1, 0, 3, 2, 4, 0, 5, 2,\n",
       "          4, 4, 1, 4, 5, 0, 4, 4, 5, 1, 6, 4, 6, 4, 2, 4], device='cuda:0')),\n",
       " (tensor([-1.2439e+00, -7.9562e-01, -9.7088e-01, -8.9797e-01, -3.9932e-01,\n",
       "          -1.1757e-03, -6.2570e-03, -5.1735e-04, -8.5271e-01, -1.9689e-03,\n",
       "          -1.2186e+00, -7.7182e-04, -1.0971e+00, -8.5620e-01, -5.9802e-01,\n",
       "          -8.3042e-01, -6.5115e-01, -8.4993e-01, -3.9260e-04, -4.2817e-01,\n",
       "          -1.5570e-01, -1.2439e+00, -7.3881e-01, -2.7676e-02, -6.2261e-01,\n",
       "          -1.6108e-01, -1.3350e+00, -8.8056e-01, -1.2835e+00, -9.0640e-01,\n",
       "          -1.4614e-04, -1.0363e-01, -1.2118e+00, -8.4082e-01, -9.7592e-01,\n",
       "          -1.2619e+00, -3.9604e-01, -4.4598e-04, -7.6513e-01, -2.0821e-02,\n",
       "          -8.5365e-04, -1.2533e+00, -1.4496e-03, -3.9040e-03, -4.3046e-01,\n",
       "          -1.3245e+00, -7.1129e-03, -8.2013e-03, -2.3558e-02, -6.4460e-04,\n",
       "          -2.3841e-01, -1.0295e+00, -1.8411e-01, -3.3613e-01, -9.4974e-01,\n",
       "          -8.7918e-01, -1.0322e+00, -9.7923e-01, -8.1423e-01, -6.3317e-01,\n",
       "          -1.0503e+00, -1.0297e+00, -1.0973e+00, -3.0789e-01], device='cuda:0'),\n",
       "  tensor([4, 5, 1, 1, 3, 3, 6, 4, 4, 6, 1, 2, 3, 4, 5, 3, 5, 3, 6, 4, 3, 1, 2, 1,\n",
       "          4, 4, 3, 1, 3, 4, 4, 6, 1, 3, 1, 1, 4, 6, 4, 2, 4, 3, 4, 5, 5, 2, 6, 1,\n",
       "          1, 0, 6, 5, 6, 6, 4, 3, 1, 4, 5, 0, 4, 4, 4, 5], device='cuda:0')),\n",
       " (tensor([-1.1511e+00, -1.0296e+00, -7.3791e-01, -7.9981e-01, -1.0311e+00,\n",
       "          -3.6631e-03, -3.3562e-01, -1.1003e+00, -1.2379e+00, -1.4482e+00,\n",
       "          -4.9687e-01, -3.2350e-01, -2.3724e-03, -8.0735e-01, -1.0992e+00,\n",
       "          -5.0061e-01, -7.2642e-03, -8.7165e-01, -1.1640e+00, -9.2281e-01,\n",
       "          -4.4566e-01, -6.2932e-01, -4.1627e-03, -9.3820e-01, -9.1803e-01,\n",
       "          -5.2706e-01, -3.7561e-01, -9.4115e-01, -1.3089e+00, -1.0385e-01,\n",
       "          -1.2093e+00, -5.5703e-04, -1.3512e-03, -1.0209e+00, -7.3510e-01,\n",
       "          -4.5366e-01, -7.6118e-01, -1.3500e+00, -4.2561e-04, -1.0840e+00,\n",
       "          -2.7870e-03, -8.2237e-01, -2.0918e-02, -7.3824e-01, -5.8230e-01,\n",
       "          -4.5107e-01, -1.0055e+00, -1.3762e+00, -5.6256e-01, -1.1739e+00,\n",
       "          -1.1437e+00, -7.9893e-01, -3.7878e-03, -2.6478e-01, -4.9263e-03,\n",
       "          -3.1962e-01, -7.2867e-01, -4.1467e-01, -1.0091e+00, -8.4735e-01,\n",
       "          -3.8265e-05, -2.5183e-01, -4.8343e-01, -6.8540e-01], device='cuda:0'),\n",
       "  tensor([5, 2, 0, 4, 3, 6, 6, 2, 4, 4, 6, 0, 0, 4, 5, 6, 5, 0, 6, 4, 5, 5, 6, 1,\n",
       "          3, 2, 5, 4, 2, 6, 0, 5, 6, 2, 5, 4, 0, 4, 6, 3, 3, 2, 3, 4, 2, 6, 4, 4,\n",
       "          0, 4, 0, 6, 2, 5, 5, 0, 3, 1, 4, 2, 6, 0, 0, 2], device='cuda:0')),\n",
       " (tensor([-8.8509e-01, -5.7460e-02, -7.3105e-01, -9.6920e-01, -9.5535e-02,\n",
       "          -6.5749e-01, -5.8498e-01, -9.2084e-01, -7.6730e-01, -1.0143e+00,\n",
       "          -6.9852e-01, -8.8375e-01, -4.2703e-01, -1.3932e+00, -2.4363e-04,\n",
       "          -8.0702e-01, -1.1673e+00, -6.1123e-03, -8.3820e-01, -6.3246e-01,\n",
       "          -1.1265e+00, -1.3457e+00, -6.2593e-01, -1.3353e+00, -2.3296e-02,\n",
       "          -8.5211e-01, -2.8936e-02, -1.3780e+00, -7.1775e-01, -5.8757e-01,\n",
       "          -3.5737e-01, -8.3558e-03, -9.7818e-01, -1.3005e+00, -6.3070e-02,\n",
       "          -1.0065e+00, -9.0647e-01, -9.3001e-02, -1.0376e-01, -3.2512e-01,\n",
       "          -1.3678e+00, -6.4828e-01, -1.0272e+00, -4.9105e-01, -1.1568e+00,\n",
       "          -6.2899e-04, -9.3525e-01, -5.3247e-01, -1.6678e-01, -9.6275e-01,\n",
       "          -1.0567e+00, -1.2194e+00, -8.5973e-04, -2.5865e-01, -4.0769e-05,\n",
       "          -9.3742e-01, -1.1976e+00, -1.0526e+00, -6.4251e-03, -1.1999e+00,\n",
       "          -1.2108e+00, -1.3201e+00, -6.6813e-01, -9.9237e-01], device='cuda:0'),\n",
       "  tensor([4, 0, 3, 3, 0, 1, 5, 2, 2, 4, 5, 4, 0, 6, 4, 3, 3, 3, 4, 5, 1, 5, 5, 2,\n",
       "          5, 4, 3, 6, 6, 0, 6, 0, 2, 0, 6, 2, 3, 0, 1, 5, 4, 5, 2, 6, 2, 2, 0, 4,\n",
       "          2, 2, 2, 3, 5, 0, 6, 4, 4, 1, 1, 5, 5, 1, 5, 3], device='cuda:0')),\n",
       " (tensor([-1.1286e+00, -1.4156e+00, -1.0073e+00, -2.3745e-01, -1.1648e+00,\n",
       "          -1.0186e+00, -1.1610e+00, -1.2733e+00, -1.0718e+00, -2.1539e-04,\n",
       "          -9.6945e-01, -9.8902e-01, -7.0695e-01, -5.8883e-01, -1.0467e+00,\n",
       "          -1.1849e+00, -1.0348e+00, -1.4486e+00, -7.7746e-01, -2.6744e-02,\n",
       "          -1.0899e+00, -1.8738e-03, -8.2953e-01, -6.9364e-01, -1.0702e+00,\n",
       "          -1.3537e+00, -1.3324e-01, -1.2855e+00, -5.7503e-01, -8.0716e-01,\n",
       "          -1.3340e-01, -1.7165e-04, -4.6539e-01, -5.6156e-04, -8.7276e-01,\n",
       "          -1.2384e+00, -1.3569e+00, -4.2724e-01, -6.5598e-01, -4.3967e-01,\n",
       "          -1.4135e-01, -8.0893e-01, -1.0169e+00, -7.8323e-01, -7.6589e-01,\n",
       "          -2.8361e-01, -8.5024e-02, -1.0153e+00, -9.7791e-01, -1.0582e+00,\n",
       "          -1.0200e+00, -2.2597e-03, -1.3110e-03, -9.9427e-01, -1.1371e-01,\n",
       "          -4.7367e-01, -5.1456e-01, -7.8649e-01, -7.9167e-01, -6.9954e-01,\n",
       "          -8.6324e-01, -1.3441e+00, -1.0827e+00, -4.7625e-01], device='cuda:0'),\n",
       "  tensor([4, 2, 4, 0, 4, 5, 1, 1, 1, 2, 0, 4, 4, 5, 4, 1, 4, 4, 5, 0, 1, 6, 4, 2,\n",
       "          5, 2, 0, 5, 5, 3, 6, 4, 5, 5, 3, 1, 3, 1, 3, 0, 6, 4, 1, 3, 2, 5, 6, 4,\n",
       "          1, 4, 6, 6, 6, 5, 6, 5, 1, 4, 3, 5, 1, 0, 2, 6], device='cuda:0')),\n",
       " (tensor([-1.0149e+00, -1.4789e+00, -1.3445e-02, -2.0071e-03, -5.2554e-01,\n",
       "          -6.0428e-01, -5.2278e-01, -9.7091e-01, -7.8388e-02, -9.6295e-01,\n",
       "          -9.4941e-01, -7.6723e-01, -4.4026e-04, -2.8014e-03, -1.1271e-02,\n",
       "          -8.6475e-01, -5.4070e-01, -1.5919e+00, -6.9537e-01, -8.5031e-01,\n",
       "          -1.1758e+00, -6.2908e-01, -6.3894e-01, -9.5305e-01, -1.0075e-03,\n",
       "          -3.1541e-01, -4.9587e-02, -1.1415e+00, -9.2163e-01, -1.2424e+00,\n",
       "          -1.2929e+00, -1.0108e+00, -5.5995e-03, -1.1037e+00, -7.3611e-01,\n",
       "          -8.2254e-01, -7.4077e-01, -1.0092e+00, -5.3723e-01, -9.5969e-01,\n",
       "          -3.4891e-02, -2.5500e-01, -3.3253e-01, -7.4836e-02, -6.6071e-03,\n",
       "          -4.1529e-01, -6.1512e-01, -8.8297e-01, -9.8799e-01, -1.3585e+00,\n",
       "          -7.5911e-01, -9.3263e-01, -6.1888e-01, -8.2885e-01, -1.1252e+00,\n",
       "          -1.0429e+00, -8.5396e-01, -1.0799e+00, -6.1446e-01, -5.8631e-01,\n",
       "          -9.6583e-01, -5.6353e-01, -1.4341e+00, -5.5781e-01], device='cuda:0'),\n",
       "  tensor([1, 4, 3, 5, 0, 5, 4, 4, 6, 5, 5, 0, 0, 5, 6, 5, 5, 4, 4, 1, 5, 2, 5, 1,\n",
       "          6, 5, 6, 4, 4, 4, 5, 4, 6, 4, 4, 3, 1, 3, 5, 4, 6, 4, 4, 6, 6, 1, 2, 5,\n",
       "          5, 6, 4, 4, 1, 5, 6, 2, 4, 1, 4, 4, 4, 5, 1, 5], device='cuda:0')),\n",
       " (tensor([-8.8892e-01, -8.2198e-01, -1.4760e+00, -5.3194e-01, -9.3179e-01,\n",
       "          -2.7333e-03, -1.3143e+00, -1.0966e+00, -1.0397e+00, -1.1790e-03,\n",
       "          -9.0646e-01, -2.3146e-01, -3.8366e-02, -8.9979e-01, -3.6237e-02,\n",
       "          -1.3134e+00, -1.4022e-02, -8.0788e-01, -3.7083e-01, -7.4023e-01,\n",
       "          -1.2346e+00, -4.8810e-01, -1.0030e+00, -1.5653e-02, -8.0119e-01,\n",
       "          -8.1040e-01, -7.9175e-01, -1.2395e+00, -7.5133e-04, -6.5938e-01,\n",
       "          -1.0528e+00, -5.0436e-01, -7.2308e-01, -8.3527e-01, -7.9802e-03,\n",
       "          -1.1784e+00, -8.2782e-01, -7.0338e-03, -5.2537e-01, -8.9161e-01,\n",
       "          -7.7515e-01, -1.3259e+00, -5.1820e-01, -1.5561e-01, -1.3647e+00,\n",
       "          -7.3790e-01, -7.2667e-01, -1.9374e-03, -1.3897e+00, -7.6294e-01,\n",
       "          -1.2416e+00, -1.1746e+00, -2.1416e-03, -1.1082e+00, -1.4870e-01,\n",
       "          -1.3827e+00, -3.7674e-01, -1.3043e+00, -1.3477e+00, -9.9699e-01,\n",
       "          -9.1302e-01, -6.7655e-01, -7.7613e-01, -6.4153e-01], device='cuda:0'),\n",
       "  tensor([1, 5, 1, 6, 3, 6, 4, 1, 3, 1, 4, 0, 6, 4, 6, 1, 5, 5, 0, 1, 4, 6, 3, 6,\n",
       "          5, 4, 4, 6, 6, 4, 3, 6, 3, 5, 2, 1, 3, 6, 4, 4, 2, 5, 3, 4, 6, 2, 4, 0,\n",
       "          5, 3, 0, 4, 4, 4, 0, 4, 4, 5, 1, 4, 4, 4, 5, 4], device='cuda:0')),\n",
       " (tensor([-6.5563e-01, -8.8434e-01, -9.6806e-03, -4.4288e-04, -1.2841e-02,\n",
       "          -6.9967e-01, -8.1750e-01, -1.0359e+00, -1.0526e+00, -1.4648e-01,\n",
       "          -6.1120e-01, -7.0503e-01, -2.6056e-03, -3.9955e-02, -5.9560e-01,\n",
       "          -1.5896e-03, -7.3388e-01, -1.0652e+00, -8.1765e-01, -1.0351e+00,\n",
       "          -9.8809e-01, -2.6459e-01, -4.8923e-04, -6.4730e-01, -8.7764e-01,\n",
       "          -9.9813e-01, -1.2153e+00, -1.3460e+00, -1.1980e+00, -9.1663e-01,\n",
       "          -5.8244e-02, -8.2006e-01, -6.8956e-01, -9.7446e-01, -7.3263e-04,\n",
       "          -1.1764e+00, -2.6932e-01, -7.1324e-01, -5.3938e-01, -1.4281e+00,\n",
       "          -2.6758e-01, -1.2897e+00, -2.7471e-01, -1.6308e-03, -6.3411e-01,\n",
       "          -6.3737e-03, -9.3160e-01, -9.3620e-01, -5.9318e-01, -9.4882e-01,\n",
       "          -5.9608e-01, -9.7334e-01, -7.6423e-01, -8.2178e-01, -2.3691e-01,\n",
       "          -9.0332e-04, -1.0273e+00, -8.2602e-04, -5.3442e-01, -7.7332e-01,\n",
       "          -1.0679e+00, -5.4658e-01, -7.1300e-01, -8.7049e-01], device='cuda:0'),\n",
       "  tensor([5, 2, 6, 5, 0, 5, 2, 4, 4, 6, 3, 4, 5, 0, 5, 0, 4, 4, 0, 4, 4, 0, 6, 4,\n",
       "          5, 2, 1, 1, 0, 3, 6, 6, 4, 4, 5, 1, 6, 4, 1, 4, 0, 2, 0, 6, 4, 6, 4, 2,\n",
       "          2, 4, 5, 5, 5, 5, 4, 5, 5, 2, 5, 1, 0, 5, 5, 3], device='cuda:0')),\n",
       " (tensor([-1.3528e+00, -5.8290e-01, -6.7418e-01, -3.5465e-01, -9.4241e-02,\n",
       "          -3.2243e-03, -3.5355e-02, -7.8966e-01, -8.9356e-01, -1.5918e-01,\n",
       "          -6.6258e-01, -7.1575e-03, -1.1939e-01, -1.2284e+00, -9.5961e-01,\n",
       "          -5.2234e-01, -7.0913e-01, -3.6427e-01, -1.2575e-02, -3.6698e-04,\n",
       "          -1.1851e-01, -1.1903e+00, -4.9708e-03, -1.4887e-02, -3.2961e-02,\n",
       "          -9.8554e-01, -3.0164e-02, -1.2053e+00, -1.2333e+00, -1.9845e-03,\n",
       "          -5.0597e-03, -5.4025e-02, -5.6004e-01, -8.9319e-01, -1.0412e+00,\n",
       "          -1.5657e-03, -1.9449e-01, -5.1396e-01, -9.4538e-01, -3.5367e-01,\n",
       "          -3.4446e-04, -1.3424e-01, -1.1156e+00, -2.5195e-01, -8.3411e-01,\n",
       "          -5.1367e-01, -9.0700e-01, -9.7797e-01, -2.3218e-01, -1.4671e-03,\n",
       "          -9.0168e-01, -2.2775e-02, -1.4273e+00, -1.0458e+00, -1.2978e-01,\n",
       "          -4.4111e-01, -4.6300e-03, -1.5280e-02, -8.1791e-01, -5.5519e-01,\n",
       "          -1.3256e+00, -1.1980e+00, -2.4208e-01, -9.4841e-01], device='cuda:0'),\n",
       "  tensor([1, 0, 1, 0, 6, 4, 1, 2, 4, 0, 4, 6, 6, 1, 3, 5, 4, 5, 6, 2, 6, 3, 0, 4,\n",
       "          1, 4, 1, 3, 4, 6, 6, 6, 0, 1, 4, 6, 0, 5, 2, 0, 4, 0, 3, 4, 0, 1, 4, 2,\n",
       "          0, 3, 4, 6, 1, 4, 0, 4, 6, 1, 4, 2, 3, 3, 2, 4], device='cuda:0')),\n",
       " (tensor([-1.8972e-03, -5.6875e-01, -1.0942e+00, -7.5002e-04, -1.1455e+00,\n",
       "          -4.7561e-02, -1.1425e+00, -6.3051e-01, -6.9074e-01, -6.9276e-01,\n",
       "          -4.3453e-01, -4.1009e-01, -1.1080e+00, -2.5085e-01, -1.1869e+00,\n",
       "          -6.9716e-01, -5.0279e-03, -1.1121e+00, -5.1347e-01, -1.1156e+00,\n",
       "          -9.2612e-01, -3.0468e-02, -1.0380e+00, -6.5017e-01, -6.1007e-01,\n",
       "          -3.2154e-01, -3.1690e-01, -2.4600e-03, -6.4157e-01, -1.1008e-03,\n",
       "          -1.1194e+00, -5.7827e-01, -6.1185e-01, -9.7495e-01, -8.9260e-01,\n",
       "          -8.7189e-01, -4.3398e-01, -4.7346e-03, -7.7012e-03, -8.3768e-01,\n",
       "          -9.0975e-01, -8.9825e-01, -8.4144e-01, -1.0323e+00, -7.3037e-04,\n",
       "          -7.2716e-01, -1.0954e+00, -2.6458e-01, -1.1285e+00, -1.4056e+00,\n",
       "          -6.7109e-01, -3.2824e-01, -1.5506e+00, -2.8643e-02, -1.0584e+00,\n",
       "          -1.0457e+00, -1.4364e+00, -1.1286e+00, -9.6813e-01, -1.2528e-04,\n",
       "          -1.3463e-01, -1.7439e-03, -1.4960e+00, -1.0576e+00], device='cuda:0'),\n",
       "  tensor([6, 4, 1, 4, 4, 5, 2, 3, 3, 6, 5, 3, 3, 0, 0, 3, 3, 4, 4, 1, 4, 0, 4, 4,\n",
       "          4, 6, 4, 5, 5, 2, 0, 5, 0, 6, 2, 5, 5, 5, 3, 1, 5, 5, 5, 5, 5, 0, 4, 0,\n",
       "          2, 3, 4, 6, 6, 0, 4, 3, 4, 4, 0, 6, 6, 3, 1, 2], device='cuda:0')),\n",
       " (tensor([-1.2675e+00, -1.1378e+00, -6.6778e-01, -1.0037e+00, -1.0992e-03,\n",
       "          -1.7110e-02, -1.0624e+00, -4.5532e-01, -6.6573e-03, -1.3701e+00,\n",
       "          -5.7907e-01, -9.6777e-01, -1.2647e+00, -6.3627e-03, -9.0441e-01,\n",
       "          -3.5408e-01, -1.3725e-01, -1.0709e+00, -1.2288e+00, -5.2521e-01,\n",
       "          -9.9298e-01, -4.0118e-04, -6.9212e-01, -1.3156e+00, -1.1632e+00,\n",
       "          -5.2069e-01, -3.3862e-04, -7.7965e-01, -1.2399e+00, -9.8529e-01,\n",
       "          -7.8192e-02, -3.2491e-01, -1.1146e-03, -1.3810e+00, -5.6755e-01,\n",
       "          -1.1910e-03, -2.9726e-01, -6.2342e-03, -5.6471e-01, -9.9596e-01,\n",
       "          -1.1717e+00, -9.2500e-03, -1.0588e+00, -4.6214e-01, -1.1096e-03,\n",
       "          -3.6584e-03, -7.3519e-01, -4.8633e-01, -6.8841e-01, -1.1273e+00,\n",
       "          -5.0514e-01, -8.2731e-02, -8.8621e-01, -8.0660e-01, -9.7899e-01,\n",
       "          -2.6162e-03, -1.3574e+00, -1.0102e+00, -5.2672e-01, -7.6127e-01,\n",
       "          -1.3522e+00, -5.7487e-01, -7.2747e-02, -1.2899e+00], device='cuda:0'),\n",
       "  tensor([1, 2, 5, 1, 3, 6, 6, 4, 6, 4, 5, 1, 4, 6, 1, 5, 0, 4, 5, 6, 4, 6, 5, 3,\n",
       "          3, 5, 6, 4, 4, 4, 4, 6, 5, 0, 2, 2, 0, 3, 5, 6, 0, 6, 0, 5, 6, 6, 5, 3,\n",
       "          4, 4, 4, 5, 3, 2, 4, 0, 3, 0, 6, 0, 1, 1, 6, 1], device='cuda:0')),\n",
       " (tensor([-4.9284e-01, -9.9296e-05, -8.7638e-01, -6.0310e-01, -1.3173e+00,\n",
       "          -4.5022e-03, -6.2794e-01, -8.7676e-01, -8.4042e-01, -9.0257e-03,\n",
       "          -6.4964e-01, -5.9053e-03, -6.1274e-01, -8.8839e-01, -1.2936e+00,\n",
       "          -8.1537e-01, -4.2250e-01, -2.1483e-01, -7.8254e-01, -8.6461e-01,\n",
       "          -5.7628e-01, -5.5924e-02, -8.7543e-02, -1.0883e+00, -1.2474e+00,\n",
       "          -3.0988e-03, -9.3449e-01, -8.8796e-01, -1.0981e+00, -1.2297e-03,\n",
       "          -5.3631e-01, -1.3943e+00, -3.6344e-01, -5.7633e-02, -1.4361e+00,\n",
       "          -8.5679e-01, -9.3929e-01, -2.9682e-02, -1.0552e+00, -1.0352e+00,\n",
       "          -1.2413e-02, -2.1525e-03, -5.2909e-03, -1.0467e+00, -2.1907e-01,\n",
       "          -6.0013e-01, -6.1443e-03, -5.3278e-01, -7.3221e-01, -2.7832e-01,\n",
       "          -9.0693e-01, -1.2778e-04, -9.6737e-01, -5.5437e-01, -1.2546e+00,\n",
       "          -1.2076e+00, -2.1795e-03, -7.6847e-01, -1.9163e-01, -1.8062e-03,\n",
       "          -8.4855e-01, -3.5074e-01, -2.9869e-01, -8.4667e-01], device='cuda:0'),\n",
       "  tensor([5, 6, 4, 5, 1, 6, 2, 5, 0, 6, 4, 6, 5, 1, 3, 1, 1, 0, 5, 5, 1, 6, 3, 4,\n",
       "          4, 6, 0, 5, 4, 2, 2, 1, 5, 6, 3, 5, 4, 2, 4, 4, 0, 6, 6, 3, 4, 5, 6, 5,\n",
       "          0, 4, 4, 4, 3, 4, 5, 4, 0, 6, 1, 1, 0, 6, 0, 3], device='cuda:0')),\n",
       " (tensor([-4.9329e-01, -6.6115e-01, -1.2201e+00, -8.7055e-01, -1.1353e+00,\n",
       "          -6.0433e-01, -6.1335e-01, -4.7811e-01, -8.4288e-01, -1.4875e-02,\n",
       "          -9.2738e-01, -1.1188e+00, -1.3911e-01, -1.2308e+00, -5.0770e-01,\n",
       "          -7.3685e-03, -1.2752e+00, -5.7573e-04, -7.0881e-01, -1.2245e+00,\n",
       "          -1.0293e+00, -6.8275e-01, -1.0508e-01, -5.2354e-03, -9.7810e-01,\n",
       "          -5.6964e-01, -8.7903e-01, -9.2336e-01, -1.2780e+00, -1.0191e+00,\n",
       "          -9.8756e-03, -8.5941e-01, -1.3164e+00, -5.5556e-01, -5.9981e-01,\n",
       "          -1.4292e+00, -8.2188e-01, -1.7354e-02, -6.5771e-01, -8.0660e-04,\n",
       "          -1.2768e+00, -9.4148e-01, -5.6475e-01, -7.8357e-01, -7.5504e-01,\n",
       "          -4.4517e-03, -6.6065e-01, -6.8209e-01, -5.1691e-01, -1.7048e-01,\n",
       "          -1.7549e-02, -7.1580e-01, -1.6213e-01, -7.7697e-01, -1.2237e+00,\n",
       "          -1.1243e+00, -5.9612e-01, -3.8018e-01, -9.0732e-01, -1.2986e+00,\n",
       "          -1.0512e+00, -1.0513e+00, -1.2327e+00, -3.6201e-01], device='cuda:0'),\n",
       "  tensor([5, 3, 4, 1, 5, 5, 2, 5, 4, 1, 0, 4, 0, 6, 5, 5, 1, 6, 3, 1, 2, 1, 6, 2,\n",
       "          4, 5, 3, 2, 3, 1, 6, 5, 1, 5, 5, 3, 4, 6, 3, 5, 1, 4, 5, 2, 2, 6, 6, 2,\n",
       "          1, 1, 1, 5, 0, 1, 6, 3, 5, 0, 4, 2, 5, 1, 6, 4], device='cuda:0')),\n",
       " (tensor([-2.2298e-01, -1.3884e-02, -6.2855e-01, -1.1780e+00, -8.4314e-01,\n",
       "          -2.8096e-01, -9.8545e-01, -6.5127e-01, -8.2805e-01, -1.0109e+00,\n",
       "          -1.2078e+00, -4.0987e-01, -1.0365e+00, -1.1429e+00, -1.7465e-01,\n",
       "          -7.4072e-01, -7.4266e-01, -7.9625e-03, -8.1732e-04, -9.7755e-01,\n",
       "          -1.1956e-01, -9.6720e-01, -6.2960e-02, -8.6192e-01, -1.5686e+00,\n",
       "          -1.0831e+00, -1.0149e-02, -7.7381e-01, -8.5946e-01, -1.2124e+00,\n",
       "          -4.0452e-01, -5.9998e-01, -1.2196e+00, -5.8299e-01, -6.2406e-01,\n",
       "          -1.1254e+00, -1.4648e+00, -5.7731e-01, -7.9183e-01, -4.5524e-01,\n",
       "          -7.0440e-01, -7.5753e-01, -1.0470e+00, -3.0415e-03, -6.1638e-01,\n",
       "          -1.2183e+00, -7.8822e-01, -1.4805e+00, -8.7421e-01, -1.0800e+00,\n",
       "          -1.2323e+00, -1.4266e+00, -5.2137e-03, -9.7209e-01, -8.3318e-01,\n",
       "          -7.5059e-01, -7.5979e-04, -1.0985e+00, -8.3850e-01, -8.7696e-01,\n",
       "          -1.0316e+00, -4.1162e-01, -6.8146e-01, -4.6954e-01], device='cuda:0'),\n",
       "  tensor([6, 6, 3, 4, 3, 6, 4, 0, 3, 0, 4, 0, 4, 4, 6, 3, 1, 3, 3, 5, 6, 1, 6, 5,\n",
       "          5, 4, 6, 2, 0, 3, 5, 0, 3, 5, 1, 0, 3, 5, 3, 0, 5, 2, 1, 6, 0, 3, 1, 1,\n",
       "          1, 5, 2, 3, 3, 3, 3, 4, 4, 2, 4, 1, 0, 0, 5, 5], device='cuda:0')),\n",
       " (tensor([-1.5553e-03, -1.1359e-02, -1.0059e+00, -4.3800e-01, -1.9694e-03,\n",
       "          -1.2086e+00, -1.1989e+00, -3.1794e-03, -4.1198e-01, -8.5061e-03,\n",
       "          -5.9572e-02, -9.8200e-01, -9.2814e-01, -1.2769e+00, -1.1524e+00,\n",
       "          -4.6777e-01, -1.2234e+00, -8.7997e-04, -5.8858e-01, -1.0537e+00,\n",
       "          -6.1259e-01, -1.2075e+00, -1.0005e+00, -7.2439e-01, -4.6464e-02,\n",
       "          -4.5400e-01, -8.5575e-01, -6.6451e-01, -9.0050e-01, -1.2098e+00,\n",
       "          -2.1016e-02, -5.3094e-01, -1.2193e+00, -1.2467e+00, -1.0272e-03,\n",
       "          -1.2252e+00, -5.7880e-01, -1.3505e+00, -8.6141e-01, -1.0569e+00,\n",
       "          -8.5282e-01, -5.3701e-01, -8.0893e-01, -1.1699e+00, -1.3529e+00,\n",
       "          -8.2745e-04, -1.1431e+00, -6.1037e-01, -1.9152e-02, -9.1411e-01,\n",
       "          -1.1353e+00, -9.9959e-01, -1.1358e+00, -3.1239e-01, -8.1246e-01,\n",
       "          -9.1340e-01, -6.2995e-01, -1.1228e+00, -8.7758e-01, -1.1541e+00,\n",
       "          -9.0372e-01, -1.0496e+00, -4.4153e-01, -1.7611e-01], device='cuda:0'),\n",
       "  tensor([2, 5, 6, 2, 4, 1, 4, 6, 5, 6, 6, 4, 2, 3, 1, 0, 5, 2, 4, 4, 0, 3, 3, 1,\n",
       "          6, 0, 4, 2, 4, 0, 6, 5, 2, 1, 6, 1, 1, 2, 5, 4, 1, 5, 5, 3, 4, 2, 3, 0,\n",
       "          0, 4, 1, 6, 5, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4], device='cuda:0')),\n",
       " (tensor([-1.0320e+00, -1.2731e+00, -9.3726e-01, -5.1998e-01, -7.5791e-01,\n",
       "          -9.3748e-01, -5.3233e-01, -9.9248e-01, -4.8112e-01, -1.0087e+00,\n",
       "          -8.9596e-01, -1.2334e+00, -5.7129e-01, -1.0496e+00, -7.9035e-01,\n",
       "          -7.1812e-01, -9.6411e-01, -5.3078e-01, -1.5534e+00, -2.5406e-01,\n",
       "          -8.9152e-01, -1.2145e+00, -1.9211e-01, -1.6999e-03, -1.2141e+00,\n",
       "          -3.1526e-04, -5.9605e-01, -3.6143e-03, -5.5730e-02, -5.1105e-01,\n",
       "          -6.7656e-01, -2.4301e-03, -2.4604e-03, -5.1820e-01, -1.0756e+00,\n",
       "          -2.1470e-02, -1.0847e+00, -5.5287e-01, -8.7485e-01, -1.0382e+00,\n",
       "          -7.3962e-03, -1.0466e-02, -1.3351e+00, -7.2374e-01, -3.5507e-01,\n",
       "          -3.9558e-03, -2.6697e-02, -1.3252e+00, -2.7806e-03, -4.6380e-02,\n",
       "          -1.0098e+00, -5.8165e-01, -2.3378e-03, -9.9140e-01, -1.1582e+00,\n",
       "          -1.3539e+00, -1.2773e+00, -8.3290e-01, -6.0715e-01, -1.7199e-03,\n",
       "          -9.6487e-01, -1.1831e-02, -2.3088e-01, -1.1428e+00], device='cuda:0'),\n",
       "  tensor([2, 5, 5, 0, 1, 5, 5, 2, 6, 0, 4, 1, 1, 4, 4, 4, 1, 5, 4, 6, 3, 6, 4, 0,\n",
       "          5, 4, 1, 1, 6, 0, 3, 4, 4, 0, 0, 3, 1, 0, 2, 1, 2, 1, 2, 2, 5, 5, 3, 3,\n",
       "          2, 6, 4, 4, 2, 0, 5, 1, 5, 0, 3, 0, 3, 0, 6, 4], device='cuda:0')),\n",
       " (tensor([-9.1849e-01, -1.1103e+00, -6.5646e-01, -4.4325e-03, -1.2045e+00,\n",
       "          -5.7013e-01, -1.4435e+00, -2.9187e-01, -1.0664e+00, -4.6270e-01,\n",
       "          -1.3105e+00, -7.1383e-03, -7.6439e-01, -8.3176e-02, -2.5587e-01,\n",
       "          -2.8014e-03, -8.4491e-01, -2.0526e-04, -6.1565e-01, -5.6883e-01,\n",
       "          -1.0361e+00, -3.2444e-03, -1.1577e+00, -8.9402e-01, -2.9905e-01,\n",
       "          -6.4426e-01, -4.7495e-02, -1.2867e+00, -2.3148e-02, -6.3106e-01,\n",
       "          -5.2884e-01, -1.1059e+00, -1.9950e-03, -1.7732e-03, -8.8517e-01,\n",
       "          -8.6407e-01, -3.1695e-01, -1.3214e+00, -1.2043e+00, -4.3422e-01,\n",
       "          -1.1220e+00, -1.0130e-02, -1.1656e+00, -1.2519e+00, -5.7144e-01,\n",
       "          -3.0544e-03, -9.4366e-03, -8.3607e-01, -7.9860e-01, -6.8601e-01,\n",
       "          -3.4860e-02, -1.0020e+00, -3.2944e-01, -6.9021e-01, -7.3385e-01,\n",
       "          -4.4820e-01, -2.3754e-01, -5.3249e-04, -9.0557e-01, -7.5273e-02,\n",
       "          -3.4020e-01, -9.5624e-01, -3.9200e-01, -1.1020e+00], device='cuda:0'),\n",
       "  tensor([5, 3, 5, 6, 2, 3, 2, 1, 4, 5, 3, 6, 3, 6, 0, 6, 0, 4, 5, 5, 5, 6, 2, 6,\n",
       "          6, 5, 6, 0, 1, 5, 4, 6, 4, 4, 4, 5, 0, 3, 6, 6, 3, 0, 6, 5, 4, 5, 6, 4,\n",
       "          1, 3, 2, 5, 0, 0, 6, 6, 6, 6, 5, 0, 6, 0, 2, 2], device='cuda:0')),\n",
       " (tensor([-1.2159e+00, -5.4944e-02, -1.2861e+00, -6.9950e-01, -1.0234e-01,\n",
       "          -1.3904e+00, -5.3126e-01, -4.8918e-01, -1.0897e+00, -2.2457e-04,\n",
       "          -1.1436e+00, -4.4114e-01, -5.6888e-01, -8.8944e-01, -4.6674e-02,\n",
       "          -3.1114e-02, -1.9402e-03, -9.6200e-01, -1.7336e-02, -1.0424e+00,\n",
       "          -5.1536e-01, -3.8836e-03, -7.0981e-01, -9.1945e-01, -7.3667e-01,\n",
       "          -1.5538e-02, -3.6966e-01, -1.3181e+00, -6.2942e-01, -3.4500e-03,\n",
       "          -8.7196e-01, -2.3553e-04, -1.5013e-01, -7.1261e-01, -1.3400e+00,\n",
       "          -3.3780e-01, -6.7191e-01, -9.9080e-01, -6.1099e-01, -1.0881e+00,\n",
       "          -2.5217e-01, -8.3373e-01, -9.3483e-01, -2.9849e-02, -5.4510e-03,\n",
       "          -9.6661e-01, -1.0964e+00, -8.2090e-01, -7.0061e-01, -7.1397e-01,\n",
       "          -1.0568e+00, -1.0495e+00, -7.2863e-01, -5.7191e-01, -9.3359e-01,\n",
       "          -7.9141e-01, -5.9464e-01, -7.8288e-01, -8.2371e-01, -1.9519e-01,\n",
       "          -9.7578e-03, -2.8611e-03, -5.0162e-01, -4.5507e-01], device='cuda:0'),\n",
       "  tensor([1, 4, 4, 5, 6, 2, 1, 4, 4, 6, 4, 4, 0, 4, 6, 6, 5, 3, 5, 1, 4, 1, 4, 3,\n",
       "          1, 6, 6, 2, 4, 1, 1, 6, 6, 0, 5, 3, 2, 1, 4, 1, 6, 0, 1, 5, 1, 5, 1, 5,\n",
       "          5, 0, 1, 1, 4, 3, 2, 5, 3, 0, 0, 6, 6, 5, 4, 5], device='cuda:0')),\n",
       " (tensor([-1.1869e+00, -7.5368e-03, -1.2721e+00, -2.7734e-02, -7.9261e-01,\n",
       "          -1.3216e+00, -8.3331e-03, -9.8627e-02, -1.1866e+00, -1.1482e+00,\n",
       "          -8.8771e-01, -4.8729e-01, -1.7736e-03, -4.7389e-01, -6.1441e-03,\n",
       "          -4.5810e-03, -1.0639e-01, -1.5613e-02, -3.9423e-02, -8.9126e-01,\n",
       "          -1.1450e+00, -6.5951e-01, -3.6523e-01, -1.3739e-02, -2.9912e-01,\n",
       "          -8.4593e-01, -4.1738e-04, -1.1546e-01, -1.2320e+00, -4.9386e-01,\n",
       "          -2.2899e-01, -6.8772e-01, -1.2246e-01, -6.2887e-04, -1.2927e+00,\n",
       "          -1.9179e-03, -6.5704e-01, -3.9360e-03, -2.9120e-03, -6.6619e-01,\n",
       "          -1.1666e+00, -6.4023e-01, -7.3779e-01, -6.1789e-01, -1.0177e+00,\n",
       "          -7.8874e-04, -8.4787e-01, -8.4709e-01, -6.4895e-01, -8.2779e-01,\n",
       "          -9.0324e-02, -2.3388e-01, -1.3469e+00, -8.3267e-01, -1.0667e+00,\n",
       "          -4.2413e-01, -8.8963e-01, -1.3812e+00, -1.1026e+00, -1.0650e+00,\n",
       "          -2.9310e-01, -1.4691e+00, -1.9644e-02, -3.2627e-01], device='cuda:0'),\n",
       "  tensor([3, 6, 5, 5, 1, 3, 6, 1, 1, 5, 2, 3, 6, 5, 6, 6, 0, 1, 2, 4, 3, 1, 5, 1,\n",
       "          4, 4, 5, 0, 2, 4, 0, 4, 6, 6, 4, 6, 3, 5, 5, 1, 4, 0, 0, 6, 4, 4, 4, 5,\n",
       "          2, 4, 1, 0, 2, 0, 0, 6, 1, 2, 4, 6, 6, 3, 4, 1], device='cuda:0')),\n",
       " (tensor([-9.2025e-05, -1.0263e-03, -7.8906e-01, -1.0184e+00, -6.8857e-02,\n",
       "          -1.1899e+00, -4.4569e-03, -7.7313e-01, -4.7510e-01, -1.5263e+00,\n",
       "          -2.6624e-02, -1.3255e+00, -7.7009e-01, -1.2562e+00, -8.2883e-01,\n",
       "          -7.9358e-03, -1.4362e-03, -6.6572e-03, -1.9620e-04, -1.0298e+00,\n",
       "          -9.3224e-01, -2.1577e-05, -4.0401e-01, -9.6912e-05, -8.2610e-01,\n",
       "          -8.2054e-01, -4.3362e-01, -1.0584e+00, -1.0392e+00, -1.0299e-03,\n",
       "          -1.0197e+00, -3.3830e-03, -3.9353e-01, -1.1362e+00, -4.1681e-01,\n",
       "          -1.1378e+00, -2.5208e-03, -9.5340e-01, -1.2602e+00, -1.4897e-03,\n",
       "          -3.1090e-01, -4.2496e-01, -6.8197e-01, -1.0716e-03, -1.3922e+00,\n",
       "          -9.9823e-01, -2.0285e-01, -7.7826e-01, -1.1209e+00, -1.1046e+00,\n",
       "          -1.9417e-01, -5.9241e-01, -4.7669e-01, -1.3101e+00, -4.3323e-04,\n",
       "          -5.3965e-01, -9.0803e-01, -4.5785e-01, -1.2743e+00, -1.2671e+00,\n",
       "          -7.0526e-01, -1.7116e-01, -8.7226e-01, -1.2233e+00], device='cuda:0'),\n",
       "  tensor([2, 6, 4, 5, 6, 0, 5, 3, 1, 1, 0, 3, 4, 1, 4, 6, 5, 6, 6, 1, 0, 4, 5, 4,\n",
       "          3, 5, 0, 5, 4, 5, 0, 6, 3, 4, 4, 2, 3, 3, 4, 6, 3, 4, 6, 4, 1, 5, 6, 4,\n",
       "          4, 4, 4, 5, 5, 5, 5, 5, 3, 5, 4, 0, 4, 0, 5, 4], device='cuda:0')),\n",
       " (tensor([-1.1684e+00, -8.9462e-01, -6.3491e-01, -1.1062e-02, -2.7927e-01,\n",
       "          -4.7400e-01, -4.9494e-01, -9.5432e-01, -2.6339e-01, -6.5185e-01,\n",
       "          -1.2022e+00, -6.0973e-01, -2.1048e-03, -7.5620e-01, -1.0511e+00,\n",
       "          -9.3866e-01, -3.9519e-01, -9.4579e-01, -2.0122e-01, -1.0872e+00,\n",
       "          -6.7365e-01, -7.0341e-01, -1.4401e-03, -1.0990e+00, -4.0017e-01,\n",
       "          -1.8901e-03, -9.7062e-01, -1.2461e+00, -6.9411e-01, -7.9128e-01,\n",
       "          -2.4504e-03, -2.4521e-01, -1.0556e+00, -1.3428e+00, -6.6146e-01,\n",
       "          -1.0239e+00, -2.5161e-03, -1.2657e+00, -5.1271e-01, -1.5344e-02,\n",
       "          -1.1158e+00, -4.4265e-04, -5.9336e-02, -6.8208e-01, -1.0747e+00,\n",
       "          -1.0401e+00, -3.8187e-02, -5.8121e-03, -1.3578e-01, -6.1853e-01,\n",
       "          -7.5698e-01, -1.0372e+00, -8.5413e-04, -1.3658e+00, -1.1271e+00,\n",
       "          -6.9469e-02, -6.7736e-03, -5.4425e-01, -1.9722e-01, -1.1984e+00,\n",
       "          -6.7316e-01, -1.4180e+00, -2.0985e-01, -7.5078e-01], device='cuda:0'),\n",
       "  tensor([2, 0, 5, 6, 4, 1, 6, 1, 1, 1, 1, 0, 4, 3, 1, 1, 0, 0, 4, 5, 0, 0, 6, 4,\n",
       "          2, 2, 4, 5, 1, 5, 0, 0, 4, 2, 5, 1, 3, 1, 5, 3, 3, 4, 3, 5, 5, 0, 5, 6,\n",
       "          1, 3, 5, 4, 2, 1, 1, 2, 6, 5, 0, 6, 4, 2, 6, 3], device='cuda:0')),\n",
       " (tensor([-4.5778e-04, -8.2626e-04, -8.3505e-01, -1.0961e+00, -1.1676e+00,\n",
       "          -5.1688e-01, -5.5498e-01, -6.2323e-01, -1.0885e+00, -8.4234e-03,\n",
       "          -9.8616e-01, -5.1582e-01, -1.0292e+00, -5.8007e-03, -9.0476e-01,\n",
       "          -1.2785e+00, -7.5461e-01, -8.9547e-01, -7.2054e-01, -9.1584e-01,\n",
       "          -2.5835e-03, -8.4739e-01, -1.3003e+00, -5.0462e-01, -1.0139e+00,\n",
       "          -6.0733e-01, -6.4693e-01, -1.0490e+00, -1.1077e+00, -9.8543e-01,\n",
       "          -5.9722e-01, -8.0636e-04, -8.0846e-01, -1.0725e+00, -4.5969e-01,\n",
       "          -2.2718e-02, -3.2970e-01, -9.5491e-01, -6.1871e-01, -2.7043e-01,\n",
       "          -4.5252e-03, -1.0646e+00, -1.4474e-02, -3.8547e-01, -8.0054e-01,\n",
       "          -8.9695e-01, -5.1307e-01, -1.4529e-01, -1.2061e+00, -7.9850e-01,\n",
       "          -8.8204e-01, -7.7049e-02, -4.0455e-01, -1.5098e+00, -9.9870e-01,\n",
       "          -4.1549e-03, -1.2285e+00, -3.1454e-01, -6.8238e-01, -7.2211e-01,\n",
       "          -6.2655e-01, -1.9997e-01, -7.4067e-01, -8.6195e-01], device='cuda:0'),\n",
       "  tensor([6, 4, 4, 3, 5, 2, 6, 4, 4, 5, 6, 4, 4, 6, 0, 2, 6, 5, 3, 2, 0, 2, 3, 4,\n",
       "          3, 5, 4, 0, 2, 1, 1, 6, 1, 1, 4, 1, 4, 3, 1, 0, 6, 4, 6, 6, 5, 4, 6, 1,\n",
       "          4, 4, 4, 6, 6, 2, 3, 6, 2, 2, 6, 4, 3, 6, 3, 3], device='cuda:0')),\n",
       " (tensor([-9.1511e-04, -1.0404e+00, -1.9862e-01, -1.1363e+00, -7.6608e-01,\n",
       "          -9.6089e-01, -1.8746e-01, -1.3488e+00, -4.7373e-01, -1.4446e+00,\n",
       "          -1.0443e+00, -4.9444e-01, -3.2692e-03, -7.9022e-02, -9.9269e-01,\n",
       "          -4.8640e-01, -9.8130e-01, -7.5678e-01, -1.2090e-03, -8.1706e-01,\n",
       "          -7.6165e-01, -7.2143e-01, -1.4090e+00, -9.6376e-01, -1.2593e+00,\n",
       "          -1.1522e+00, -8.9766e-01, -9.6878e-01, -2.1462e-03, -6.7022e-01,\n",
       "          -2.1254e-02, -1.2282e+00, -2.0146e-03, -4.7291e-04, -1.1221e+00,\n",
       "          -5.6158e-03, -8.3418e-03, -9.5874e-01, -6.0482e-01, -1.4475e-01,\n",
       "          -4.2697e-02, -9.9111e-01, -1.0900e+00, -9.8084e-01, -5.0556e-01,\n",
       "          -5.6768e-01, -1.0677e+00, -3.4326e-04, -1.1723e+00, -7.3406e-01,\n",
       "          -4.3754e-01, -8.6306e-01, -3.7063e-01, -8.1990e-01, -1.0493e+00,\n",
       "          -7.1721e-01, -1.3988e+00, -5.4797e-01, -7.8541e-01, -4.2104e-01,\n",
       "          -4.1597e-01, -1.0897e-03, -9.8883e-01, -5.2936e-01], device='cuda:0'),\n",
       "  tensor([3, 2, 1, 4, 0, 4, 0, 1, 1, 6, 4, 0, 6, 1, 5, 4, 3, 4, 5, 5, 4, 6, 4, 1,\n",
       "          4, 4, 3, 2, 6, 2, 3, 1, 0, 2, 0, 6, 6, 5, 4, 4, 6, 4, 4, 1, 0, 5, 4, 6,\n",
       "          1, 3, 0, 1, 5, 3, 4, 3, 4, 6, 5, 3, 3, 5, 4, 1], device='cuda:0')),\n",
       " (tensor([-5.1038e-01, -1.1342e+00, -1.0340e-03, -3.6381e-01, -3.8053e-01,\n",
       "          -5.6806e-01, -1.2000e+00, -7.0609e-01, -8.4376e-04, -3.3874e-04,\n",
       "          -7.4934e-01, -1.0675e+00, -1.1770e+00, -1.2433e-04, -7.5103e-02,\n",
       "          -9.6823e-01, -6.8095e-01, -2.8612e-02, -1.2916e+00, -4.4537e-02,\n",
       "          -1.1208e+00, -1.2584e+00, -1.0225e+00, -7.8322e-01, -1.0364e+00,\n",
       "          -1.9251e-01, -1.7571e-02, -1.2879e+00, -5.6622e-01, -5.7035e-01,\n",
       "          -1.2013e+00, -6.4084e-01, -1.9793e-02, -8.8749e-01, -1.1899e+00,\n",
       "          -8.1461e-01, -1.3949e+00, -6.0799e-03, -9.1340e-01, -1.0953e+00,\n",
       "          -8.6210e-01, -9.4225e-01, -1.4080e+00, -7.3612e-01, -1.4755e+00,\n",
       "          -2.8325e-03, -9.9160e-01, -1.4855e+00, -1.8328e-03, -1.0611e+00,\n",
       "          -2.3976e-01, -1.3911e+00, -1.2546e+00, -2.2228e-01, -1.1888e+00,\n",
       "          -2.6366e-02, -1.0873e+00, -8.3468e-01, -9.2886e-01, -4.7115e-01,\n",
       "          -6.0855e-01, -4.7099e-03, -1.2185e+00, -1.2774e+00], device='cuda:0'),\n",
       "  tensor([0, 3, 3, 0, 0, 4, 0, 2, 6, 5, 0, 4, 4, 2, 6, 3, 5, 6, 3, 6, 3, 2, 1, 0,\n",
       "          0, 0, 1, 3, 3, 0, 4, 4, 0, 0, 3, 5, 5, 4, 4, 4, 4, 4, 1, 0, 5, 6, 4, 4,\n",
       "          6, 1, 0, 3, 4, 3, 1, 6, 4, 0, 4, 4, 5, 5, 1, 3], device='cuda:0')),\n",
       " (tensor([-3.1951e-03, -7.7021e-02, -1.0451e+00, -8.3941e-01, -7.5503e-02,\n",
       "          -1.3795e+00, -1.2946e+00, -9.0073e-01, -6.6302e-01, -1.2456e+00,\n",
       "          -1.3060e+00, -1.2821e+00, -1.0319e+00, -2.9752e-01, -7.5936e-01,\n",
       "          -1.0040e+00, -9.3745e-01, -9.4786e-04, -1.0699e+00, -4.2132e-01,\n",
       "          -1.8071e-03, -3.6058e-02, -1.2713e+00, -9.4391e-01, -4.9521e-01,\n",
       "          -1.3108e+00, -8.6114e-01, -1.1007e+00, -1.0815e+00, -9.7596e-01,\n",
       "          -4.5007e-01, -7.9262e-01, -2.6834e-03, -1.0695e+00, -1.2238e+00,\n",
       "          -1.2339e+00, -1.0838e+00, -3.4415e-03, -8.5617e-01, -1.0359e+00,\n",
       "          -3.3259e-05, -1.0106e+00, -2.2308e-01, -1.0968e+00, -7.6702e-01,\n",
       "          -2.7464e-01, -8.6284e-01, -1.0854e+00, -7.3150e-01, -1.0663e+00,\n",
       "          -6.0731e-04, -7.7974e-02, -1.0728e+00, -9.0035e-01, -1.2311e+00,\n",
       "          -4.7297e-01, -1.3110e-01, -5.4034e-03, -5.0489e-01, -5.0199e-01,\n",
       "          -1.1691e+00, -9.1469e-01, -9.4280e-01, -5.9134e-01], device='cuda:0'),\n",
       "  tensor([1, 6, 2, 2, 0, 1, 5, 3, 5, 4, 3, 0, 2, 1, 4, 4, 3, 4, 4, 5, 1, 3, 4, 3,\n",
       "          0, 3, 4, 4, 2, 4, 2, 6, 1, 0, 4, 4, 3, 0, 6, 4, 4, 2, 6, 5, 1, 0, 4, 2,\n",
       "          3, 3, 6, 4, 0, 4, 3, 5, 1, 4, 2, 2, 1, 5, 4, 4], device='cuda:0')),\n",
       " (tensor([-9.6318e-03, -2.2145e-02, -4.0364e-02, -8.4210e-01, -1.2789e+00,\n",
       "          -1.3928e+00, -6.7080e-01, -3.1226e-03, -6.0418e-01, -5.2830e-01,\n",
       "          -5.9042e-01, -1.0287e-03, -9.5812e-01, -2.8764e-02, -8.3237e-01,\n",
       "          -1.0013e+00, -1.0335e+00, -8.8145e-02, -9.8383e-01, -4.1722e-01,\n",
       "          -1.0391e+00, -1.6648e-01, -1.2250e+00, -9.1847e-01, -2.8354e-02,\n",
       "          -1.4464e-01, -7.5845e-01, -4.7411e-01, -4.3152e-01, -8.0398e-01,\n",
       "          -8.4309e-01, -8.9783e-01, -2.7907e-01, -4.0545e-03, -1.0132e-04,\n",
       "          -1.1663e+00, -7.6973e-01, -6.9693e-01, -9.0713e-01, -1.2020e+00,\n",
       "          -6.8284e-04, -1.2591e+00, -8.1746e-01, -8.2706e-01, -1.1442e+00,\n",
       "          -2.0204e-01, -1.1087e+00, -5.1283e-04, -7.7578e-01, -9.2946e-01,\n",
       "          -1.5160e-02, -4.3192e-01, -1.0110e+00, -6.9956e-01, -1.0135e+00,\n",
       "          -6.9075e-01, -5.2523e-01, -1.2728e+00, -8.5868e-01, -1.2905e+00,\n",
       "          -5.4988e-04, -4.1940e-01, -6.5232e-01, -6.3330e-02], device='cuda:0'),\n",
       "  tensor([1, 0, 3, 6, 1, 6, 4, 5, 5, 5, 3, 2, 1, 6, 1, 4, 1, 5, 4, 3, 2, 5, 5, 4,\n",
       "          1, 6, 2, 5, 0, 1, 1, 4, 6, 2, 6, 2, 4, 4, 4, 3, 4, 6, 0, 5, 1, 5, 1, 0,\n",
       "          3, 1, 6, 1, 4, 0, 4, 3, 4, 4, 3, 4, 6, 6, 1, 1], device='cuda:0')),\n",
       " (tensor([-1.1629e+00, -8.7483e-01, -1.1730e+00, -2.7343e-02, -4.3606e-03,\n",
       "          -1.1583e+00, -3.4873e-02, -2.9936e-02, -9.7675e-01, -2.9953e-04,\n",
       "          -1.2333e-01, -9.6130e-01, -1.1573e+00, -4.4621e-01, -4.6422e-01,\n",
       "          -8.6101e-03, -3.9382e-02, -4.3201e-01, -7.5298e-01, -1.2320e+00,\n",
       "          -4.8494e-04, -6.1384e-02, -3.2859e-01, -5.8290e-01, -9.6488e-01,\n",
       "          -1.2060e-03, -8.3124e-01, -1.1271e+00, -2.2552e-01, -7.4841e-01,\n",
       "          -1.0085e+00, -8.2528e-02, -6.5489e-01, -1.3294e-03, -2.4790e-01,\n",
       "          -1.0470e+00, -9.7291e-01, -8.9270e-02, -9.0563e-01, -9.8161e-01,\n",
       "          -5.7215e-03, -9.9382e-01, -1.3365e+00, -9.1259e-01, -8.8084e-01,\n",
       "          -1.0264e+00, -1.2808e+00, -8.8200e-01, -1.0446e+00, -3.3612e-01,\n",
       "          -4.6764e-01, -1.0385e+00, -1.9269e-02, -1.3461e+00, -1.8596e-03,\n",
       "          -9.1320e-04, -9.3810e-01, -7.9812e-01, -1.1182e+00, -1.2631e+00,\n",
       "          -7.4855e-01, -4.5429e-01, -5.0136e-03, -7.0525e-03], device='cuda:0'),\n",
       "  tensor([2, 2, 4, 1, 4, 4, 6, 5, 3, 5, 6, 5, 4, 5, 5, 6, 6, 0, 3, 2, 4, 6, 4, 0,\n",
       "          4, 6, 3, 4, 0, 1, 4, 1, 4, 6, 5, 1, 6, 4, 1, 4, 0, 0, 3, 3, 6, 1, 2, 4,\n",
       "          0, 4, 2, 3, 3, 2, 6, 6, 1, 4, 1, 4, 3, 1, 1, 6], device='cuda:0')),\n",
       " (tensor([-8.0608e-01, -1.2838e+00, -9.9826e-02, -1.1996e+00, -1.3495e+00,\n",
       "          -1.3745e+00, -1.7012e-03, -7.2393e-01, -1.2293e+00, -4.9493e-01,\n",
       "          -1.3531e-03, -4.9495e-04, -8.4627e-01, -1.0072e+00, -8.2976e-01,\n",
       "          -1.0935e+00, -1.3525e+00, -2.2741e-02, -2.7129e-01, -1.0383e+00,\n",
       "          -1.8775e-03, -7.5433e-01, -3.6376e-01, -9.5235e-01, -8.7923e-01,\n",
       "          -6.5780e-01, -9.5453e-01, -8.7773e-01, -9.3727e-01, -1.4037e+00,\n",
       "          -4.8329e-01, -4.7442e-01, -6.1635e-01, -9.0271e-02, -1.3640e-03,\n",
       "          -3.9666e-01, -3.3505e-02, -6.8879e-04, -2.0249e-01, -3.0808e-02,\n",
       "          -4.1364e-02, -9.5983e-01, -9.3065e-01, -9.1260e-01, -1.2741e+00,\n",
       "          -4.6886e-01, -1.3836e-01, -4.8110e-01, -7.3937e-01, -7.4303e-01,\n",
       "          -7.2097e-01, -1.2588e+00, -1.8535e-03, -7.8221e-01, -8.4595e-01,\n",
       "          -8.7192e-01, -9.9436e-01, -1.3229e+00, -2.8883e-02, -1.1851e-02,\n",
       "          -1.3135e+00, -1.2090e+00, -6.5865e-04, -7.4319e-01], device='cuda:0'),\n",
       "  tensor([5, 3, 6, 3, 2, 1, 6, 1, 2, 4, 2, 5, 4, 4, 4, 4, 0, 5, 0, 4, 1, 5, 2, 5,\n",
       "          5, 5, 1, 4, 5, 4, 6, 2, 4, 0, 5, 2, 1, 5, 0, 6, 6, 3, 4, 5, 2, 4, 0, 2,\n",
       "          4, 4, 4, 1, 6, 5, 4, 4, 2, 4, 4, 0, 4, 2, 6, 0], device='cuda:0')),\n",
       " (tensor([-1.2342e+00, -2.1408e-04, -1.1731e+00, -8.0820e-01, -1.2185e+00,\n",
       "          -5.1118e-03, -1.0553e+00, -6.6879e-01, -1.3516e-01, -1.3225e+00,\n",
       "          -1.0803e+00, -1.2728e+00, -2.2516e-03, -6.4317e-01, -8.6221e-01,\n",
       "          -1.1429e+00, -8.5037e-01, -1.6932e-03, -8.9150e-01, -2.5170e-01,\n",
       "          -8.3818e-01, -1.8835e-03, -1.1112e+00, -1.1134e+00, -1.1635e+00,\n",
       "          -3.7475e-01, -7.1309e-04, -1.8427e-02, -1.3632e-03, -1.1763e+00,\n",
       "          -2.7627e-01, -4.5034e-01, -9.5690e-01, -1.2798e+00, -9.6329e-01,\n",
       "          -7.5789e-01, -3.3013e-01, -2.5916e-01, -1.2986e+00, -4.2130e-01,\n",
       "          -8.5540e-01, -1.1670e+00, -7.9025e-01, -8.7357e-01, -3.0702e-01,\n",
       "          -2.1530e-03, -6.5452e-01, -1.3668e+00, -5.8435e-01, -2.5066e-02,\n",
       "          -5.1369e-01, -1.0704e+00, -9.1772e-01, -1.8913e-01, -1.0935e+00,\n",
       "          -2.5210e-01, -9.1477e-01, -8.3347e-01, -5.8175e-01, -1.0900e-02,\n",
       "          -6.5958e-01, -8.1893e-05, -1.8726e-01, -3.5217e-03], device='cuda:0'),\n",
       "  tensor([1, 6, 3, 2, 3, 3, 4, 1, 4, 3, 1, 5, 4, 2, 3, 3, 4, 6, 4, 4, 1, 6, 1, 4,\n",
       "          1, 0, 6, 6, 5, 2, 0, 5, 1, 1, 4, 5, 1, 0, 4, 4, 3, 4, 0, 0, 4, 6, 3, 1,\n",
       "          5, 6, 0, 2, 1, 2, 3, 4, 1, 4, 4, 6, 1, 4, 0, 6], device='cuda:0')),\n",
       " (tensor([-3.4922e-03, -1.2528e+00, -3.5256e-04, -1.0442e+00, -5.1528e-01,\n",
       "          -2.0949e-03, -6.4194e-01, -1.7452e-02, -9.2918e-01, -4.0297e-04,\n",
       "          -1.3116e+00, -1.1857e+00, -9.0688e-01, -4.7564e-01, -1.0479e+00,\n",
       "          -1.1521e-01, -4.1157e-02, -2.7706e-03, -6.7039e-01, -1.1405e-02,\n",
       "          -7.1138e-03, -2.8021e-02, -6.1242e-01, -4.6908e-01, -6.0922e-02,\n",
       "          -1.0399e+00, -1.0263e-01, -2.2128e-01, -9.7320e-01, -2.5593e-02,\n",
       "          -1.3885e+00, -2.8179e-03, -2.2434e-01, -1.3061e-02, -1.1082e-03,\n",
       "          -1.7176e-02, -1.2145e-01, -6.5472e-04, -2.6294e-03, -1.0194e+00,\n",
       "          -1.0179e+00, -8.5477e-03, -2.9968e-01, -9.9920e-01, -4.9768e-01,\n",
       "          -2.1824e-01, -1.0977e-02, -1.0825e+00, -5.8240e-01, -1.1745e+00,\n",
       "          -6.5445e-01, -9.0256e-01, -3.0727e-04, -2.3096e-01, -4.6867e-02,\n",
       "          -4.0719e-01, -5.4009e-01, -1.1677e+00, -9.6223e-01, -7.4926e-01,\n",
       "          -1.1353e+00, -1.0367e+00, -1.1309e+00, -4.1333e-04], device='cuda:0'),\n",
       "  tensor([6, 1, 6, 4, 0, 3, 4, 6, 3, 6, 6, 4, 4, 4, 4, 0, 0, 6, 3, 6, 6, 0, 0, 5,\n",
       "          0, 5, 1, 4, 4, 4, 4, 5, 6, 6, 2, 6, 6, 2, 2, 4, 3, 6, 0, 4, 4, 0, 1, 3,\n",
       "          2, 2, 5, 2, 6, 6, 6, 5, 5, 4, 2, 2, 2, 1, 1, 6], device='cuda:0')),\n",
       " (tensor([-3.2367e-01, -4.4468e-01, -4.8980e-01, -4.0332e-01, -7.3513e-04,\n",
       "          -5.5885e-01, -8.7558e-01, -4.9651e-03, -9.4459e-01, -2.6194e-01,\n",
       "          -1.0995e+00, -1.2015e+00, -1.1038e+00, -7.0136e-01, -9.1472e-01,\n",
       "          -7.0144e-01, -5.9441e-03, -3.5194e-02, -4.8648e-01, -1.0421e+00,\n",
       "          -1.3537e+00, -8.5597e-01, -1.8983e-01, -1.1378e+00, -1.1140e+00,\n",
       "          -3.0199e-03, -1.7279e-03, -6.8984e-01, -7.1520e-01, -3.7444e-01,\n",
       "          -1.0285e+00, -3.3325e-04, -2.6078e-01, -5.9253e-01, -2.5308e-01,\n",
       "          -7.8718e-01, -4.4343e-01, -2.5013e-03, -5.3294e-01, -6.0055e-01,\n",
       "          -5.1601e-01, -1.3804e-03, -1.2709e-01, -9.0089e-01, -6.7938e-04,\n",
       "          -1.1363e-03, -2.1010e-02, -1.9160e-03, -3.5957e-02, -8.0613e-04,\n",
       "          -8.6954e-01, -6.6099e-01, -6.7357e-01, -1.5421e-01, -1.4994e-02,\n",
       "          -7.3996e-01, -9.0700e-02, -1.3486e+00, -5.1428e-01, -8.8936e-01,\n",
       "          -1.4448e+00, -7.2614e-01, -9.7183e-01, -3.2794e-03], device='cuda:0'),\n",
       "  tensor([1, 4, 0, 5, 4, 2, 4, 4, 5, 6, 1, 1, 2, 5, 3, 4, 4, 1, 0, 4, 3, 4, 0, 4,\n",
       "          4, 3, 3, 5, 1, 4, 2, 6, 4, 5, 4, 6, 5, 6, 4, 5, 6, 4, 5, 4, 4, 2, 1, 5,\n",
       "          5, 4, 4, 1, 1, 0, 4, 4, 6, 4, 3, 5, 4, 0, 3, 0], device='cuda:0')),\n",
       " (tensor([-7.6663e-03, -8.0795e-01, -1.4905e-02, -9.0022e-01, -9.7351e-01,\n",
       "          -1.9431e-01, -9.5567e-01, -1.3712e+00, -6.9902e-01, -5.0869e-01,\n",
       "          -1.3532e+00, -1.0303e+00, -1.0586e+00, -8.7490e-01, -1.1525e+00,\n",
       "          -5.6574e-01, -7.7265e-04, -1.1962e+00, -5.8701e-02, -9.6611e-01,\n",
       "          -1.0833e+00, -3.2547e-02, -1.2632e-01, -2.4802e-02, -3.5947e-01,\n",
       "          -8.2604e-01, -2.9142e-03, -1.9605e-01, -4.7454e-01, -7.7805e-01,\n",
       "          -9.5963e-01, -1.1360e+00, -2.8392e-04, -3.2452e-03, -1.4457e-03,\n",
       "          -8.6637e-01, -4.3022e-02, -2.0676e-02, -2.8415e-04, -9.2758e-01,\n",
       "          -8.4843e-01, -1.1597e+00, -1.0591e+00, -4.3107e-01, -3.7703e-02,\n",
       "          -2.7124e-03, -1.2683e+00, -8.5962e-01, -2.5567e-01, -4.6166e-01,\n",
       "          -8.8782e-01, -1.6696e-01, -3.8001e-01, -8.2100e-01, -1.4253e+00,\n",
       "          -2.5923e-02, -1.2148e+00, -4.7954e-01, -3.2232e-02, -9.6154e-01,\n",
       "          -1.1819e-01, -1.2372e+00, -9.3131e-01, -1.2723e-03], device='cuda:0'),\n",
       "  tensor([1, 6, 0, 3, 1, 0, 0, 2, 3, 3, 4, 2, 3, 4, 3, 5, 6, 1, 3, 3, 4, 2, 5, 6,\n",
       "          5, 1, 5, 4, 5, 4, 1, 5, 6, 4, 2, 1, 0, 6, 2, 2, 3, 5, 4, 5, 6, 5, 4, 2,\n",
       "          6, 1, 4, 6, 5, 1, 5, 6, 1, 4, 1, 1, 0, 1, 4, 3], device='cuda:0')),\n",
       " (tensor([-7.6889e-01, -1.1375e+00, -9.7225e-03, -1.1921e+00, -7.7802e-01,\n",
       "          -8.5422e-01, -3.2714e-01, -1.0485e+00, -1.1204e+00, -1.0881e-02,\n",
       "          -2.4739e-01, -4.6045e-01, -8.2437e-01, -2.7894e-01, -2.2328e-01,\n",
       "          -6.9754e-01, -1.3971e+00, -1.0528e+00, -1.2682e+00, -7.1965e-01,\n",
       "          -1.0814e+00, -6.2995e-01, -7.5116e-01, -6.1265e-01, -1.9618e-03,\n",
       "          -1.4645e+00, -4.2786e-01, -5.2655e-01, -5.2850e-01, -7.9034e-01,\n",
       "          -6.3431e-01, -8.4882e-01, -1.5913e-04, -2.2058e-03, -2.2952e-01,\n",
       "          -1.0701e+00, -9.3341e-01, -4.5317e-03, -1.5970e-02, -6.2779e-01,\n",
       "          -7.5143e-01, -2.4815e-02, -8.8150e-01, -1.0059e+00, -9.8703e-01,\n",
       "          -8.2064e-01, -3.6517e-03, -9.3429e-01, -1.4343e+00, -7.6459e-01,\n",
       "          -1.6550e-01, -1.3458e+00, -1.0515e+00, -8.0144e-03, -2.7403e-01,\n",
       "          -1.0898e-02, -1.2333e+00, -6.3635e-01, -1.4083e+00, -8.3152e-01,\n",
       "          -1.1662e-01, -1.0537e+00, -8.2116e-01, -1.1414e-03], device='cuda:0'),\n",
       "  tensor([0, 4, 6, 5, 5, 1, 3, 4, 0, 3, 2, 0, 3, 1, 4, 4, 3, 4, 1, 5, 5, 0, 5, 3,\n",
       "          6, 1, 5, 2, 4, 5, 4, 4, 2, 5, 0, 0, 3, 6, 6, 0, 1, 6, 5, 3, 0, 1, 2, 4,\n",
       "          6, 2, 6, 6, 1, 1, 5, 6, 4, 1, 1, 1, 3, 1, 1, 4], device='cuda:0')),\n",
       " (tensor([-4.4649e-01, -1.3547e+00, -1.1227e-03, -1.6444e-01, -1.0946e-03,\n",
       "          -3.4812e-03, -1.8310e-02, -6.9958e-01, -5.5888e-01, -5.0907e-01,\n",
       "          -6.2197e-01, -9.5638e-01, -5.9432e-04, -1.3008e+00, -5.1106e-01,\n",
       "          -1.0867e+00, -8.6446e-01, -9.6854e-01, -8.6180e-01, -6.3307e-01,\n",
       "          -8.7455e-01, -3.0894e-01, -1.2439e+00, -1.7071e-02, -2.3044e-01,\n",
       "          -1.3237e+00, -1.1592e+00, -5.7062e-03, -9.6951e-01, -1.1264e+00,\n",
       "          -7.2198e-02, -1.2216e-03, -1.0052e+00, -6.5972e-01, -3.4969e-01,\n",
       "          -3.8527e-03, -9.5297e-01, -7.6291e-01, -3.8204e-01, -9.5519e-01,\n",
       "          -9.8756e-01, -7.9687e-01, -1.2456e+00, -1.0623e+00, -1.2461e+00,\n",
       "          -1.9147e-03, -1.4305e-01, -6.6379e-01, -4.3309e-01, -1.0636e+00,\n",
       "          -2.7971e-02, -1.5064e-01, -6.2707e-01, -8.4291e-01, -6.0614e-03,\n",
       "          -7.9969e-01, -1.0696e+00, -9.9253e-01, -7.4669e-01, -5.0073e-01,\n",
       "          -9.8638e-03, -1.6370e-01, -1.7067e-01, -9.3162e-01], device='cuda:0'),\n",
       "  tensor([0, 4, 6, 6, 0, 5, 6, 5, 5, 2, 5, 1, 6, 1, 0, 5, 1, 0, 2, 4, 4, 4, 5, 6,\n",
       "          6, 3, 2, 5, 1, 5, 0, 6, 3, 5, 2, 6, 1, 4, 0, 4, 0, 4, 1, 5, 4, 3, 0, 5,\n",
       "          0, 6, 6, 0, 5, 2, 0, 1, 1, 2, 1, 2, 5, 4, 0, 1], device='cuda:0')),\n",
       " (tensor([-7.1232e-01, -9.1287e-01, -1.0890e+00, -8.6015e-01, -4.3057e-01,\n",
       "          -7.7575e-01, -8.4750e-01, -4.8875e-05, -6.1364e-01, -6.2744e-01,\n",
       "          -9.9140e-01, -8.9851e-01, -4.9669e-01, -8.3277e-01, -6.9347e-01,\n",
       "          -2.3386e-02, -8.3787e-01, -6.4899e-01, -1.9254e-02, -5.9448e-01,\n",
       "          -1.1104e+00, -1.2109e+00, -8.5150e-01, -8.5555e-01, -6.6784e-01,\n",
       "          -1.3918e+00, -9.9567e-01, -1.0777e+00, -1.3879e+00, -3.0556e-02,\n",
       "          -6.3623e-01, -2.1081e-03, -3.3112e-03, -3.2410e-01, -6.4096e-01,\n",
       "          -1.0647e+00, -9.8004e-01, -1.3787e+00, -8.8411e-01, -5.4508e-01,\n",
       "          -8.4093e-03, -7.6373e-02, -4.0736e-01, -5.0808e-01, -1.2484e+00,\n",
       "          -7.6688e-01, -1.9569e-03, -1.1870e+00, -9.7930e-01, -2.9753e-03,\n",
       "          -8.6066e-01, -1.2148e-01, -9.1144e-01, -9.7196e-01, -1.5601e-03,\n",
       "          -4.2516e-01, -7.2624e-01, -1.0122e+00, -6.4792e-01, -4.1730e-03,\n",
       "          -5.9227e-03, -1.0795e+00, -1.0102e+00, -1.1064e+00], device='cuda:0'),\n",
       "  tensor([0, 0, 4, 5, 2, 3, 4, 6, 1, 2, 0, 4, 5, 5, 4, 1, 2, 5, 4, 6, 6, 3, 6, 3,\n",
       "          5, 1, 5, 1, 4, 5, 6, 4, 2, 0, 3, 1, 4, 5, 4, 0, 0, 6, 4, 3, 2, 4, 5, 1,\n",
       "          1, 6, 6, 0, 4, 0, 2, 6, 0, 2, 2, 6, 6, 4, 1, 1], device='cuda:0')),\n",
       " (tensor([-1.5973e-04, -9.3710e-01, -1.0820e+00, -8.6142e-01, -8.1872e-01,\n",
       "          -1.1535e+00, -1.0563e+00, -1.0594e+00, -7.3720e-01, -5.8877e-03,\n",
       "          -6.1042e-01, -9.2087e-01, -1.3854e-01, -9.8649e-01, -9.3109e-01,\n",
       "          -3.7495e-01, -1.3471e+00, -2.6378e-04, -8.7530e-01, -1.0440e+00,\n",
       "          -4.6686e-01, -4.4130e-01, -5.6237e-01, -1.0293e+00, -3.5621e-01,\n",
       "          -8.2824e-02, -1.1749e-02, -5.6588e-01, -6.6388e-01, -9.6154e-01,\n",
       "          -2.2061e-01, -5.1461e-01, -7.3682e-01, -1.2163e+00, -1.0665e+00,\n",
       "          -1.1608e-02, -3.0134e-01, -9.9874e-01, -1.0093e+00, -1.6647e-03,\n",
       "          -4.4981e-01, -7.9456e-01, -7.2965e-01, -5.4115e-01, -9.2717e-01,\n",
       "          -9.1294e-01, -1.3804e+00, -1.2421e+00, -6.5438e-01, -6.1739e-03,\n",
       "          -1.1379e+00, -5.8111e-03, -9.9818e-01, -8.4228e-01, -8.3607e-02,\n",
       "          -5.9965e-01, -3.9135e-03, -1.4320e+00, -1.7294e-03, -8.2097e-02,\n",
       "          -1.1919e+00, -9.0842e-01, -4.4640e-01, -1.2816e+00], device='cuda:0'),\n",
       "  tensor([2, 5, 4, 1, 3, 1, 1, 5, 0, 6, 4, 4, 6, 6, 1, 1, 2, 4, 4, 2, 4, 3, 5, 1,\n",
       "          0, 6, 6, 5, 5, 1, 4, 4, 5, 1, 4, 6, 0, 1, 2, 3, 6, 4, 1, 1, 3, 5, 1, 4,\n",
       "          3, 5, 3, 2, 5, 4, 2, 4, 5, 3, 5, 3, 1, 2, 2, 3], device='cuda:0')),\n",
       " (tensor([-1.3569e+00, -7.1370e-01, -1.0268e+00, -8.9899e-01, -1.0191e+00,\n",
       "          -1.0411e+00, -2.0424e-01, -9.9273e-03, -1.2481e+00, -9.3887e-01,\n",
       "          -1.0715e+00, -8.7355e-01, -3.3983e-01, -6.0864e-01, -5.8882e-01,\n",
       "          -4.7553e-04, -1.3130e-01, -1.2297e+00, -1.6284e-03, -1.1559e+00,\n",
       "          -1.4005e+00, -3.5629e-01, -7.3227e-04, -1.0242e+00, -4.2074e-03,\n",
       "          -1.0008e+00, -8.0807e-01, -7.8800e-01, -1.0756e+00, -1.4872e-02,\n",
       "          -1.4705e+00, -1.1239e+00, -1.0834e-01, -8.7861e-01, -4.4509e-01,\n",
       "          -9.9928e-01, -6.0675e-01, -1.1263e+00, -5.7750e-01, -5.3502e-03,\n",
       "          -9.3298e-01, -9.5213e-01, -1.1610e+00, -4.6001e-01, -7.8834e-01,\n",
       "          -3.7472e-04, -2.1558e-01, -3.3160e-01, -1.0774e+00, -1.3774e+00,\n",
       "          -5.6265e-01, -1.3014e+00, -1.0092e+00, -9.6168e-04, -1.0359e+00,\n",
       "          -1.2690e+00, -9.5456e-01, -5.4511e-04, -5.0180e-01, -1.0283e-01,\n",
       "          -1.3006e+00, -1.0888e+00, -4.8894e-01, -3.3405e-03], device='cuda:0'),\n",
       "  tensor([4, 4, 2, 0, 3, 5, 0, 3, 4, 4, 6, 3, 0, 5, 2, 6, 0, 2, 2, 5, 3, 5, 6, 4,\n",
       "          5, 1, 4, 4, 4, 0, 4, 2, 6, 2, 6, 1, 3, 2, 4, 6, 4, 6, 4, 0, 4, 6, 6, 0,\n",
       "          2, 1, 5, 3, 5, 4, 1, 2, 4, 5, 2, 4, 3, 1, 0, 4], device='cuda:0')),\n",
       " (tensor([-1.2382e+00, -8.2770e-01, -5.5428e-01, -1.2520e-03, -5.5265e-01,\n",
       "          -1.9391e-03, -8.5138e-03, -8.6582e-01, -1.2538e+00, -5.8951e-01,\n",
       "          -5.9722e-01, -2.1215e-01, -9.0428e-01, -2.5243e-03, -1.0030e+00,\n",
       "          -7.7830e-01, -4.0843e-01, -3.8211e-04, -1.4190e+00, -2.2476e-02,\n",
       "          -1.8682e-02, -6.0853e-01, -7.6859e-01, -1.2171e+00, -4.1612e-01,\n",
       "          -1.2036e+00, -1.4256e+00, -1.1288e+00, -1.0831e+00, -1.0057e-02,\n",
       "          -8.5741e-01, -1.1398e+00, -1.3832e-01, -9.0859e-01, -3.9864e-01,\n",
       "          -3.9012e-01, -5.0336e-01, -1.3479e+00, -1.0596e+00, -4.6146e-01,\n",
       "          -8.1065e-01, -7.8675e-01, -9.0955e-01, -4.4291e-01, -7.2418e-01,\n",
       "          -5.4168e-02, -4.7307e-01, -1.2855e+00, -1.2567e-01, -1.4947e-02,\n",
       "          -9.6172e-01, -5.1427e-01, -9.0680e-01, -1.4894e+00, -7.4158e-01,\n",
       "          -7.5151e-01, -5.2963e-01, -2.4256e-04, -1.3458e+00, -1.1639e+00,\n",
       "          -4.4722e-01, -8.7808e-01, -9.4912e-01, -5.9482e-01], device='cuda:0'),\n",
       "  tensor([3, 3, 2, 5, 4, 3, 6, 0, 5, 3, 5, 0, 5, 5, 3, 1, 5, 2, 2, 2, 6, 5, 0, 4,\n",
       "          1, 1, 1, 5, 1, 0, 4, 4, 0, 0, 4, 4, 5, 4, 0, 6, 1, 2, 1, 5, 3, 6, 3, 5,\n",
       "          6, 0, 1, 0, 0, 0, 5, 3, 2, 4, 6, 2, 6, 3, 4, 3], device='cuda:0')),\n",
       " (tensor([-1.0486e+00, -9.1170e-01, -1.2571e+00, -6.5970e-01, -7.7175e-01,\n",
       "          -1.2787e-01, -1.1221e+00, -5.0476e-01, -8.4308e-01, -1.0915e+00,\n",
       "          -9.3132e-01, -5.3740e-01, -1.0982e+00, -9.9481e-01, -8.3721e-04,\n",
       "          -1.1585e+00, -4.4334e-01, -1.1857e+00, -5.8058e-03, -1.2835e+00,\n",
       "          -8.5014e-01, -8.8569e-05, -8.7580e-04, -1.2400e+00, -8.2292e-01,\n",
       "          -1.0972e+00, -6.8216e-01, -5.5438e-03, -1.5973e-04, -1.1576e+00,\n",
       "          -9.4619e-01, -1.2901e+00, -9.9390e-01, -1.2139e-01, -9.6506e-01,\n",
       "          -7.9318e-01, -8.0095e-01, -5.0001e-01, -1.3838e+00, -9.5482e-05,\n",
       "          -3.2181e-04, -1.0562e+00, -4.0594e-01, -1.0832e+00, -1.0556e+00,\n",
       "          -6.9666e-02, -9.7812e-02, -1.1671e+00, -4.5366e-03, -1.2069e+00,\n",
       "          -1.4506e+00, -9.3288e-01, -9.5524e-04, -3.6902e-03, -6.1105e-01,\n",
       "          -9.8834e-01, -1.1084e+00, -1.1237e+00, -1.4163e+00, -6.3798e-01,\n",
       "          -1.4107e-03, -3.5575e-01, -9.3066e-01, -1.1159e-03], device='cuda:0'),\n",
       "  tensor([3, 5, 3, 2, 1, 0, 3, 4, 2, 1, 4, 0, 4, 5, 6, 5, 0, 0, 6, 3, 5, 4, 6, 4,\n",
       "          2, 5, 2, 6, 4, 5, 1, 3, 1, 0, 3, 5, 2, 3, 4, 6, 6, 4, 2, 5, 4, 6, 1, 1,\n",
       "          6, 4, 0, 0, 6, 6, 5, 1, 4, 3, 1, 5, 5, 5, 1, 5], device='cuda:0')),\n",
       " (tensor([-9.4239e-01, -7.9324e-01, -1.3833e+00, -8.5433e-01, -7.7326e-01,\n",
       "          -8.0435e-01, -1.1790e-01, -6.7480e-02, -9.2647e-01, -4.6585e-01,\n",
       "          -9.1290e-01, -1.3413e+00, -5.4587e-01, -1.9975e-03, -9.9494e-01,\n",
       "          -1.0349e-01, -9.8145e-01, -1.3099e+00, -1.3147e+00, -8.6584e-01,\n",
       "          -1.5122e-01, -1.1879e+00, -5.3877e-01, -1.0863e+00, -9.5149e-01,\n",
       "          -6.8206e-01, -1.0101e+00, -2.8164e-02, -1.0222e+00, -8.8986e-04,\n",
       "          -3.8669e-02, -1.1462e+00, -1.0597e+00, -1.5725e+00, -6.6246e-03,\n",
       "          -1.9280e-02, -5.6787e-01, -1.2205e+00, -1.1033e-01, -5.5816e-01,\n",
       "          -6.2632e-01, -9.4173e-01, -1.1682e+00, -1.6974e-01, -1.1477e+00,\n",
       "          -3.6333e-01, -8.0787e-01, -1.0459e+00, -1.2698e+00, -5.7604e-01,\n",
       "          -4.8818e-01, -1.4225e+00, -1.7170e-01, -1.1003e+00, -8.9567e-03,\n",
       "          -4.3199e-03, -1.0831e+00, -7.3844e-01, -2.0324e-01, -1.0273e+00,\n",
       "          -1.1235e+00, -3.0400e-02, -1.1700e+00, -1.0003e+00], device='cuda:0'),\n",
       "  tensor([1, 4, 0, 4, 5, 5, 0, 0, 5, 6, 4, 4, 6, 1, 3, 0, 1, 4, 5, 2, 0, 2, 4, 1,\n",
       "          2, 5, 1, 0, 3, 6, 6, 2, 5, 4, 6, 5, 0, 4, 6, 5, 2, 1, 2, 0, 1, 0, 1, 1,\n",
       "          5, 1, 5, 0, 0, 1, 6, 4, 3, 3, 0, 1, 4, 6, 1, 4], device='cuda:0')),\n",
       " (tensor([-9.1342e-01, -1.0610e+00, -1.0660e+00, -6.3964e-01, -1.8148e-01,\n",
       "          -8.5916e-01, -1.2662e+00, -1.1654e+00, -8.4643e-01, -6.2573e-01,\n",
       "          -1.1463e+00, -6.5962e-01, -8.7776e-01, -1.4393e+00, -8.8299e-01,\n",
       "          -1.1572e+00, -1.8488e-04, -1.0582e+00, -6.8524e-01, -8.1033e-01,\n",
       "          -8.0249e-01, -1.4090e+00, -3.5862e-03, -1.1802e+00, -9.2194e-01,\n",
       "          -9.3186e-01, -1.2046e+00, -5.1710e-02, -7.8573e-01, -2.4361e-02,\n",
       "          -1.6164e-03, -1.0894e+00, -4.6034e-03, -1.0622e+00, -1.0737e+00,\n",
       "          -8.8863e-01, -1.5426e-02, -5.8843e-01, -2.2986e-01, -3.3571e-01,\n",
       "          -1.1427e+00, -4.7692e-01, -7.6885e-01, -1.2000e+00, -7.6254e-01,\n",
       "          -9.8181e-03, -6.7313e-03, -7.3139e-01, -5.3472e-01, -6.4256e-01,\n",
       "          -1.1472e+00, -1.0437e+00, -8.7624e-01, -4.8679e-01, -7.5267e-01,\n",
       "          -4.8487e-01, -1.1312e+00, -7.9587e-01, -1.0200e+00, -7.7696e-01,\n",
       "          -1.1623e+00, -1.3023e+00, -9.9075e-02, -1.3424e-02], device='cuda:0'),\n",
       "  tensor([1, 4, 3, 1, 6, 4, 4, 4, 2, 4, 0, 5, 3, 6, 2, 4, 6, 1, 3, 4, 5, 4, 3, 1,\n",
       "          3, 0, 5, 4, 1, 0, 6, 1, 3, 1, 4, 1, 6, 4, 6, 0, 1, 5, 0, 1, 0, 0, 3, 5,\n",
       "          5, 0, 5, 2, 4, 4, 5, 5, 6, 2, 4, 3, 5, 5, 6, 3], device='cuda:0')),\n",
       " (tensor([-3.6090e-04, -5.0697e-03, -6.1459e-01, -3.1563e-01, -9.7401e-01,\n",
       "          -5.1846e-01, -6.0376e-01, -6.0176e-01, -1.4648e+00, -1.3731e+00,\n",
       "          -1.1576e+00, -5.8575e-01, -7.2006e-01, -4.0294e-01, -7.1045e-01,\n",
       "          -7.7444e-01, -1.6284e-01, -6.2665e-01, -8.0032e-01, -1.1599e+00,\n",
       "          -7.4617e-01, -8.6460e-01, -5.2073e-03, -1.0783e+00, -1.4043e+00,\n",
       "          -1.1616e+00, -1.0879e+00, -8.9697e-01, -7.1527e-01, -1.1417e+00,\n",
       "          -1.1727e+00, -1.2444e+00, -1.3914e-01, -4.9753e-01, -9.7189e-01,\n",
       "          -8.1519e-01, -8.8285e-01, -1.9385e-01, -1.0049e+00, -1.0765e+00,\n",
       "          -7.4539e-01, -9.4462e-01, -3.1870e-03, -3.2169e-01, -8.5367e-01,\n",
       "          -6.1089e-01, -4.9360e-01, -3.5145e-01, -3.9549e-03, -4.4969e-01,\n",
       "          -6.6717e-01, -1.0449e+00, -7.9205e-01, -8.5552e-01, -1.0926e+00,\n",
       "          -1.3808e+00, -1.5375e+00, -4.8894e-01, -1.6041e-03, -1.2000e+00,\n",
       "          -1.0233e+00, -4.2921e-01, -9.0006e-01, -5.8174e-02], device='cuda:0'),\n",
       "  tensor([2, 2, 5, 4, 2, 5, 5, 5, 4, 2, 1, 3, 5, 0, 0, 0, 0, 1, 1, 4, 3, 5, 4, 5,\n",
       "          1, 5, 3, 1, 2, 1, 5, 3, 0, 0, 2, 6, 5, 0, 3, 3, 4, 3, 2, 0, 2, 4, 5, 2,\n",
       "          4, 5, 4, 4, 0, 1, 1, 1, 1, 6, 6, 1, 1, 5, 4, 6], device='cuda:0')),\n",
       " (tensor([-1.1371e+00, -9.2437e-01, -1.3313e+00, -1.2314e+00, -1.9943e-01,\n",
       "          -2.8996e-01, -1.1314e+00, -4.7586e-01, -8.4103e-04, -1.1919e-03,\n",
       "          -7.7416e-01, -6.4026e-02, -9.1187e-01, -1.1892e+00, -1.0320e+00,\n",
       "          -2.8489e-02, -1.0337e+00, -1.0992e+00, -1.6505e-03, -1.2507e+00,\n",
       "          -5.0624e-01, -5.9720e-01, -1.7644e-01, -1.0794e+00, -1.2120e+00,\n",
       "          -4.8969e-01, -1.2614e+00, -1.0417e+00, -6.2042e-01, -1.1390e+00,\n",
       "          -1.1408e+00, -1.2789e+00, -6.8502e-02, -4.8147e-03, -3.9694e-01,\n",
       "          -1.5460e-03, -7.0942e-01, -9.2764e-01, -1.6284e-03, -1.2057e+00,\n",
       "          -7.4412e-01, -2.2153e-01, -7.6493e-01, -8.2221e-01, -1.0341e+00,\n",
       "          -9.6088e-01, -7.1804e-01, -8.6640e-04, -3.5503e-01, -5.9555e-01,\n",
       "          -1.1365e+00, -9.7468e-01, -8.2642e-01, -3.9448e-01, -1.4235e+00,\n",
       "          -1.1984e-01, -9.4254e-01, -1.2677e-03, -1.0680e+00, -1.1473e+00,\n",
       "          -1.0307e+00, -3.8781e-03, -1.1301e+00, -1.4639e+00], device='cuda:0'),\n",
       "  tensor([2, 1, 3, 6, 6, 4, 2, 4, 5, 6, 3, 6, 5, 1, 4, 6, 4, 4, 4, 5, 5, 4, 3, 4,\n",
       "          4, 5, 6, 4, 5, 2, 5, 5, 6, 1, 4, 3, 5, 2, 6, 3, 1, 4, 3, 5, 0, 1, 1, 4,\n",
       "          4, 5, 1, 5, 1, 5, 3, 5, 0, 5, 4, 4, 4, 2, 0, 4], device='cuda:0')),\n",
       " (tensor([-9.3010e-01, -1.2567e-03, -3.3058e-03, -9.0879e-01, -8.9975e-01,\n",
       "          -1.2071e+00, -1.0817e+00, -8.9762e-01, -9.1187e-01, -6.8703e-01,\n",
       "          -4.2204e-01, -1.1079e-03, -9.2869e-03, -5.0036e-01, -1.1469e+00,\n",
       "          -4.6360e-01, -1.2375e-03, -6.1157e-01, -1.3013e+00, -6.8219e-01,\n",
       "          -8.9276e-01, -1.1621e+00, -9.6078e-01, -1.2292e+00, -4.4372e-04,\n",
       "          -9.6001e-01, -6.0112e-01, -1.3508e+00, -8.3036e-01, -7.6841e-01,\n",
       "          -6.1422e-01, -2.8536e-02, -8.7243e-01, -6.5802e-01, -9.4738e-01,\n",
       "          -1.0751e+00, -7.0433e-01, -3.7287e-01, -1.0014e+00, -1.2901e+00,\n",
       "          -3.8458e-01, -6.5508e-01, -1.2373e+00, -2.2695e-04, -8.7646e-01,\n",
       "          -8.1780e-04, -8.8395e-01, -1.0797e+00, -5.7584e-01, -1.1489e+00,\n",
       "          -1.1480e+00, -8.8323e-01, -1.2721e+00, -4.6603e-01, -3.5783e-01,\n",
       "          -9.6149e-01, -7.8959e-01, -9.7470e-01, -6.8526e-01, -1.2467e+00,\n",
       "          -1.9697e-02, -1.0676e+00, -1.3173e-03, -1.9583e-01], device='cuda:0'),\n",
       "  tensor([4, 4, 6, 4, 1, 4, 4, 1, 5, 1, 4, 6, 6, 1, 5, 1, 5, 4, 3, 4, 2, 5, 4, 4,\n",
       "          4, 2, 0, 5, 1, 5, 4, 1, 1, 4, 6, 2, 1, 6, 4, 1, 2, 6, 4, 6, 2, 6, 4, 2,\n",
       "          3, 1, 3, 1, 5, 0, 4, 1, 3, 3, 2, 4, 3, 6, 3, 3], device='cuda:0')),\n",
       " (tensor([-1.0094e+00, -1.3079e+00, -1.8564e-03, -7.0015e-01, -7.2429e-01,\n",
       "          -2.4890e-01, -2.9952e-03, -8.5930e-01, -7.4177e-01, -1.3287e+00,\n",
       "          -1.3398e-04, -2.1232e-02, -4.8499e-01, -3.5787e-01, -3.2796e-02,\n",
       "          -1.0847e-03, -8.0887e-02, -7.4502e-01, -4.4567e-01, -6.3154e-03,\n",
       "          -1.6987e-03, -5.8300e-04, -1.0460e+00, -4.7203e-01, -6.0201e-01,\n",
       "          -1.4372e-02, -7.6704e-01, -9.6805e-01, -5.3949e-01, -1.2286e+00,\n",
       "          -1.2720e+00, -9.9113e-01, -5.3308e-04, -2.1072e-02, -1.3921e+00,\n",
       "          -1.2764e+00, -1.2840e+00, -1.3028e+00, -5.3315e-01, -8.0771e-01,\n",
       "          -7.2169e-02, -1.0526e-02, -8.6212e-01, -1.2230e+00, -9.5223e-01,\n",
       "          -1.2200e+00, -8.9768e-02, -5.5708e-01, -2.4106e-03, -8.4921e-01,\n",
       "          -5.5317e-01, -8.6284e-01, -2.5103e-03, -5.7746e-01, -1.1113e+00,\n",
       "          -1.1887e+00, -1.1280e+00, -7.3068e-01, -1.0665e+00, -6.3569e-01,\n",
       "          -1.1734e+00, -1.3453e-01, -1.2157e-02, -1.4016e+00], device='cuda:0'),\n",
       "  tensor([4, 4, 6, 0, 5, 6, 6, 4, 5, 4, 6, 0, 1, 3, 6, 6, 3, 5, 1, 6, 3, 4, 3, 1,\n",
       "          5, 3, 1, 1, 0, 6, 5, 1, 5, 1, 6, 1, 0, 1, 0, 0, 6, 6, 1, 1, 4, 4, 6, 5,\n",
       "          5, 5, 4, 1, 0, 1, 4, 6, 1, 3, 4, 2, 1, 6, 3, 2], device='cuda:0')),\n",
       " (tensor([-3.7818e-04, -5.9218e-04, -4.4365e-03, -8.1033e-02, -1.8758e-01,\n",
       "          -1.5577e-01, -8.6927e-01, -8.7764e-01, -1.8445e-03, -8.5994e-03,\n",
       "          -1.0912e+00, -2.4633e-03, -1.0865e+00, -1.2225e+00, -6.3737e-01,\n",
       "          -2.7545e-04, -1.0087e+00, -2.0120e-03, -6.3888e-01, -6.2145e-01,\n",
       "          -2.3389e-03, -1.5467e+00, -1.6446e-03, -7.8515e-01, -1.0055e+00,\n",
       "          -9.6447e-01, -1.0478e+00, -9.9200e-01, -2.0516e-01, -1.2247e+00,\n",
       "          -5.2222e-01, -6.8076e-01, -9.6622e-01, -7.0996e-02, -5.4499e-01,\n",
       "          -1.3248e+00, -5.3942e-01, -1.1431e+00, -1.3001e+00, -1.8657e-03,\n",
       "          -6.9409e-01, -4.5480e-04, -8.6860e-01, -6.2735e-03, -6.1065e-01,\n",
       "          -8.6210e-01, -6.5162e-01, -6.6443e-01, -4.2518e-01, -5.1840e-01,\n",
       "          -6.9598e-01, -6.8451e-01, -6.7265e-02, -1.2002e+00, -1.0919e-02,\n",
       "          -1.4008e+00, -6.9796e-01, -1.0731e+00, -3.8023e-01, -1.4296e+00,\n",
       "          -8.6569e-01, -1.0934e+00, -1.3348e-03, -2.5580e-02], device='cuda:0'),\n",
       "  tensor([4, 6, 0, 3, 0, 6, 1, 2, 4, 5, 4, 0, 4, 4, 3, 6, 4, 1, 1, 3, 6, 1, 5, 5,\n",
       "          1, 4, 5, 2, 6, 3, 5, 4, 4, 6, 3, 3, 2, 4, 3, 1, 3, 6, 3, 6, 5, 6, 0, 4,\n",
       "          0, 5, 2, 3, 6, 4, 1, 2, 0, 5, 4, 1, 5, 5, 6, 1], device='cuda:0')),\n",
       " (tensor([-7.3102e-02, -1.4309e+00, -1.5505e-01, -4.8240e-01, -2.0094e-03,\n",
       "          -1.2202e+00, -1.4007e-03, -8.5415e-01, -5.1308e-01, -8.9318e-01,\n",
       "          -1.2252e+00, -1.2787e+00, -1.2348e+00, -1.2634e+00, -9.5533e-01,\n",
       "          -5.2084e-01, -1.0309e+00, -5.4406e-01, -1.2799e+00, -8.7789e-01,\n",
       "          -7.4236e-01, -1.0856e+00, -1.7850e-02, -7.5291e-01, -7.2776e-01,\n",
       "          -5.8787e-01, -1.5759e-01, -9.5069e-01, -4.6794e-02, -1.4425e-01,\n",
       "          -7.6302e-01, -1.1085e+00, -1.0095e+00, -3.8459e-01, -5.9421e-01,\n",
       "          -5.7102e-01, -4.9698e-04, -6.6312e-01, -1.0404e+00, -8.1385e-01,\n",
       "          -7.7337e-01, -8.1328e-01, -5.7886e-01, -6.8699e-01, -1.1960e+00,\n",
       "          -2.3486e-03, -5.0778e-01, -8.5067e-01, -2.6006e-01, -1.5618e-01,\n",
       "          -4.6086e-03, -9.3778e-01, -8.6530e-02, -9.0460e-01, -1.2615e+00,\n",
       "          -4.7236e-01, -8.7163e-03, -1.2479e+00, -1.0120e+00, -5.4605e-01,\n",
       "          -1.1604e-03, -7.6732e-01, -1.0008e+00, -2.4004e-01], device='cuda:0'),\n",
       "  tensor([0, 4, 1, 4, 6, 2, 6, 0, 3, 2, 6, 2, 6, 1, 2, 4, 4, 4, 4, 4, 4, 2, 6, 1,\n",
       "          2, 4, 6, 4, 4, 5, 4, 4, 4, 3, 0, 4, 5, 5, 5, 2, 1, 3, 0, 0, 4, 3, 4, 6,\n",
       "          6, 0, 0, 4, 0, 1, 3, 4, 6, 4, 3, 0, 6, 5, 1, 0], device='cuda:0')),\n",
       " (tensor([-1.4389e-01, -5.7968e-01, -2.1866e-01, -9.3335e-01, -6.9286e-03,\n",
       "          -1.3771e+00, -1.2835e+00, -9.2212e-01, -3.2592e-01, -1.1000e+00,\n",
       "          -5.2355e-04, -1.2574e+00, -9.7253e-01, -5.1662e-01, -5.8437e-01,\n",
       "          -3.3640e-01, -4.2047e-01, -2.7443e-01, -1.3217e+00, -2.7977e-03,\n",
       "          -1.5604e-02, -1.0906e+00, -5.0838e-01, -2.9082e-01, -2.1853e-01,\n",
       "          -4.8289e-01, -5.4799e-02, -1.2392e+00, -7.3973e-01, -3.1414e-01,\n",
       "          -5.6496e-01, -1.1302e-03, -7.5478e-01, -1.1069e+00, -4.6319e-01,\n",
       "          -7.1343e-01, -1.1442e+00, -3.4954e-01, -4.1406e-01, -4.5892e-01,\n",
       "          -6.6528e-01, -5.4747e-01, -1.4864e-03, -9.9828e-01, -8.9405e-01,\n",
       "          -3.7497e-03, -1.9996e-01, -2.3148e-01, -4.3256e-03, -5.1005e-03,\n",
       "          -1.5325e-01, -4.4234e-01, -6.8828e-03, -9.9453e-01, -7.5313e-01,\n",
       "          -1.2413e+00, -8.6574e-01, -1.2209e+00, -8.0925e-01, -1.2007e+00,\n",
       "          -5.3582e-01, -9.8582e-01, -2.2344e-01, -2.6917e-01], device='cuda:0'),\n",
       "  tensor([6, 3, 6, 5, 2, 1, 4, 2, 0, 3, 0, 4, 2, 3, 3, 0, 0, 4, 1, 6, 1, 5, 5, 0,\n",
       "          0, 5, 5, 1, 4, 0, 0, 6, 1, 1, 3, 0, 5, 5, 4, 5, 1, 5, 4, 1, 4, 0, 0, 0,\n",
       "          6, 4, 0, 0, 2, 4, 0, 3, 6, 0, 5, 3, 4, 4, 0, 0], device='cuda:0')),\n",
       " (tensor([-1.6597e-01, -1.3379e-02, -1.1229e+00, -5.6785e-01, -5.3426e-01,\n",
       "          -6.1221e-01, -2.5749e-03, -6.1240e-01, -4.7087e-01, -8.7373e-01,\n",
       "          -1.0437e+00, -8.1768e-02, -5.0518e-01, -7.0569e-01, -1.0857e+00,\n",
       "          -1.1019e+00, -8.8502e-01, -6.3232e-01, -9.0209e-01, -1.2264e+00,\n",
       "          -6.3441e-01, -3.7117e-03, -1.2763e+00, -8.2483e-01, -9.6309e-01,\n",
       "          -1.1381e+00, -8.3840e-01, -2.8514e-01, -4.6879e-01, -9.0520e-01,\n",
       "          -4.7660e-01, -2.6409e-03, -4.3310e-02, -9.4574e-01, -7.9881e-01,\n",
       "          -1.4350e+00, -1.6980e-01, -1.0906e+00, -8.4052e-01, -8.3486e-01,\n",
       "          -7.9523e-01, -6.8870e-03, -5.7265e-01, -1.2970e-01, -1.6815e-03,\n",
       "          -1.0725e+00, -1.4888e-01, -7.5959e-02, -8.3340e-01, -1.2135e+00,\n",
       "          -1.1822e+00, -1.2179e+00, -7.9584e-01, -4.5659e-04, -9.5944e-01,\n",
       "          -6.3117e-03, -1.0114e+00, -1.0093e+00, -4.8768e-01, -1.3589e+00,\n",
       "          -7.1406e-01, -1.2457e+00, -4.9800e-01, -8.7185e-01], device='cuda:0'),\n",
       "  tensor([6, 1, 2, 0, 0, 5, 0, 5, 5, 2, 4, 6, 2, 4, 5, 2, 3, 3, 4, 4, 4, 3, 4, 2,\n",
       "          1, 4, 3, 1, 1, 4, 4, 6, 6, 2, 0, 3, 4, 6, 2, 5, 4, 0, 5, 1, 4, 4, 0, 6,\n",
       "          0, 5, 5, 4, 1, 6, 4, 2, 4, 3, 5, 4, 2, 2, 0, 4], device='cuda:0')),\n",
       " (tensor([-5.2632e-01, -2.9083e-04, -1.2479e+00, -4.3492e-02, -9.3805e-01,\n",
       "          -2.6593e-01, -8.0774e-01, -9.5584e-04, -4.4739e-03, -8.6847e-01,\n",
       "          -4.0375e-01, -1.2576e-03, -3.7976e-01, -1.0985e+00, -1.1295e+00,\n",
       "          -7.8072e-02, -8.0303e-04, -1.5670e+00, -9.4636e-01, -1.2825e-01,\n",
       "          -1.0921e+00, -2.0280e-03, -6.9195e-03, -1.1610e+00, -8.5482e-01,\n",
       "          -5.7071e-01, -8.2756e-01, -5.0125e-01, -6.5712e-01, -6.3673e-04,\n",
       "          -9.5138e-02, -6.9211e-01, -4.3669e-01, -9.6853e-01, -2.3624e-04,\n",
       "          -1.4553e+00, -1.4309e-02, -9.4644e-01, -2.2440e-01, -3.6163e-01,\n",
       "          -1.1947e+00, -1.3264e+00, -5.1978e-01, -7.9935e-01, -7.2896e-01,\n",
       "          -8.7798e-01, -7.5055e-01, -1.1763e+00, -3.9862e-01, -1.2617e+00,\n",
       "          -7.2744e-01, -2.4464e-02, -1.3771e+00, -9.7251e-01, -1.2005e+00,\n",
       "          -8.7421e-01, -5.8407e-04, -1.3629e-03, -5.6103e-01, -1.4759e-02,\n",
       "          -1.5988e-02, -1.0311e+00, -5.1253e-01, -3.5186e-01], device='cuda:0'),\n",
       "  tensor([0, 4, 1, 6, 1, 5, 4, 6, 6, 1, 1, 4, 0, 5, 4, 0, 2, 1, 0, 6, 1, 5, 0, 4,\n",
       "          6, 0, 4, 2, 5, 6, 0, 5, 0, 4, 6, 3, 6, 4, 1, 4, 6, 4, 2, 6, 4, 5, 5, 5,\n",
       "          5, 2, 1, 1, 4, 3, 2, 5, 6, 3, 2, 4, 6, 3, 5, 3], device='cuda:0')),\n",
       " (tensor([-1.6804e-01, -3.9705e-03, -1.1670e+00, -5.4377e-01, -5.6582e-01,\n",
       "          -8.8353e-01, -3.9465e-01, -9.4005e-01, -5.7513e-02, -8.1430e-01,\n",
       "          -2.4396e-02, -9.1926e-01, -2.9562e-02, -1.3852e-01, -7.1735e-01,\n",
       "          -2.6163e-04, -1.1221e+00, -6.5321e-01, -2.3139e-01, -4.9783e-01,\n",
       "          -7.3929e-01, -7.9832e-01, -1.1665e+00, -1.3484e+00, -8.1206e-01,\n",
       "          -1.1849e+00, -1.0583e+00, -9.0940e-01, -7.8500e-01, -9.8177e-01,\n",
       "          -7.3118e-01, -1.8416e-04, -1.3376e-02, -1.2906e+00, -3.2491e-04,\n",
       "          -6.0551e-01, -5.0184e-01, -8.5395e-01, -3.7095e-03, -1.4802e+00,\n",
       "          -1.1940e+00, -1.3536e+00, -1.2480e+00, -5.7326e-01, -6.2324e-01,\n",
       "          -8.3695e-01, -8.0500e-01, -3.6102e-02], device='cuda:0'),\n",
       "  tensor([0, 4, 0, 0, 6, 4, 0, 4, 5, 4, 1, 3, 0, 3, 1, 4, 2, 5, 4, 6, 1, 5, 3, 1,\n",
       "          0, 1, 2, 2, 0, 2, 6, 6, 6, 4, 5, 5, 2, 2, 2, 1, 1, 1, 3, 4, 1, 4, 2, 6],\n",
       "         device='cuda:0'))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T04:39:22.968355Z",
     "start_time": "2024-08-11T04:39:22.955432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.save(model.state_dict(), \"model/model_CNN_L.t\")\n",
    "torch.save(model.state_dict(), \"model/model_CNN_L_B.t\")"
   ],
   "id": "7636fdf1ad603b23",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T03:53:01.241891Z",
     "start_time": "2024-08-09T03:53:01.228612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_model = NetDropout().to(device)\n",
    "loaded_model.load_state_dict(torch.load(\"model/model_CNN_L.t\"))\n",
    "# loaded_model = NetDropoutBig().to(device)\n",
    "# loaded_model.load_state_dict(torch.load(\"model/model_CNN_L_B.t\"))"
   ],
   "id": "5fe886437ea88b2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# New dataset CNN",
   "id": "8840794a544ee7ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Features model",
   "id": "5b967e4a420be904"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:57:13.259292Z",
     "start_time": "2024-08-21T23:57:13.253866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_1(nn.Module):\n",
    "    def __init__(self, n=32):\n",
    "        super(CNN_1, self).__init__()\n",
    "        self.n = n\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, self.n, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout1d(p=0.3)\n",
    "        self.conv2 = nn.Conv1d(self.n, self.n // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout1d(p=0.3)\n",
    "        self.conv3 = nn.Conv1d(self.n // 2, self.n // 2, kernel_size=3, padding=1)\n",
    "        self.conv3_dropout = nn.Dropout1d(p=0.3)\n",
    "\n",
    "        # Calculate the correct input size for the fully connected layer\n",
    "        self.fc1 = nn.Linear((self.n // 2) * (197 // 8), 32)  # 170 // 8 due to three max_pool1d with kernel_size=2\n",
    "        self.fc2 = nn.Linear(32, 7)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool1d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool1d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = F.max_pool1d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = self.conv3_dropout(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.sigmoid(self.fc2(out))\n",
    "        return out\n"
   ],
   "id": "498dce42af19097d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T03:32:24.888285Z",
     "start_time": "2024-08-18T03:32:24.350727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('datasets/dataset_2_1.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, :-7].values  # First 198 columns as features\n",
    "y = df.iloc[:, -7:].values  # Last 7 columns as labels\n",
    "\n",
    "# Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n"
   ],
   "id": "48bbd88aeb4ca42a",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T03:32:31.616289Z",
     "start_time": "2024-08-18T03:32:31.596430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 80% training and 20% testing split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "n_epochs = 1000\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNN_1().to(device)\n",
    "# model = NetDropoutBig().to(device)\n",
    "criterion = nn.BCELoss()  # Assuming multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "753a927894991b0c",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T03:51:06.963888Z",
     "start_time": "2024-08-18T03:32:37.335520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "for epoch in range(n_epochs):  # Number of epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n"
   ],
   "id": "415f145e7a5e0fa0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4486325819151742\n",
      "Epoch 2, Loss: 0.39762668734505063\n",
      "Epoch 3, Loss: 0.38867109071640743\n",
      "Epoch 4, Loss: 0.38247274245534624\n",
      "Epoch 5, Loss: 0.3773257799375625\n",
      "Epoch 6, Loss: 0.3739976100126902\n",
      "Epoch 7, Loss: 0.3711932798226674\n",
      "Epoch 8, Loss: 0.3686487981818971\n",
      "Epoch 9, Loss: 0.3661191771711622\n",
      "Epoch 10, Loss: 0.3632771249044509\n",
      "Epoch 11, Loss: 0.36099889403297786\n",
      "Epoch 12, Loss: 0.3592999704678853\n",
      "Epoch 13, Loss: 0.356257537546612\n",
      "Epoch 14, Loss: 0.3544087184610821\n",
      "Epoch 15, Loss: 0.3521505890573774\n",
      "Epoch 16, Loss: 0.34930519700050355\n",
      "Epoch 17, Loss: 0.34762438671929496\n",
      "Epoch 18, Loss: 0.3452296314920698\n",
      "Epoch 19, Loss: 0.3427830933956873\n",
      "Epoch 20, Loss: 0.34031704664230344\n",
      "Epoch 21, Loss: 0.33802150658198765\n",
      "Epoch 22, Loss: 0.3364326817648751\n",
      "Epoch 23, Loss: 0.3343791537625449\n",
      "Epoch 24, Loss: 0.3327805301121303\n",
      "Epoch 25, Loss: 0.3311699575469607\n",
      "Epoch 26, Loss: 0.32953153269631524\n",
      "Epoch 27, Loss: 0.3278573333081745\n",
      "Epoch 28, Loss: 0.3268139088153839\n",
      "Epoch 29, Loss: 0.32449379097847714\n",
      "Epoch 30, Loss: 0.3232911835397993\n",
      "Epoch 31, Loss: 0.32271278545970006\n",
      "Epoch 32, Loss: 0.32106561711856296\n",
      "Epoch 33, Loss: 0.32032475976716906\n",
      "Epoch 34, Loss: 0.3190529816491263\n",
      "Epoch 35, Loss: 0.3181921929404849\n",
      "Epoch 36, Loss: 0.3173465130442665\n",
      "Epoch 37, Loss: 0.31595355800219943\n",
      "Epoch 38, Loss: 0.31460589999244326\n",
      "Epoch 39, Loss: 0.31347556923116954\n",
      "Epoch 40, Loss: 0.3134496204342161\n",
      "Epoch 41, Loss: 0.31261328390666415\n",
      "Epoch 42, Loss: 0.3113617358888899\n",
      "Epoch 43, Loss: 0.310950758315268\n",
      "Epoch 44, Loss: 0.3102501399460293\n",
      "Epoch 45, Loss: 0.30970072436900364\n",
      "Epoch 46, Loss: 0.30747374702067604\n",
      "Epoch 47, Loss: 0.30804736577329184\n",
      "Epoch 48, Loss: 0.30634847345806304\n",
      "Epoch 49, Loss: 0.3057794606685638\n",
      "Epoch 50, Loss: 0.3061543986910865\n",
      "Epoch 51, Loss: 0.30460468476726893\n",
      "Epoch 52, Loss: 0.3035744242157255\n",
      "Epoch 53, Loss: 0.3032059145541418\n",
      "Epoch 54, Loss: 0.3031918922776268\n",
      "Epoch 55, Loss: 0.30269343242758795\n",
      "Epoch 56, Loss: 0.3018334043309802\n",
      "Epoch 57, Loss: 0.30206091914858135\n",
      "Epoch 58, Loss: 0.30110752188024065\n",
      "Epoch 59, Loss: 0.300494974454244\n",
      "Epoch 60, Loss: 0.29997200846672056\n",
      "Epoch 61, Loss: 0.29922059870901563\n",
      "Epoch 62, Loss: 0.29961721241474154\n",
      "Epoch 63, Loss: 0.2987364837669191\n",
      "Epoch 64, Loss: 0.29780677818116685\n",
      "Epoch 65, Loss: 0.29810898306823913\n",
      "Epoch 66, Loss: 0.2961778711421149\n",
      "Epoch 67, Loss: 0.2965273441303344\n",
      "Epoch 68, Loss: 0.29695826851186297\n",
      "Epoch 69, Loss: 0.29720716709182377\n",
      "Epoch 70, Loss: 0.29599301866122657\n",
      "Epoch 71, Loss: 0.294718479343823\n",
      "Epoch 72, Loss: 0.2948625863166082\n",
      "Epoch 73, Loss: 0.29460600872834525\n",
      "Epoch 74, Loss: 0.29451632039887565\n",
      "Epoch 75, Loss: 0.2944023434888749\n",
      "Epoch 76, Loss: 0.2932591318516504\n",
      "Epoch 77, Loss: 0.293693822593916\n",
      "Epoch 78, Loss: 0.293436628863925\n",
      "Epoch 79, Loss: 0.2930332812524977\n",
      "Epoch 80, Loss: 0.2921241841145924\n",
      "Epoch 81, Loss: 0.29237482550598326\n",
      "Epoch 82, Loss: 0.29195719670681725\n",
      "Epoch 83, Loss: 0.2917587262959707\n",
      "Epoch 84, Loss: 0.29123165059657324\n",
      "Epoch 85, Loss: 0.2911793181442079\n",
      "Epoch 86, Loss: 0.2903111598037538\n",
      "Epoch 87, Loss: 0.2902458779017131\n",
      "Epoch 88, Loss: 0.290153414947646\n",
      "Epoch 89, Loss: 0.29004617322058907\n",
      "Epoch 90, Loss: 0.2900078200158619\n",
      "Epoch 91, Loss: 0.2892288932062331\n",
      "Epoch 92, Loss: 0.2890406347740264\n",
      "Epoch 93, Loss: 0.28830432426361813\n",
      "Epoch 94, Loss: 0.28797675410906476\n",
      "Epoch 95, Loss: 0.28884757615271067\n",
      "Epoch 96, Loss: 0.28824989557266234\n",
      "Epoch 97, Loss: 0.28786590124879563\n",
      "Epoch 98, Loss: 0.28836782898221697\n",
      "Epoch 99, Loss: 0.28548072556654613\n",
      "Epoch 100, Loss: 0.2875578319458734\n",
      "Epoch 101, Loss: 0.2866841755594526\n",
      "Epoch 102, Loss: 0.28632991867406027\n",
      "Epoch 103, Loss: 0.28619187142167773\n",
      "Epoch 104, Loss: 0.28727849009491147\n",
      "Epoch 105, Loss: 0.2857603202263514\n",
      "Epoch 106, Loss: 0.28652359777972813\n",
      "Epoch 107, Loss: 0.2860752629098438\n",
      "Epoch 108, Loss: 0.28569903751214343\n",
      "Epoch 109, Loss: 0.285998519772575\n",
      "Epoch 110, Loss: 0.2852724505606152\n",
      "Epoch 111, Loss: 0.28409518423534574\n",
      "Epoch 112, Loss: 0.283869929540725\n",
      "Epoch 113, Loss: 0.28403595887479327\n",
      "Epoch 114, Loss: 0.284034482439359\n",
      "Epoch 115, Loss: 0.28486343097119105\n",
      "Epoch 116, Loss: 0.28364019359861103\n",
      "Epoch 117, Loss: 0.28361996662049066\n",
      "Epoch 118, Loss: 0.2833527975990659\n",
      "Epoch 119, Loss: 0.2839489639373053\n",
      "Epoch 120, Loss: 0.2833901879049483\n",
      "Epoch 121, Loss: 0.2832855289039158\n",
      "Epoch 122, Loss: 0.2820339741877147\n",
      "Epoch 123, Loss: 0.28216039444719043\n",
      "Epoch 124, Loss: 0.28169877642676944\n",
      "Epoch 125, Loss: 0.2821371684471766\n",
      "Epoch 126, Loss: 0.2827711081504822\n",
      "Epoch 127, Loss: 0.2816668894461223\n",
      "Epoch 128, Loss: 0.28131321123668124\n",
      "Epoch 129, Loss: 0.28164251957620895\n",
      "Epoch 130, Loss: 0.2810535057669594\n",
      "Epoch 131, Loss: 0.2801205809059597\n",
      "Epoch 132, Loss: 0.282030398391542\n",
      "Epoch 133, Loss: 0.2808069906915937\n",
      "Epoch 134, Loss: 0.2803021400315421\n",
      "Epoch 135, Loss: 0.280352305713154\n",
      "Epoch 136, Loss: 0.28007559157553175\n",
      "Epoch 137, Loss: 0.2806955286150887\n",
      "Epoch 138, Loss: 0.27964547452472505\n",
      "Epoch 139, Loss: 0.2803433200291225\n",
      "Epoch 140, Loss: 0.27958888601689114\n",
      "Epoch 141, Loss: 0.2795946187348593\n",
      "Epoch 142, Loss: 0.2795379774911063\n",
      "Epoch 143, Loss: 0.27838925239585693\n",
      "Epoch 144, Loss: 0.2784395121960413\n",
      "Epoch 145, Loss: 0.27868944625059766\n",
      "Epoch 146, Loss: 0.27807570338249205\n",
      "Epoch 147, Loss: 0.2785794538543338\n",
      "Epoch 148, Loss: 0.2784701374031249\n",
      "Epoch 149, Loss: 0.2790858173654193\n",
      "Epoch 150, Loss: 0.277945896869614\n",
      "Epoch 151, Loss: 0.2787720288549151\n",
      "Epoch 152, Loss: 0.278341275368418\n",
      "Epoch 153, Loss: 0.2774408901021594\n",
      "Epoch 154, Loss: 0.276622551991826\n",
      "Epoch 155, Loss: 0.2778222648586546\n",
      "Epoch 156, Loss: 0.2775656036252067\n",
      "Epoch 157, Loss: 0.2765092446690514\n",
      "Epoch 158, Loss: 0.2763856549206234\n",
      "Epoch 159, Loss: 0.2764854508922214\n",
      "Epoch 160, Loss: 0.2759758811337607\n",
      "Epoch 161, Loss: 0.27586604796704794\n",
      "Epoch 162, Loss: 0.27698261632805776\n",
      "Epoch 163, Loss: 0.2769200295493716\n",
      "Epoch 164, Loss: 0.2772634430726369\n",
      "Epoch 165, Loss: 0.27475204805533093\n",
      "Epoch 166, Loss: 0.27528461825279965\n",
      "Epoch 167, Loss: 0.27515354681582677\n",
      "Epoch 168, Loss: 0.27635041889690215\n",
      "Epoch 169, Loss: 0.27526798906780425\n",
      "Epoch 170, Loss: 0.2758004060529527\n",
      "Epoch 171, Loss: 0.2752085602851141\n",
      "Epoch 172, Loss: 0.2758015810591834\n",
      "Epoch 173, Loss: 0.2747918688399451\n",
      "Epoch 174, Loss: 0.2750550224951335\n",
      "Epoch 175, Loss: 0.27486698176179614\n",
      "Epoch 176, Loss: 0.2745389702490398\n",
      "Epoch 177, Loss: 0.27529617704096293\n",
      "Epoch 178, Loss: 0.2745863354773749\n",
      "Epoch 179, Loss: 0.2743423854737055\n",
      "Epoch 180, Loss: 0.27452949645973385\n",
      "Epoch 181, Loss: 0.27477265346617924\n",
      "Epoch 182, Loss: 0.27373981850487844\n",
      "Epoch 183, Loss: 0.2741081813119707\n",
      "Epoch 184, Loss: 0.2735307468402953\n",
      "Epoch 185, Loss: 0.27543103047779627\n",
      "Epoch 186, Loss: 0.273540344891094\n",
      "Epoch 187, Loss: 0.27371396411032906\n",
      "Epoch 188, Loss: 0.27353291622229986\n",
      "Epoch 189, Loss: 0.2735316240787506\n",
      "Epoch 190, Loss: 0.2725898907865797\n",
      "Epoch 191, Loss: 0.2731036395969845\n",
      "Epoch 192, Loss: 0.27366897049404326\n",
      "Epoch 193, Loss: 0.2729322841053917\n",
      "Epoch 194, Loss: 0.27318592886130016\n",
      "Epoch 195, Loss: 0.27290514775684904\n",
      "Epoch 196, Loss: 0.27300502899147217\n",
      "Epoch 197, Loss: 0.27252081260794686\n",
      "Epoch 198, Loss: 0.27293535422711146\n",
      "Epoch 199, Loss: 0.2722139695712498\n",
      "Epoch 200, Loss: 0.27262256471883684\n",
      "Epoch 201, Loss: 0.270934389375505\n",
      "Epoch 202, Loss: 0.27096866619019283\n",
      "Epoch 203, Loss: 0.27203980766591573\n",
      "Epoch 204, Loss: 0.2712553010951905\n",
      "Epoch 205, Loss: 0.2708659086624781\n",
      "Epoch 206, Loss: 0.271344916281246\n",
      "Epoch 207, Loss: 0.27090452753362204\n",
      "Epoch 208, Loss: 0.2718336708205087\n",
      "Epoch 209, Loss: 0.2706905683733168\n",
      "Epoch 210, Loss: 0.27096426995027634\n",
      "Epoch 211, Loss: 0.27102660244419463\n",
      "Epoch 212, Loss: 0.27085559873353865\n",
      "Epoch 213, Loss: 0.2706363293102809\n",
      "Epoch 214, Loss: 0.27095182169051396\n",
      "Epoch 215, Loss: 0.27132885558264597\n",
      "Epoch 216, Loss: 0.2708142553624653\n",
      "Epoch 217, Loss: 0.270427042103949\n",
      "Epoch 218, Loss: 0.27079056197688695\n",
      "Epoch 219, Loss: 0.270809041261673\n",
      "Epoch 220, Loss: 0.26984410098620826\n",
      "Epoch 221, Loss: 0.2708766701675597\n",
      "Epoch 222, Loss: 0.2706111459221159\n",
      "Epoch 223, Loss: 0.2698683859053112\n",
      "Epoch 224, Loss: 0.2687737153825306\n",
      "Epoch 225, Loss: 0.2695598500967026\n",
      "Epoch 226, Loss: 0.26968816782746996\n",
      "Epoch 227, Loss: 0.26914798449902305\n",
      "Epoch 228, Loss: 0.2692251622960681\n",
      "Epoch 229, Loss: 0.2696051107134138\n",
      "Epoch 230, Loss: 0.26937293041320076\n",
      "Epoch 231, Loss: 0.269879931977817\n",
      "Epoch 232, Loss: 0.2700753368082501\n",
      "Epoch 233, Loss: 0.26859358421393803\n",
      "Epoch 234, Loss: 0.2699090259415763\n",
      "Epoch 235, Loss: 0.26979234706787836\n",
      "Epoch 236, Loss: 0.2696572917415982\n",
      "Epoch 237, Loss: 0.268935885713214\n",
      "Epoch 238, Loss: 0.26820087784812563\n",
      "Epoch 239, Loss: 0.26880736070019856\n",
      "Epoch 240, Loss: 0.26918869472685314\n",
      "Epoch 241, Loss: 0.26817450895195916\n",
      "Epoch 242, Loss: 0.2692569146837507\n",
      "Epoch 243, Loss: 0.267706892320088\n",
      "Epoch 244, Loss: 0.2688738457361857\n",
      "Epoch 245, Loss: 0.26900168333734786\n",
      "Epoch 246, Loss: 0.2677165485279901\n",
      "Epoch 247, Loss: 0.2668672885497411\n",
      "Epoch 248, Loss: 0.2676802257412956\n",
      "Epoch 249, Loss: 0.26679726504144213\n",
      "Epoch 250, Loss: 0.2675198292732239\n",
      "Epoch 251, Loss: 0.26705850958824157\n",
      "Epoch 252, Loss: 0.26757536394255504\n",
      "Epoch 253, Loss: 0.26620603530179887\n",
      "Epoch 254, Loss: 0.2674489211752301\n",
      "Epoch 255, Loss: 0.26742508201372056\n",
      "Epoch 256, Loss: 0.26723849830173313\n",
      "Epoch 257, Loss: 0.2674387582143148\n",
      "Epoch 258, Loss: 0.26709674860749927\n",
      "Epoch 259, Loss: 0.26736278698557897\n",
      "Epoch 260, Loss: 0.2674961521511986\n",
      "Epoch 261, Loss: 0.26610836040406\n",
      "Epoch 262, Loss: 0.2664303096419289\n",
      "Epoch 263, Loss: 0.267022274959655\n",
      "Epoch 264, Loss: 0.2668719177019028\n",
      "Epoch 265, Loss: 0.2668205634185246\n",
      "Epoch 266, Loss: 0.26644024763788493\n",
      "Epoch 267, Loss: 0.26732600578239984\n",
      "Epoch 268, Loss: 0.26542537166958763\n",
      "Epoch 269, Loss: 0.2668198569615682\n",
      "Epoch 270, Loss: 0.26714288311345236\n",
      "Epoch 271, Loss: 0.2657893745672135\n",
      "Epoch 272, Loss: 0.26551461126123155\n",
      "Epoch 273, Loss: 0.26663391346023196\n",
      "Epoch 274, Loss: 0.265780038805235\n",
      "Epoch 275, Loss: 0.26548359277702516\n",
      "Epoch 276, Loss: 0.2665121650695801\n",
      "Epoch 277, Loss: 0.26623632422515325\n",
      "Epoch 278, Loss: 0.26509849982602257\n",
      "Epoch 279, Loss: 0.26504083355267843\n",
      "Epoch 280, Loss: 0.2660513655344645\n",
      "Epoch 281, Loss: 0.2656710368962515\n",
      "Epoch 282, Loss: 0.264920131507374\n",
      "Epoch 283, Loss: 0.2659318023068564\n",
      "Epoch 284, Loss: 0.2647994920469466\n",
      "Epoch 285, Loss: 0.2643353088412966\n",
      "Epoch 286, Loss: 0.26515964743636905\n",
      "Epoch 287, Loss: 0.2647763595126924\n",
      "Epoch 288, Loss: 0.2645031236466907\n",
      "Epoch 289, Loss: 0.2648100919099081\n",
      "Epoch 290, Loss: 0.26518383923031036\n",
      "Epoch 291, Loss: 0.26507143630867913\n",
      "Epoch 292, Loss: 0.26587583893821354\n",
      "Epoch 293, Loss: 0.2648963987827301\n",
      "Epoch 294, Loss: 0.2643581539960135\n",
      "Epoch 295, Loss: 0.26477103582450323\n",
      "Epoch 296, Loss: 0.26387785534063973\n",
      "Epoch 297, Loss: 0.26410312402816044\n",
      "Epoch 298, Loss: 0.263938493955703\n",
      "Epoch 299, Loss: 0.26379064466272084\n",
      "Epoch 300, Loss: 0.2641050006945928\n",
      "Epoch 301, Loss: 0.2646136436575935\n",
      "Epoch 302, Loss: 0.26440379381179807\n",
      "Epoch 303, Loss: 0.26415414307798657\n",
      "Epoch 304, Loss: 0.26350277247883025\n",
      "Epoch 305, Loss: 0.2641103805530639\n",
      "Epoch 306, Loss: 0.26303855444703783\n",
      "Epoch 307, Loss: 0.2639634049790246\n",
      "Epoch 308, Loss: 0.2628619678531374\n",
      "Epoch 309, Loss: 0.26416834734735034\n",
      "Epoch 310, Loss: 0.2639703590813137\n",
      "Epoch 311, Loss: 0.26383932911214375\n",
      "Epoch 312, Loss: 0.26363196043741133\n",
      "Epoch 313, Loss: 0.2639938103868848\n",
      "Epoch 314, Loss: 0.26461420941920505\n",
      "Epoch 315, Loss: 0.26329755465189614\n",
      "Epoch 316, Loss: 0.2632578874202002\n",
      "Epoch 317, Loss: 0.2635280466363544\n",
      "Epoch 318, Loss: 0.2618186812173753\n",
      "Epoch 319, Loss: 0.2624348921151388\n",
      "Epoch 320, Loss: 0.26210115980534326\n",
      "Epoch 321, Loss: 0.26363828999655586\n",
      "Epoch 322, Loss: 0.2634639395702453\n",
      "Epoch 323, Loss: 0.2638301143759773\n",
      "Epoch 324, Loss: 0.26251585440976277\n",
      "Epoch 325, Loss: 0.2630545724857421\n",
      "Epoch 326, Loss: 0.26280324129831223\n",
      "Epoch 327, Loss: 0.2621694881007785\n",
      "Epoch 328, Loss: 0.2623462476900646\n",
      "Epoch 329, Loss: 0.2623894863753092\n",
      "Epoch 330, Loss: 0.26292844863164994\n",
      "Epoch 331, Loss: 0.26187997667562396\n",
      "Epoch 332, Loss: 0.2623533867938178\n",
      "Epoch 333, Loss: 0.2617511134488242\n",
      "Epoch 334, Loss: 0.26246681483018963\n",
      "Epoch 335, Loss: 0.2617741117023286\n",
      "Epoch 336, Loss: 0.2627028254100255\n",
      "Epoch 337, Loss: 0.2627872271764846\n",
      "Epoch 338, Loss: 0.2635287469625473\n",
      "Epoch 339, Loss: 0.26127796062401365\n",
      "Epoch 340, Loss: 0.2625973686717805\n",
      "Epoch 341, Loss: 0.26251568110216233\n",
      "Epoch 342, Loss: 0.26201180739062174\n",
      "Epoch 343, Loss: 0.2617274152664911\n",
      "Epoch 344, Loss: 0.2625652245112828\n",
      "Epoch 345, Loss: 0.26139353945141747\n",
      "Epoch 346, Loss: 0.26137678748085386\n",
      "Epoch 347, Loss: 0.2624215274197715\n",
      "Epoch 348, Loss: 0.2617092320181075\n",
      "Epoch 349, Loss: 0.2617876413038799\n",
      "Epoch 350, Loss: 0.26182147764024283\n",
      "Epoch 351, Loss: 0.2610913029455003\n",
      "Epoch 352, Loss: 0.26129547195775166\n",
      "Epoch 353, Loss: 0.2614027117547535\n",
      "Epoch 354, Loss: 0.2600086112817129\n",
      "Epoch 355, Loss: 0.26156433429036824\n",
      "Epoch 356, Loss: 0.2611035038176037\n",
      "Epoch 357, Loss: 0.2612163857335136\n",
      "Epoch 358, Loss: 0.26129451306093304\n",
      "Epoch 359, Loss: 0.26169242166337514\n",
      "Epoch 360, Loss: 0.2607161880958648\n",
      "Epoch 361, Loss: 0.2614144922721954\n",
      "Epoch 362, Loss: 0.26183340643133435\n",
      "Epoch 363, Loss: 0.26063016289756413\n",
      "Epoch 364, Loss: 0.2611971612771352\n",
      "Epoch 365, Loss: 0.2610218370528448\n",
      "Epoch 366, Loss: 0.26107137592065904\n",
      "Epoch 367, Loss: 0.25981561300300415\n",
      "Epoch 368, Loss: 0.2605651493583407\n",
      "Epoch 369, Loss: 0.26075993651435486\n",
      "Epoch 370, Loss: 0.2607185039917628\n",
      "Epoch 371, Loss: 0.2603148894934427\n",
      "Epoch 372, Loss: 0.26046643878732406\n",
      "Epoch 373, Loss: 0.26022983346666606\n",
      "Epoch 374, Loss: 0.26074290326663424\n",
      "Epoch 375, Loss: 0.2596788193782171\n",
      "Epoch 376, Loss: 0.26043594879763465\n",
      "Epoch 377, Loss: 0.2602555296250752\n",
      "Epoch 378, Loss: 0.26032257786818913\n",
      "Epoch 379, Loss: 0.25920976894242426\n",
      "Epoch 380, Loss: 0.2601573877107529\n",
      "Epoch 381, Loss: 0.2595759197927657\n",
      "Epoch 382, Loss: 0.26065658296857563\n",
      "Epoch 383, Loss: 0.2605471401271366\n",
      "Epoch 384, Loss: 0.25930048042819615\n",
      "Epoch 385, Loss: 0.25947877265158154\n",
      "Epoch 386, Loss: 0.25881268836203075\n",
      "Epoch 387, Loss: 0.25941275678929826\n",
      "Epoch 388, Loss: 0.2604047049511047\n",
      "Epoch 389, Loss: 0.2597295568102882\n",
      "Epoch 390, Loss: 0.2602632711614881\n",
      "Epoch 391, Loss: 0.2593446623711359\n",
      "Epoch 392, Loss: 0.2595517687286649\n",
      "Epoch 393, Loss: 0.26111849404516674\n",
      "Epoch 394, Loss: 0.25927788660639806\n",
      "Epoch 395, Loss: 0.2597064293282373\n",
      "Epoch 396, Loss: 0.2590370046524774\n",
      "Epoch 397, Loss: 0.2591664737746829\n",
      "Epoch 398, Loss: 0.259218742393312\n",
      "Epoch 399, Loss: 0.25986218770345054\n",
      "Epoch 400, Loss: 0.2588422013464428\n",
      "Epoch 401, Loss: 0.2587843581324532\n",
      "Epoch 402, Loss: 0.25881468772888183\n",
      "Epoch 403, Loss: 0.25796778684570676\n",
      "Epoch 404, Loss: 0.25959039500781467\n",
      "Epoch 405, Loss: 0.2589345065752665\n",
      "Epoch 406, Loss: 0.25949544855526513\n",
      "Epoch 407, Loss: 0.2585061237357912\n",
      "Epoch 408, Loss: 0.2581465616680327\n",
      "Epoch 409, Loss: 0.2589419142689024\n",
      "Epoch 410, Loss: 0.2581920683951605\n",
      "Epoch 411, Loss: 0.25915135956945873\n",
      "Epoch 412, Loss: 0.2597719402256466\n",
      "Epoch 413, Loss: 0.2574906799339113\n",
      "Epoch 414, Loss: 0.25764131642523264\n",
      "Epoch 415, Loss: 0.257954991374697\n",
      "Epoch 416, Loss: 0.2585793289684114\n",
      "Epoch 417, Loss: 0.25914177196366445\n",
      "Epoch 418, Loss: 0.2588477947598412\n",
      "Epoch 419, Loss: 0.25805744213717324\n",
      "Epoch 420, Loss: 0.25819793562094373\n",
      "Epoch 421, Loss: 0.2584961262203398\n",
      "Epoch 422, Loss: 0.25865743299325306\n",
      "Epoch 423, Loss: 0.2576429199037098\n",
      "Epoch 424, Loss: 0.25772643682502566\n",
      "Epoch 425, Loss: 0.25853047186420075\n",
      "Epoch 426, Loss: 0.25821931018715816\n",
      "Epoch 427, Loss: 0.2585974459704899\n",
      "Epoch 428, Loss: 0.25917464889231184\n",
      "Epoch 429, Loss: 0.25855409940083823\n",
      "Epoch 430, Loss: 0.2579998765956788\n",
      "Epoch 431, Loss: 0.258960655218079\n",
      "Epoch 432, Loss: 0.25786684572696683\n",
      "Epoch 433, Loss: 0.25664034763971966\n",
      "Epoch 434, Loss: 0.25777639298211963\n",
      "Epoch 435, Loss: 0.2577196299462091\n",
      "Epoch 436, Loss: 0.257277757695743\n",
      "Epoch 437, Loss: 0.25713834166526794\n",
      "Epoch 438, Loss: 0.25657403727372485\n",
      "Epoch 439, Loss: 0.25672616606666926\n",
      "Epoch 440, Loss: 0.2567309805608931\n",
      "Epoch 441, Loss: 0.2580689334301721\n",
      "Epoch 442, Loss: 0.2572649026768548\n",
      "Epoch 443, Loss: 0.25660896630514235\n",
      "Epoch 444, Loss: 0.2558615211645762\n",
      "Epoch 445, Loss: 0.2576216846704483\n",
      "Epoch 446, Loss: 0.2572943942319779\n",
      "Epoch 447, Loss: 0.257801920459384\n",
      "Epoch 448, Loss: 0.25730837841828663\n",
      "Epoch 449, Loss: 0.25754095017910006\n",
      "Epoch 450, Loss: 0.25685316718759993\n",
      "Epoch 451, Loss: 0.25675495973655155\n",
      "Epoch 452, Loss: 0.2564920689094634\n",
      "Epoch 453, Loss: 0.2568063039439065\n",
      "Epoch 454, Loss: 0.25733544863405683\n",
      "Epoch 455, Loss: 0.2577547166461036\n",
      "Epoch 456, Loss: 0.256679729336784\n",
      "Epoch 457, Loss: 0.2559518636408306\n",
      "Epoch 458, Loss: 0.2554546813170115\n",
      "Epoch 459, Loss: 0.25762057977063313\n",
      "Epoch 460, Loss: 0.25677758696533387\n",
      "Epoch 461, Loss: 0.25637963862646196\n",
      "Epoch 462, Loss: 0.2562273850043615\n",
      "Epoch 463, Loss: 0.2565680513495491\n",
      "Epoch 464, Loss: 0.2564789075227011\n",
      "Epoch 465, Loss: 0.2571905824116298\n",
      "Epoch 466, Loss: 0.25668491741021476\n",
      "Epoch 467, Loss: 0.2565317448547908\n",
      "Epoch 468, Loss: 0.2557874119849432\n",
      "Epoch 469, Loss: 0.2557172534011659\n",
      "Epoch 470, Loss: 0.25590239243847984\n",
      "Epoch 471, Loss: 0.25733151867276144\n",
      "Epoch 472, Loss: 0.2562267451626914\n",
      "Epoch 473, Loss: 0.25474715388956526\n",
      "Epoch 474, Loss: 0.2565514805203392\n",
      "Epoch 475, Loss: 0.25585883674167453\n",
      "Epoch 476, Loss: 0.256188702753612\n",
      "Epoch 477, Loss: 0.25604720342726933\n",
      "Epoch 478, Loss: 0.2563276843797593\n",
      "Epoch 479, Loss: 0.25502680511701675\n",
      "Epoch 480, Loss: 0.2551206483443578\n",
      "Epoch 481, Loss: 0.25587325729074933\n",
      "Epoch 482, Loss: 0.25570074163732076\n",
      "Epoch 483, Loss: 0.25546424130598705\n",
      "Epoch 484, Loss: 0.25608899652957917\n",
      "Epoch 485, Loss: 0.2558515585036505\n",
      "Epoch 486, Loss: 0.2557534815016247\n",
      "Epoch 487, Loss: 0.25565944572289784\n",
      "Epoch 488, Loss: 0.2560259792634419\n",
      "Epoch 489, Loss: 0.2555382772286733\n",
      "Epoch 490, Loss: 0.2541094845249539\n",
      "Epoch 491, Loss: 0.2551589682840166\n",
      "Epoch 492, Loss: 0.25572142030511585\n",
      "Epoch 493, Loss: 0.25540008647101264\n",
      "Epoch 494, Loss: 0.25457313103335244\n",
      "Epoch 495, Loss: 0.25459831217924755\n",
      "Epoch 496, Loss: 0.25475237565381187\n",
      "Epoch 497, Loss: 0.2557145918834777\n",
      "Epoch 498, Loss: 0.2539676667395092\n",
      "Epoch 499, Loss: 0.25463122821989514\n",
      "Epoch 500, Loss: 0.2550313810223625\n",
      "Epoch 501, Loss: 0.25555730728876025\n",
      "Epoch 502, Loss: 0.2546230920723506\n",
      "Epoch 503, Loss: 0.25466168375242326\n",
      "Epoch 504, Loss: 0.255261045495669\n",
      "Epoch 505, Loss: 0.25494796349888754\n",
      "Epoch 506, Loss: 0.25519822063900177\n",
      "Epoch 507, Loss: 0.25524075729506357\n",
      "Epoch 508, Loss: 0.25404743705477034\n",
      "Epoch 509, Loss: 0.2552468154543922\n",
      "Epoch 510, Loss: 0.2553797358842123\n",
      "Epoch 511, Loss: 0.2551652377560025\n",
      "Epoch 512, Loss: 0.2554622498864219\n",
      "Epoch 513, Loss: 0.25443537564504715\n",
      "Epoch 514, Loss: 0.2551152770576023\n",
      "Epoch 515, Loss: 0.2537191075654257\n",
      "Epoch 516, Loss: 0.2542095367965244\n",
      "Epoch 517, Loss: 0.25576879938443503\n",
      "Epoch 518, Loss: 0.25467804508549824\n",
      "Epoch 519, Loss: 0.25418329028856185\n",
      "Epoch 520, Loss: 0.25463008815333954\n",
      "Epoch 521, Loss: 0.25339665415741147\n",
      "Epoch 522, Loss: 0.2540530062005633\n",
      "Epoch 523, Loss: 0.2544202916111265\n",
      "Epoch 524, Loss: 0.25377904928865885\n",
      "Epoch 525, Loss: 0.2548736159290586\n",
      "Epoch 526, Loss: 0.2539634584529059\n",
      "Epoch 527, Loss: 0.25421724313781374\n",
      "Epoch 528, Loss: 0.25460734026772636\n",
      "Epoch 529, Loss: 0.2544249253613608\n",
      "Epoch 530, Loss: 0.2545184533368974\n",
      "Epoch 531, Loss: 0.25449854399476735\n",
      "Epoch 532, Loss: 0.25437092051619575\n",
      "Epoch 533, Loss: 0.25457763754186175\n",
      "Epoch 534, Loss: 0.25449435384500596\n",
      "Epoch 535, Loss: 0.2538814920470828\n",
      "Epoch 536, Loss: 0.25430829448359354\n",
      "Epoch 537, Loss: 0.2536492562577838\n",
      "Epoch 538, Loss: 0.25463230706396556\n",
      "Epoch 539, Loss: 0.2531781095550174\n",
      "Epoch 540, Loss: 0.25452461986314684\n",
      "Epoch 541, Loss: 0.25361249787466866\n",
      "Epoch 542, Loss: 0.2534997828517641\n",
      "Epoch 543, Loss: 0.254148422564779\n",
      "Epoch 544, Loss: 0.253882035783359\n",
      "Epoch 545, Loss: 0.2536236527704057\n",
      "Epoch 546, Loss: 0.25444945477304004\n",
      "Epoch 547, Loss: 0.2541163603748594\n",
      "Epoch 548, Loss: 0.2538316739740826\n",
      "Epoch 549, Loss: 0.2537354342994236\n",
      "Epoch 550, Loss: 0.2525590779667809\n",
      "Epoch 551, Loss: 0.2543122722705205\n",
      "Epoch 552, Loss: 0.2527170188370205\n",
      "Epoch 553, Loss: 0.2542537317957197\n",
      "Epoch 554, Loss: 0.2534244224854878\n",
      "Epoch 555, Loss: 0.2534655828986849\n",
      "Epoch 556, Loss: 0.2534028887181055\n",
      "Epoch 557, Loss: 0.25288032662300836\n",
      "Epoch 558, Loss: 0.25302752633889514\n",
      "Epoch 559, Loss: 0.25395185958771477\n",
      "Epoch 560, Loss: 0.2524985895270393\n",
      "Epoch 561, Loss: 0.2546716990073522\n",
      "Epoch 562, Loss: 0.2535778283789044\n",
      "Epoch 563, Loss: 0.2535865484532856\n",
      "Epoch 564, Loss: 0.25373173759097145\n",
      "Epoch 565, Loss: 0.25268838354519435\n",
      "Epoch 566, Loss: 0.25262325065476554\n",
      "Epoch 567, Loss: 0.2541034793569928\n",
      "Epoch 568, Loss: 0.2530048494395756\n",
      "Epoch 569, Loss: 0.2535421415170034\n",
      "Epoch 570, Loss: 0.2529633285601934\n",
      "Epoch 571, Loss: 0.25299183045114787\n",
      "Epoch 572, Loss: 0.2525983734074093\n",
      "Epoch 573, Loss: 0.2528634767589115\n",
      "Epoch 574, Loss: 0.25352263175305867\n",
      "Epoch 575, Loss: 0.25237444301446277\n",
      "Epoch 576, Loss: 0.2528078226816087\n",
      "Epoch 577, Loss: 0.2524599263781593\n",
      "Epoch 578, Loss: 0.2518087725979941\n",
      "Epoch 579, Loss: 0.25295002071630385\n",
      "Epoch 580, Loss: 0.25283387984548295\n",
      "Epoch 581, Loss: 0.2519606347878774\n",
      "Epoch 582, Loss: 0.2529979491233826\n",
      "Epoch 583, Loss: 0.2528302528744652\n",
      "Epoch 584, Loss: 0.25270393655413675\n",
      "Epoch 585, Loss: 0.2526667326688766\n",
      "Epoch 586, Loss: 0.2530347723336447\n",
      "Epoch 587, Loss: 0.25284096970444636\n",
      "Epoch 588, Loss: 0.2519504183246976\n",
      "Epoch 589, Loss: 0.25126385586602346\n",
      "Epoch 590, Loss: 0.25125192409469965\n",
      "Epoch 591, Loss: 0.2529966049251102\n",
      "Epoch 592, Loss: 0.25209174354871117\n",
      "Epoch 593, Loss: 0.2513511057694753\n",
      "Epoch 594, Loss: 0.25292213093666804\n",
      "Epoch 595, Loss: 0.25207277036848524\n",
      "Epoch 596, Loss: 0.25201965360414413\n",
      "Epoch 597, Loss: 0.25306535419963655\n",
      "Epoch 598, Loss: 0.2533662980794907\n",
      "Epoch 599, Loss: 0.25203743548620317\n",
      "Epoch 600, Loss: 0.25207822493144444\n",
      "Epoch 601, Loss: 0.2520515131382715\n",
      "Epoch 602, Loss: 0.25170430532523563\n",
      "Epoch 603, Loss: 0.25092100864364986\n",
      "Epoch 604, Loss: 0.25198127800510045\n",
      "Epoch 605, Loss: 0.25203214523338135\n",
      "Epoch 606, Loss: 0.2522759414570672\n",
      "Epoch 607, Loss: 0.2520328542448225\n",
      "Epoch 608, Loss: 0.2508730639730181\n",
      "Epoch 609, Loss: 0.2536495786621457\n",
      "Epoch 610, Loss: 0.2515140483209065\n",
      "Epoch 611, Loss: 0.2518275441726049\n",
      "Epoch 612, Loss: 0.251546315181823\n",
      "Epoch 613, Loss: 0.2514437026920773\n",
      "Epoch 614, Loss: 0.253196454956418\n",
      "Epoch 615, Loss: 0.251229114418938\n",
      "Epoch 616, Loss: 0.2499258414620445\n",
      "Epoch 617, Loss: 0.25130206176212855\n",
      "Epoch 618, Loss: 0.25182549215498423\n",
      "Epoch 619, Loss: 0.25100055260317666\n",
      "Epoch 620, Loss: 0.25171074975104557\n",
      "Epoch 621, Loss: 0.25072550362064727\n",
      "Epoch 622, Loss: 0.25147465370950245\n",
      "Epoch 623, Loss: 0.25006485618296126\n",
      "Epoch 624, Loss: 0.25118928324608575\n",
      "Epoch 625, Loss: 0.2509904187633878\n",
      "Epoch 626, Loss: 0.2506908705688658\n",
      "Epoch 627, Loss: 0.2513684057621729\n",
      "Epoch 628, Loss: 0.2510115427062625\n",
      "Epoch 629, Loss: 0.2508679772842498\n",
      "Epoch 630, Loss: 0.25009802758693694\n",
      "Epoch 631, Loss: 0.250946774823325\n",
      "Epoch 632, Loss: 0.2509513269719623\n",
      "Epoch 633, Loss: 0.25183140470868065\n",
      "Epoch 634, Loss: 0.24941958654494512\n",
      "Epoch 635, Loss: 0.2505238520815259\n",
      "Epoch 636, Loss: 0.251362225157874\n",
      "Epoch 637, Loss: 0.25111316575890497\n",
      "Epoch 638, Loss: 0.2513965669416246\n",
      "Epoch 639, Loss: 0.25089832515943616\n",
      "Epoch 640, Loss: 0.250949834443274\n",
      "Epoch 641, Loss: 0.2504726691189266\n",
      "Epoch 642, Loss: 0.2509532266571408\n",
      "Epoch 643, Loss: 0.2494606176728294\n",
      "Epoch 644, Loss: 0.2513701848756699\n",
      "Epoch 645, Loss: 0.24995872616767884\n",
      "Epoch 646, Loss: 0.250544910743123\n",
      "Epoch 647, Loss: 0.2511978143453598\n",
      "Epoch 648, Loss: 0.25009990473588306\n",
      "Epoch 649, Loss: 0.25080508036272864\n",
      "Epoch 650, Loss: 0.2503338090294883\n",
      "Epoch 651, Loss: 0.2508086950438363\n",
      "Epoch 652, Loss: 0.2507198110648564\n",
      "Epoch 653, Loss: 0.25148161198411667\n",
      "Epoch 654, Loss: 0.2501040397087733\n",
      "Epoch 655, Loss: 0.251759162005924\n",
      "Epoch 656, Loss: 0.2501938432455063\n",
      "Epoch 657, Loss: 0.2510301431587764\n",
      "Epoch 658, Loss: 0.24993755794706798\n",
      "Epoch 659, Loss: 0.24952056067330497\n",
      "Epoch 660, Loss: 0.25063031176726025\n",
      "Epoch 661, Loss: 0.2509884523493903\n",
      "Epoch 662, Loss: 0.25155240799699513\n",
      "Epoch 663, Loss: 0.2509293389888037\n",
      "Epoch 664, Loss: 0.24969815435863676\n",
      "Epoch 665, Loss: 0.25029710647605713\n",
      "Epoch 666, Loss: 0.25016903056984857\n",
      "Epoch 667, Loss: 0.24966307773476556\n",
      "Epoch 668, Loss: 0.24932629607972645\n",
      "Epoch 669, Loss: 0.2490710294530505\n",
      "Epoch 670, Loss: 0.25005604306856793\n",
      "Epoch 671, Loss: 0.2497537606670743\n",
      "Epoch 672, Loss: 0.24898460444949921\n",
      "Epoch 673, Loss: 0.2497770725545429\n",
      "Epoch 674, Loss: 0.25040488529772986\n",
      "Epoch 675, Loss: 0.24990873427618118\n",
      "Epoch 676, Loss: 0.24976283663795107\n",
      "Epoch 677, Loss: 0.2500994749580111\n",
      "Epoch 678, Loss: 0.24983964556739444\n",
      "Epoch 679, Loss: 0.2504485970167887\n",
      "Epoch 680, Loss: 0.2503831235567729\n",
      "Epoch 681, Loss: 0.2494943422930581\n",
      "Epoch 682, Loss: 0.24902019625618343\n",
      "Epoch 683, Loss: 0.24950763983385904\n",
      "Epoch 684, Loss: 0.24959303767908186\n",
      "Epoch 685, Loss: 0.24991046073890869\n",
      "Epoch 686, Loss: 0.24906266882306052\n",
      "Epoch 687, Loss: 0.24965400911512828\n",
      "Epoch 688, Loss: 0.24940070376509713\n",
      "Epoch 689, Loss: 0.24929351945718128\n",
      "Epoch 690, Loss: 0.24976289439769017\n",
      "Epoch 691, Loss: 0.24899845327649797\n",
      "Epoch 692, Loss: 0.2501759871698561\n",
      "Epoch 693, Loss: 0.2493037543126515\n",
      "Epoch 694, Loss: 0.2492085593654996\n",
      "Epoch 695, Loss: 0.24919965218930018\n",
      "Epoch 696, Loss: 0.24958925809179033\n",
      "Epoch 697, Loss: 0.24956742093676612\n",
      "Epoch 698, Loss: 0.2488631169285093\n",
      "Epoch 699, Loss: 0.24925077659743172\n",
      "Epoch 700, Loss: 0.24937366758074078\n",
      "Epoch 701, Loss: 0.24924751698970796\n",
      "Epoch 702, Loss: 0.24934589746452512\n",
      "Epoch 703, Loss: 0.2488314715169725\n",
      "Epoch 704, Loss: 0.24903275404657638\n",
      "Epoch 705, Loss: 0.2496911344641731\n",
      "Epoch 706, Loss: 0.2497399268547694\n",
      "Epoch 707, Loss: 0.2498132359130042\n",
      "Epoch 708, Loss: 0.24956912560122355\n",
      "Epoch 709, Loss: 0.24843264701820555\n",
      "Epoch 710, Loss: 0.24904150284471965\n",
      "Epoch 711, Loss: 0.24864800793784006\n",
      "Epoch 712, Loss: 0.24960119962692262\n",
      "Epoch 713, Loss: 0.24926416371549878\n",
      "Epoch 714, Loss: 0.2481959730386734\n",
      "Epoch 715, Loss: 0.24935851976985024\n",
      "Epoch 716, Loss: 0.2495302054427919\n",
      "Epoch 717, Loss: 0.24898247707457768\n",
      "Epoch 718, Loss: 0.2484024596498126\n",
      "Epoch 719, Loss: 0.24929389601662044\n",
      "Epoch 720, Loss: 0.2478380372126897\n",
      "Epoch 721, Loss: 0.24798562387625375\n",
      "Epoch 722, Loss: 0.24882716789132073\n",
      "Epoch 723, Loss: 0.24823772964023408\n",
      "Epoch 724, Loss: 0.2487631186417171\n",
      "Epoch 725, Loss: 0.2487671290692829\n",
      "Epoch 726, Loss: 0.24890254091648828\n",
      "Epoch 727, Loss: 0.2486712041922978\n",
      "Epoch 728, Loss: 0.24761171829132805\n",
      "Epoch 729, Loss: 0.24795731516111466\n",
      "Epoch 730, Loss: 0.24869147306396847\n",
      "Epoch 731, Loss: 0.24749802390734355\n",
      "Epoch 732, Loss: 0.2496527040856225\n",
      "Epoch 733, Loss: 0.2487545916296187\n",
      "Epoch 734, Loss: 0.2485902596087683\n",
      "Epoch 735, Loss: 0.24804037048703148\n",
      "Epoch 736, Loss: 0.24849472275802068\n",
      "Epoch 737, Loss: 0.24749189058939616\n",
      "Epoch 738, Loss: 0.2490023621207192\n",
      "Epoch 739, Loss: 0.24909201454548607\n",
      "Epoch 740, Loss: 0.24848691815421695\n",
      "Epoch 741, Loss: 0.24812469280901409\n",
      "Epoch 742, Loss: 0.24685326911154248\n",
      "Epoch 743, Loss: 0.2485495711792083\n",
      "Epoch 744, Loss: 0.24791138382185074\n",
      "Epoch 745, Loss: 0.24853479987099056\n",
      "Epoch 746, Loss: 0.248330661938304\n",
      "Epoch 747, Loss: 0.24808662919771104\n",
      "Epoch 748, Loss: 0.2482584530682791\n",
      "Epoch 749, Loss: 0.24859344550541468\n",
      "Epoch 750, Loss: 0.2485198620387486\n",
      "Epoch 751, Loss: 0.2476886537813005\n",
      "Epoch 752, Loss: 0.24834976400647846\n",
      "Epoch 753, Loss: 0.24797461898553938\n",
      "Epoch 754, Loss: 0.24862158622060504\n",
      "Epoch 755, Loss: 0.2484153455779666\n",
      "Epoch 756, Loss: 0.24844606686206092\n",
      "Epoch 757, Loss: 0.2482790462176005\n",
      "Epoch 758, Loss: 0.24913135233379546\n",
      "Epoch 759, Loss: 0.24845393200715382\n",
      "Epoch 760, Loss: 0.24834744419370378\n",
      "Epoch 761, Loss: 0.24762201800232841\n",
      "Epoch 762, Loss: 0.24770898532299768\n",
      "Epoch 763, Loss: 0.24842639948640552\n",
      "Epoch 764, Loss: 0.24757447787693568\n",
      "Epoch 765, Loss: 0.2486470403557732\n",
      "Epoch 766, Loss: 0.24741809331235431\n",
      "Epoch 767, Loss: 0.24668674772693996\n",
      "Epoch 768, Loss: 0.24856954114777702\n",
      "Epoch 769, Loss: 0.24849175827843803\n",
      "Epoch 770, Loss: 0.24766205481120518\n",
      "Epoch 771, Loss: 0.24691228894960313\n",
      "Epoch 772, Loss: 0.24722928228832428\n",
      "Epoch 773, Loss: 0.24688280383745828\n",
      "Epoch 774, Loss: 0.247568747145789\n",
      "Epoch 775, Loss: 0.24746189089048476\n",
      "Epoch 776, Loss: 0.24662012171177636\n",
      "Epoch 777, Loss: 0.24760223365965345\n",
      "Epoch 778, Loss: 0.2477840922276179\n",
      "Epoch 779, Loss: 0.24813490685962494\n",
      "Epoch 780, Loss: 0.24732356272992634\n",
      "Epoch 781, Loss: 0.2479859975973765\n",
      "Epoch 782, Loss: 0.24758960573446184\n",
      "Epoch 783, Loss: 0.2462395076240812\n",
      "Epoch 784, Loss: 0.2476371423403422\n",
      "Epoch 785, Loss: 0.24790242379619962\n",
      "Epoch 786, Loss: 0.2486172777414322\n",
      "Epoch 787, Loss: 0.24717203344617572\n",
      "Epoch 788, Loss: 0.24778216520945232\n",
      "Epoch 789, Loss: 0.24705250901835304\n",
      "Epoch 790, Loss: 0.24831199089686076\n",
      "Epoch 791, Loss: 0.24701408567882718\n",
      "Epoch 792, Loss: 0.2471318519115448\n",
      "Epoch 793, Loss: 0.24613031472478594\n",
      "Epoch 794, Loss: 0.2472548493601027\n",
      "Epoch 795, Loss: 0.24647953013579052\n",
      "Epoch 796, Loss: 0.24714726272083465\n",
      "Epoch 797, Loss: 0.24614557859443484\n",
      "Epoch 798, Loss: 0.2472086728470666\n",
      "Epoch 799, Loss: 0.2480433066402163\n",
      "Epoch 800, Loss: 0.24763362606366476\n",
      "Epoch 801, Loss: 0.24775954238006045\n",
      "Epoch 802, Loss: 0.24653213563419524\n",
      "Epoch 803, Loss: 0.24642028442450933\n",
      "Epoch 804, Loss: 0.24717708976495834\n",
      "Epoch 805, Loss: 0.2471236100650969\n",
      "Epoch 806, Loss: 0.24682835099242983\n",
      "Epoch 807, Loss: 0.24786797046661377\n",
      "Epoch 808, Loss: 0.24768391370773316\n",
      "Epoch 809, Loss: 0.24614817511467707\n",
      "Epoch 810, Loss: 0.24681114596979958\n",
      "Epoch 811, Loss: 0.24762279831227801\n",
      "Epoch 812, Loss: 0.24617418206873395\n",
      "Epoch 813, Loss: 0.24772556881109872\n",
      "Epoch 814, Loss: 0.24623777823788778\n",
      "Epoch 815, Loss: 0.24570761904830024\n",
      "Epoch 816, Loss: 0.2469183240334193\n",
      "Epoch 817, Loss: 0.24739837470508758\n",
      "Epoch 818, Loss: 0.2466410345690591\n",
      "Epoch 819, Loss: 0.246751587277367\n",
      "Epoch 820, Loss: 0.24746055781841278\n",
      "Epoch 821, Loss: 0.24657214877151307\n",
      "Epoch 822, Loss: 0.24757382767541067\n",
      "Epoch 823, Loss: 0.24663434965269906\n",
      "Epoch 824, Loss: 0.24801862549214135\n",
      "Epoch 825, Loss: 0.24772720518566313\n",
      "Epoch 826, Loss: 0.2460559873637699\n",
      "Epoch 827, Loss: 0.24638198361510322\n",
      "Epoch 828, Loss: 0.2469197173061825\n",
      "Epoch 829, Loss: 0.24625387427352724\n",
      "Epoch 830, Loss: 0.24638211826483408\n",
      "Epoch 831, Loss: 0.24697293386572883\n",
      "Epoch 832, Loss: 0.2474907122339521\n",
      "Epoch 833, Loss: 0.24671050852253323\n",
      "Epoch 834, Loss: 0.24701865993794941\n",
      "Epoch 835, Loss: 0.24615874809878213\n",
      "Epoch 836, Loss: 0.246326636331422\n",
      "Epoch 837, Loss: 0.24669326983747028\n",
      "Epoch 838, Loss: 0.24709151148796082\n",
      "Epoch 839, Loss: 0.24615467105593\n",
      "Epoch 840, Loss: 0.2461104167926879\n",
      "Epoch 841, Loss: 0.24629146008264452\n",
      "Epoch 842, Loss: 0.24596637149651845\n",
      "Epoch 843, Loss: 0.24565962924843743\n",
      "Epoch 844, Loss: 0.245970228882063\n",
      "Epoch 845, Loss: 0.24674368469488053\n",
      "Epoch 846, Loss: 0.24607505137012117\n",
      "Epoch 847, Loss: 0.246646154210681\n",
      "Epoch 848, Loss: 0.24575327623458135\n",
      "Epoch 849, Loss: 0.24507789152009146\n",
      "Epoch 850, Loss: 0.2462411963088172\n",
      "Epoch 851, Loss: 0.2440327003740129\n",
      "Epoch 852, Loss: 0.24684692839781444\n",
      "Epoch 853, Loss: 0.24492252412296478\n",
      "Epoch 854, Loss: 0.2468070377622332\n",
      "Epoch 855, Loss: 0.2461690451701482\n",
      "Epoch 856, Loss: 0.2457278464805512\n",
      "Epoch 857, Loss: 0.2474782499812898\n",
      "Epoch 858, Loss: 0.24735971317404792\n",
      "Epoch 859, Loss: 0.24567305266857148\n",
      "Epoch 860, Loss: 0.24558837234973907\n",
      "Epoch 861, Loss: 0.2467865055799484\n",
      "Epoch 862, Loss: 0.2449753041778292\n",
      "Epoch 863, Loss: 0.2452873065641948\n",
      "Epoch 864, Loss: 0.24623838560921804\n",
      "Epoch 865, Loss: 0.24512687756901697\n",
      "Epoch 866, Loss: 0.2459632826986767\n",
      "Epoch 867, Loss: 0.24637365860598429\n",
      "Epoch 868, Loss: 0.24627866517929803\n",
      "Epoch 869, Loss: 0.2468844629469372\n",
      "Epoch 870, Loss: 0.24543792352789925\n",
      "Epoch 871, Loss: 0.24587052336760928\n",
      "Epoch 872, Loss: 0.2456735237155642\n",
      "Epoch 873, Loss: 0.24662586717378526\n",
      "Epoch 874, Loss: 0.24558014074961346\n",
      "Epoch 875, Loss: 0.24575408257189252\n",
      "Epoch 876, Loss: 0.24657659414268676\n",
      "Epoch 877, Loss: 0.24507916663374218\n",
      "Epoch 878, Loss: 0.24626214620612916\n",
      "Epoch 879, Loss: 0.24503675142923992\n",
      "Epoch 880, Loss: 0.24548031000863937\n",
      "Epoch 881, Loss: 0.24551845783279055\n",
      "Epoch 882, Loss: 0.24694496344952357\n",
      "Epoch 883, Loss: 0.24609423276923953\n",
      "Epoch 884, Loss: 0.24584342720962707\n",
      "Epoch 885, Loss: 0.24461148117269788\n",
      "Epoch 886, Loss: 0.24601896433603196\n",
      "Epoch 887, Loss: 0.24631813103244418\n",
      "Epoch 888, Loss: 0.24547090121677945\n",
      "Epoch 889, Loss: 0.2455067512251082\n",
      "Epoch 890, Loss: 0.2448775889759972\n",
      "Epoch 891, Loss: 0.24523592906338829\n",
      "Epoch 892, Loss: 0.24520795226097106\n",
      "Epoch 893, Loss: 0.24463353511833008\n",
      "Epoch 894, Loss: 0.24535350921608154\n",
      "Epoch 895, Loss: 0.24666338435241153\n",
      "Epoch 896, Loss: 0.24490249696232025\n",
      "Epoch 897, Loss: 0.24544148280507042\n",
      "Epoch 898, Loss: 0.24562694980984642\n",
      "Epoch 899, Loss: 0.2454772382690793\n",
      "Epoch 900, Loss: 0.24482680011363256\n",
      "Epoch 901, Loss: 0.2461394284452711\n",
      "Epoch 902, Loss: 0.24399099412418548\n",
      "Epoch 903, Loss: 0.24550876648653122\n",
      "Epoch 904, Loss: 0.24570451807408106\n",
      "Epoch 905, Loss: 0.24570710202058157\n",
      "Epoch 906, Loss: 0.24456171617621467\n",
      "Epoch 907, Loss: 0.24552493725504193\n",
      "Epoch 908, Loss: 0.24612901960100447\n",
      "Epoch 909, Loss: 0.2461785628114428\n",
      "Epoch 910, Loss: 0.24429092850003925\n",
      "Epoch 911, Loss: 0.2456289291949499\n",
      "Epoch 912, Loss: 0.24618151792458126\n",
      "Epoch 913, Loss: 0.24518568677561622\n",
      "Epoch 914, Loss: 0.24540815123489926\n",
      "Epoch 915, Loss: 0.24446969906489055\n",
      "Epoch 916, Loss: 0.24524456302324932\n",
      "Epoch 917, Loss: 0.24520919104417166\n",
      "Epoch 918, Loss: 0.24508626182874044\n",
      "Epoch 919, Loss: 0.24502160662696476\n",
      "Epoch 920, Loss: 0.2445192340725944\n",
      "Epoch 921, Loss: 0.2441027154525121\n",
      "Epoch 922, Loss: 0.2453611222051439\n",
      "Epoch 923, Loss: 0.24511331552550905\n",
      "Epoch 924, Loss: 0.244919036144302\n",
      "Epoch 925, Loss: 0.24541180836302892\n",
      "Epoch 926, Loss: 0.24500159919261932\n",
      "Epoch 927, Loss: 0.245856264375505\n",
      "Epoch 928, Loss: 0.24481346655459632\n",
      "Epoch 929, Loss: 0.24472293694814046\n",
      "Epoch 930, Loss: 0.24556440251214165\n",
      "Epoch 931, Loss: 0.2465528684570676\n",
      "Epoch 932, Loss: 0.24407214774971916\n",
      "Epoch 933, Loss: 0.24614346995240166\n",
      "Epoch 934, Loss: 0.24567857166131338\n",
      "Epoch 935, Loss: 0.24567703386147818\n",
      "Epoch 936, Loss: 0.2445509562605903\n",
      "Epoch 937, Loss: 0.24481855193773905\n",
      "Epoch 938, Loss: 0.24475533352011725\n",
      "Epoch 939, Loss: 0.24429916052591233\n",
      "Epoch 940, Loss: 0.24502985894680024\n",
      "Epoch 941, Loss: 0.2447065663621539\n",
      "Epoch 942, Loss: 0.2446848601102829\n",
      "Epoch 943, Loss: 0.2435959432522456\n",
      "Epoch 944, Loss: 0.24521645375660486\n",
      "Epoch 945, Loss: 0.2451915897641863\n",
      "Epoch 946, Loss: 0.24532548089822134\n",
      "Epoch 947, Loss: 0.2447249038730349\n",
      "Epoch 948, Loss: 0.24401322540782747\n",
      "Epoch 949, Loss: 0.24505626292455765\n",
      "Epoch 950, Loss: 0.24447929842131477\n",
      "Epoch 951, Loss: 0.24526841844831193\n",
      "Epoch 952, Loss: 0.2442990054119201\n",
      "Epoch 953, Loss: 0.24442267307213375\n",
      "Epoch 954, Loss: 0.24572657976831708\n",
      "Epoch 955, Loss: 0.2454560763495309\n",
      "Epoch 956, Loss: 0.24426965276400248\n",
      "Epoch 957, Loss: 0.24642136871814727\n",
      "Epoch 958, Loss: 0.24432506572632562\n",
      "Epoch 959, Loss: 0.24425203933602288\n",
      "Epoch 960, Loss: 0.24396508631252106\n",
      "Epoch 961, Loss: 0.24365343232949574\n",
      "Epoch 962, Loss: 0.2441488649447759\n",
      "Epoch 963, Loss: 0.24476675706250328\n",
      "Epoch 964, Loss: 0.24465869560128167\n",
      "Epoch 965, Loss: 0.24541566774958656\n",
      "Epoch 966, Loss: 0.2448631564492271\n",
      "Epoch 967, Loss: 0.2438231161094847\n",
      "Epoch 968, Loss: 0.24402382873353504\n",
      "Epoch 969, Loss: 0.24314953131335124\n",
      "Epoch 970, Loss: 0.24405189207621983\n",
      "Epoch 971, Loss: 0.24455655960809616\n",
      "Epoch 972, Loss: 0.24342131807690576\n",
      "Epoch 973, Loss: 0.24488432872863042\n",
      "Epoch 974, Loss: 0.24410442573683602\n",
      "Epoch 975, Loss: 0.24379868640786126\n",
      "Epoch 976, Loss: 0.24390090990634192\n",
      "Epoch 977, Loss: 0.24496416529019674\n",
      "Epoch 978, Loss: 0.24270859014420282\n",
      "Epoch 979, Loss: 0.24333953411806197\n",
      "Epoch 980, Loss: 0.2436647090173903\n",
      "Epoch 981, Loss: 0.2442534970953351\n",
      "Epoch 982, Loss: 0.24406201697531202\n",
      "Epoch 983, Loss: 0.24462980559894018\n",
      "Epoch 984, Loss: 0.24445859250568208\n",
      "Epoch 985, Loss: 0.24399933091231754\n",
      "Epoch 986, Loss: 0.24354489312285468\n",
      "Epoch 987, Loss: 0.24427409549554188\n",
      "Epoch 988, Loss: 0.2445281617982047\n",
      "Epoch 989, Loss: 0.24328359808240618\n",
      "Epoch 990, Loss: 0.24385496227514175\n",
      "Epoch 991, Loss: 0.2444427594684419\n",
      "Epoch 992, Loss: 0.2450166419290361\n",
      "Epoch 993, Loss: 0.2434377473592758\n",
      "Epoch 994, Loss: 0.24457375858511243\n",
      "Epoch 995, Loss: 0.2440119580995469\n",
      "Epoch 996, Loss: 0.24291351253078097\n",
      "Epoch 997, Loss: 0.2447838418824332\n",
      "Epoch 998, Loss: 0.24316023554120744\n",
      "Epoch 999, Loss: 0.24434080237434025\n",
      "Epoch 1000, Loss: 0.24413973283200036\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T03:51:27.059841Z",
     "start_time": "2024-08-18T03:51:26.029597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "# loader = test_loader\n",
    "loader = train_loader\n",
    "results = []\n",
    "results_x = []\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU\n",
    "        outputs = model(inputs)\n",
    "        results.append(outputs)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class (highest log-probability)\n",
    "        x, predicted = torch.max(outputs, 1)\n",
    "        results_x.append((x, predicted))\n",
    "        \n",
    "        # print(outputs)\n",
    "        # Calculate the number of correct predictions\n",
    "        correct += (predicted == labels.argmax(dim=1)).sum().item()  # labels.argmax(dim=1) for one-hot encoded labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "avg_test_loss = test_loss / len(loader)\n",
    "accuracy = correct / total * 100\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n"
   ],
   "id": "79d1b5f8f20b8372",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2184, Test Accuracy: 64.76%\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T03:51:50.904901Z",
     "start_time": "2024-08-18T03:51:50.896898Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"model/model_CNN_2_1.t\")",
   "id": "560260b8b384345c",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loaded_model = CNN_1().to(device)\n",
    "loaded_model.load_state_dict(torch.load(\"model/model_CNN_2_1.t\"))\n",
    "# loaded_model = NetDropoutBig().to(device)\n",
    "# loaded_model.load_state_dict(torch.load(\"model/model_CNN_L_B.t\"))"
   ],
   "id": "97652cd5f367dc9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mel spectrogram model",
   "id": "7593df99db843122"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:57:16.976078Z",
     "start_time": "2024-08-21T23:57:16.969750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.dropout_conv1 = nn.Dropout2d(p=0.5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.dropout_conv2 = nn.Dropout2d(p=0.5)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.dropout_conv3 = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 2 * (44 // 2 // 2 // 2), 256)  # Adjust based on the output size from feature extractor\n",
    "        self.fc1_dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc2_dropout = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(128, 7)  # 7 output units for 7 emotions\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.dropout_conv1(torch.relu(self.conv1(x))))\n",
    "        x = self.pool(self.dropout_conv2(torch.relu(self.conv2(x))))\n",
    "        x = self.pool(self.dropout_conv3(torch.relu(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1_dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2_dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return self.sigmoid(x)"
   ],
   "id": "f8a3099e141068db",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T03:52:04.298678Z",
     "start_time": "2024-08-18T03:52:02.741171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('datasets/dataset_2_2.csv')\n",
    "N_MELS = 16\n",
    "TIME_FRAMES = int(704 / N_MELS)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, :-7].values  # First 704 columns as features\n",
    "y = df.iloc[:, -7:].values  # Last 7 columns as labels\n",
    "\n",
    "X_reshaped = X.reshape(-1, 1, N_MELS, TIME_FRAMES)\n",
    "\n",
    "print(X.shape, X_reshaped.shape, X_reshaped[0].shape)\n",
    "# Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X_reshaped)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X_reshaped, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n"
   ],
   "id": "c3f935bd4067232b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20990, 704) (20990, 1, 16, 44) (1, 16, 44)\n"
     ]
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T03:52:12.661890Z",
     "start_time": "2024-08-18T03:52:12.649156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 80% training and 20% testing split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "n_epochs = 500\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNN_2().to(device)\n",
    "# model = NetDropoutBig().to(device)\n",
    "criterion = nn.BCELoss()  # Assuming multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "b8f529c89a079acb",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T04:03:03.098516Z",
     "start_time": "2024-08-18T03:52:16.655357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "for epoch in range(n_epochs):  # Number of epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n"
   ],
   "id": "ed55615dba8e834e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4791552142869859\n",
      "Epoch 2, Loss: 0.43286370549883163\n",
      "Epoch 3, Loss: 0.4252861285777319\n",
      "Epoch 4, Loss: 0.42062427009854997\n",
      "Epoch 5, Loss: 0.4180423634960538\n",
      "Epoch 6, Loss: 0.41535464519546145\n",
      "Epoch 7, Loss: 0.413453475804556\n",
      "Epoch 8, Loss: 0.4105277957802727\n",
      "Epoch 9, Loss: 0.40609642721357797\n",
      "Epoch 10, Loss: 0.4004548645019531\n",
      "Epoch 11, Loss: 0.3944721519379389\n",
      "Epoch 12, Loss: 0.3890017412390028\n",
      "Epoch 13, Loss: 0.3836770900658199\n",
      "Epoch 14, Loss: 0.3793657392547244\n",
      "Epoch 15, Loss: 0.37513214656284877\n",
      "Epoch 16, Loss: 0.37169519765036446\n",
      "Epoch 17, Loss: 0.3685377051716759\n",
      "Epoch 18, Loss: 0.3663645627385094\n",
      "Epoch 19, Loss: 0.36287262655439834\n",
      "Epoch 20, Loss: 0.3590447570028759\n",
      "Epoch 21, Loss: 0.35706651528676353\n",
      "Epoch 22, Loss: 0.3544048733370645\n",
      "Epoch 23, Loss: 0.35181389547529673\n",
      "Epoch 24, Loss: 0.34871350356510705\n",
      "Epoch 25, Loss: 0.3460703848089491\n",
      "Epoch 26, Loss: 0.3425153544970921\n",
      "Epoch 27, Loss: 0.34051265614373344\n",
      "Epoch 28, Loss: 0.3374666392803192\n",
      "Epoch 29, Loss: 0.3365363944144476\n",
      "Epoch 30, Loss: 0.3322077632801873\n",
      "Epoch 31, Loss: 0.3304957407996768\n",
      "Epoch 32, Loss: 0.3270737950007121\n",
      "Epoch 33, Loss: 0.3253197163059598\n",
      "Epoch 34, Loss: 0.32267523995467595\n",
      "Epoch 35, Loss: 0.3221025564840862\n",
      "Epoch 36, Loss: 0.32018385347865874\n",
      "Epoch 37, Loss: 0.3173684364557266\n",
      "Epoch 38, Loss: 0.3153219984258924\n",
      "Epoch 39, Loss: 0.3134990764231909\n",
      "Epoch 40, Loss: 0.31079326799937657\n",
      "Epoch 41, Loss: 0.3089752970706849\n",
      "Epoch 42, Loss: 0.3075383391834441\n",
      "Epoch 43, Loss: 0.306397165173576\n",
      "Epoch 44, Loss: 0.30308057154927937\n",
      "Epoch 45, Loss: 0.303716183531852\n",
      "Epoch 46, Loss: 0.3021217423109781\n",
      "Epoch 47, Loss: 0.30071126841363455\n",
      "Epoch 48, Loss: 0.29897657876922973\n",
      "Epoch 49, Loss: 0.2978594851777667\n",
      "Epoch 50, Loss: 0.29598373342128026\n",
      "Epoch 51, Loss: 0.29344220547449024\n",
      "Epoch 52, Loss: 0.2946384337686357\n",
      "Epoch 53, Loss: 0.2931901470820109\n",
      "Epoch 54, Loss: 0.2914209483634858\n",
      "Epoch 55, Loss: 0.2908383826414744\n",
      "Epoch 56, Loss: 0.2902356737568265\n",
      "Epoch 57, Loss: 0.28772920722053164\n",
      "Epoch 58, Loss: 0.28827510342711493\n",
      "Epoch 59, Loss: 0.2876368885380881\n",
      "Epoch 60, Loss: 0.28471341737679073\n",
      "Epoch 61, Loss: 0.2853927076998211\n",
      "Epoch 62, Loss: 0.2853178781838644\n",
      "Epoch 63, Loss: 0.2840410228002639\n",
      "Epoch 64, Loss: 0.28410816941942485\n",
      "Epoch 65, Loss: 0.2825908937624523\n",
      "Epoch 66, Loss: 0.28117656713440303\n",
      "Epoch 67, Loss: 0.28173346224285306\n",
      "Epoch 68, Loss: 0.28071364178544\n",
      "Epoch 69, Loss: 0.2808651367823283\n",
      "Epoch 70, Loss: 0.2790828907773608\n",
      "Epoch 71, Loss: 0.27710308350267865\n",
      "Epoch 72, Loss: 0.2770456933123725\n",
      "Epoch 73, Loss: 0.2774755161432993\n",
      "Epoch 74, Loss: 0.27618478638785227\n",
      "Epoch 75, Loss: 0.2749106945026489\n",
      "Epoch 76, Loss: 0.2751963980992635\n",
      "Epoch 77, Loss: 0.27397720677512033\n",
      "Epoch 78, Loss: 0.2748230437437693\n",
      "Epoch 79, Loss: 0.27337240375223615\n",
      "Epoch 80, Loss: 0.2722222167821158\n",
      "Epoch 81, Loss: 0.2713909724212828\n",
      "Epoch 82, Loss: 0.2707663304181326\n",
      "Epoch 83, Loss: 0.2706201665458225\n",
      "Epoch 84, Loss: 0.270532110390209\n",
      "Epoch 85, Loss: 0.2703759110257739\n",
      "Epoch 86, Loss: 0.26990587365059626\n",
      "Epoch 87, Loss: 0.27026809732119245\n",
      "Epoch 88, Loss: 0.26937847818647115\n",
      "Epoch 89, Loss: 0.26792762804599035\n",
      "Epoch 90, Loss: 0.2678152751354944\n",
      "Epoch 91, Loss: 0.2668836615482966\n",
      "Epoch 92, Loss: 0.26611593797093347\n",
      "Epoch 93, Loss: 0.26617991541113173\n",
      "Epoch 94, Loss: 0.26561395585536957\n",
      "Epoch 95, Loss: 0.2655461070367268\n",
      "Epoch 96, Loss: 0.2647104736169179\n",
      "Epoch 97, Loss: 0.2655823149283727\n",
      "Epoch 98, Loss: 0.2652241236255282\n",
      "Epoch 99, Loss: 0.2633611033927827\n",
      "Epoch 100, Loss: 0.26350623062678746\n",
      "Epoch 101, Loss: 0.26283587027163735\n",
      "Epoch 102, Loss: 0.26256885383810313\n",
      "Epoch 103, Loss: 0.262475810505095\n",
      "Epoch 104, Loss: 0.2598002261491049\n",
      "Epoch 105, Loss: 0.2604116481542587\n",
      "Epoch 106, Loss: 0.26100988101391565\n",
      "Epoch 107, Loss: 0.25905526416642327\n",
      "Epoch 108, Loss: 0.25874475323018575\n",
      "Epoch 109, Loss: 0.26116783156281426\n",
      "Epoch 110, Loss: 0.25921495710100445\n",
      "Epoch 111, Loss: 0.2583208685829526\n",
      "Epoch 112, Loss: 0.25898427435329985\n",
      "Epoch 113, Loss: 0.2579358643861044\n",
      "Epoch 114, Loss: 0.2559535498846145\n",
      "Epoch 115, Loss: 0.2563295740456808\n",
      "Epoch 116, Loss: 0.25612558540843783\n",
      "Epoch 117, Loss: 0.2566713958978653\n",
      "Epoch 118, Loss: 0.2563173921619143\n",
      "Epoch 119, Loss: 0.2551480440582548\n",
      "Epoch 120, Loss: 0.2552136360463642\n",
      "Epoch 121, Loss: 0.25522507800942373\n",
      "Epoch 122, Loss: 0.2541631524903434\n",
      "Epoch 123, Loss: 0.25460611235527764\n",
      "Epoch 124, Loss: 0.25521813798518406\n",
      "Epoch 125, Loss: 0.2521331124646323\n",
      "Epoch 126, Loss: 0.25316037515799206\n",
      "Epoch 127, Loss: 0.2541656300851277\n",
      "Epoch 128, Loss: 0.25333477814992267\n",
      "Epoch 129, Loss: 0.25173271159331007\n",
      "Epoch 130, Loss: 0.25072630814143587\n",
      "Epoch 131, Loss: 0.2512850098382859\n",
      "Epoch 132, Loss: 0.2511098168861298\n",
      "Epoch 133, Loss: 0.2506493150904065\n",
      "Epoch 134, Loss: 0.25087920469897135\n",
      "Epoch 135, Loss: 0.2498159506775084\n",
      "Epoch 136, Loss: 0.2507529742377145\n",
      "Epoch 137, Loss: 0.2502083384423029\n",
      "Epoch 138, Loss: 0.25130070660795484\n",
      "Epoch 139, Loss: 0.24953162783668154\n",
      "Epoch 140, Loss: 0.250074863802819\n",
      "Epoch 141, Loss: 0.24967684791201636\n",
      "Epoch 142, Loss: 0.24852827259472438\n",
      "Epoch 143, Loss: 0.24945165980429876\n",
      "Epoch 144, Loss: 0.24743036471662067\n",
      "Epoch 145, Loss: 0.2472053341070811\n",
      "Epoch 146, Loss: 0.2489462366274425\n",
      "Epoch 147, Loss: 0.24873974536146437\n",
      "Epoch 148, Loss: 0.24784132892177219\n",
      "Epoch 149, Loss: 0.2459971525839397\n",
      "Epoch 150, Loss: 0.24603361649172648\n",
      "Epoch 151, Loss: 0.247097417258081\n",
      "Epoch 152, Loss: 0.24599580449717384\n",
      "Epoch 153, Loss: 0.24448215257553826\n",
      "Epoch 154, Loss: 0.2460923548823311\n",
      "Epoch 155, Loss: 0.2435115264710926\n",
      "Epoch 156, Loss: 0.24475867166405632\n",
      "Epoch 157, Loss: 0.2433260463816779\n",
      "Epoch 158, Loss: 0.24511002123355866\n",
      "Epoch 159, Loss: 0.24317450231029875\n",
      "Epoch 160, Loss: 0.24499412181831542\n",
      "Epoch 161, Loss: 0.24234211873440514\n",
      "Epoch 162, Loss: 0.24415000078224\n",
      "Epoch 163, Loss: 0.24396440872124264\n",
      "Epoch 164, Loss: 0.2428419000478018\n",
      "Epoch 165, Loss: 0.24205011966682616\n",
      "Epoch 166, Loss: 0.24083538608891622\n",
      "Epoch 167, Loss: 0.24426405401456924\n",
      "Epoch 168, Loss: 0.24119416180111114\n",
      "Epoch 169, Loss: 0.24130509694417318\n",
      "Epoch 170, Loss: 0.24101788850057693\n",
      "Epoch 171, Loss: 0.23926840015820094\n",
      "Epoch 172, Loss: 0.2410841514099212\n",
      "Epoch 173, Loss: 0.24084575814860207\n",
      "Epoch 174, Loss: 0.23905888421194893\n",
      "Epoch 175, Loss: 0.2414363443851471\n",
      "Epoch 176, Loss: 0.24009857132321313\n",
      "Epoch 177, Loss: 0.2376768668492635\n",
      "Epoch 178, Loss: 0.2395784626688276\n",
      "Epoch 179, Loss: 0.2391528679359527\n",
      "Epoch 180, Loss: 0.23998446751208533\n",
      "Epoch 181, Loss: 0.2382868526663099\n",
      "Epoch 182, Loss: 0.2381357669262659\n",
      "Epoch 183, Loss: 0.23914558876128425\n",
      "Epoch 184, Loss: 0.23737496989113943\n",
      "Epoch 185, Loss: 0.2396473247096652\n",
      "Epoch 186, Loss: 0.23766592136451176\n",
      "Epoch 187, Loss: 0.2390241898383413\n",
      "Epoch 188, Loss: 0.23770200930890584\n",
      "Epoch 189, Loss: 0.23729565089657192\n",
      "Epoch 190, Loss: 0.23759156678404128\n",
      "Epoch 191, Loss: 0.2363629766021456\n",
      "Epoch 192, Loss: 0.23624939223130545\n",
      "Epoch 193, Loss: 0.23790304226534706\n",
      "Epoch 194, Loss: 0.2379029381275177\n",
      "Epoch 195, Loss: 0.23584236775125775\n",
      "Epoch 196, Loss: 0.2355661829028811\n",
      "Epoch 197, Loss: 0.23484463666166577\n",
      "Epoch 198, Loss: 0.23469343446549915\n",
      "Epoch 199, Loss: 0.2342881376118887\n",
      "Epoch 200, Loss: 0.2342258407956078\n",
      "Epoch 201, Loss: 0.23582275044350398\n",
      "Epoch 202, Loss: 0.23380664893559047\n",
      "Epoch 203, Loss: 0.23456918381509326\n",
      "Epoch 204, Loss: 0.23513712187608082\n",
      "Epoch 205, Loss: 0.23621343015205293\n",
      "Epoch 206, Loss: 0.23260048747062684\n",
      "Epoch 207, Loss: 0.23246131837368011\n",
      "Epoch 208, Loss: 0.23220074324380785\n",
      "Epoch 209, Loss: 0.23404490760394506\n",
      "Epoch 210, Loss: 0.2352400687762669\n",
      "Epoch 211, Loss: 0.23315718032064892\n",
      "Epoch 212, Loss: 0.23368605979851315\n",
      "Epoch 213, Loss: 0.23317804714043935\n",
      "Epoch 214, Loss: 0.23248750411328814\n",
      "Epoch 215, Loss: 0.23326164827460336\n",
      "Epoch 216, Loss: 0.23132698762984502\n",
      "Epoch 217, Loss: 0.23149574591999963\n",
      "Epoch 218, Loss: 0.23107236362638928\n",
      "Epoch 219, Loss: 0.23284323536214374\n",
      "Epoch 220, Loss: 0.2307119723444893\n",
      "Epoch 221, Loss: 0.23012032672053293\n",
      "Epoch 222, Loss: 0.2307857154664539\n",
      "Epoch 223, Loss: 0.2319478367339997\n",
      "Epoch 224, Loss: 0.2303646131640389\n",
      "Epoch 225, Loss: 0.23134434199049358\n",
      "Epoch 226, Loss: 0.22902955048141024\n",
      "Epoch 227, Loss: 0.22992643946693056\n",
      "Epoch 228, Loss: 0.22804743355228788\n",
      "Epoch 229, Loss: 0.23008851431664967\n",
      "Epoch 230, Loss: 0.22900533908889406\n",
      "Epoch 231, Loss: 0.22904388152417682\n",
      "Epoch 232, Loss: 0.22815811827069238\n",
      "Epoch 233, Loss: 0.2264353019566763\n",
      "Epoch 234, Loss: 0.228157107205618\n",
      "Epoch 235, Loss: 0.22851399225848062\n",
      "Epoch 236, Loss: 0.22788834583191644\n",
      "Epoch 237, Loss: 0.22794919493652527\n",
      "Epoch 238, Loss: 0.22793795846757434\n",
      "Epoch 239, Loss: 0.22872469103052503\n",
      "Epoch 240, Loss: 0.22828077912330627\n",
      "Epoch 241, Loss: 0.22909423379671007\n",
      "Epoch 242, Loss: 0.22975344957340332\n",
      "Epoch 243, Loss: 0.22929603710061028\n",
      "Epoch 244, Loss: 0.22788382043441135\n",
      "Epoch 245, Loss: 0.2278727146841231\n",
      "Epoch 246, Loss: 0.22721188824801217\n",
      "Epoch 247, Loss: 0.22698702338195983\n",
      "Epoch 248, Loss: 0.2250451313881647\n",
      "Epoch 249, Loss: 0.22459666747422447\n",
      "Epoch 250, Loss: 0.2256649665889286\n",
      "Epoch 251, Loss: 0.22655184047562735\n",
      "Epoch 252, Loss: 0.2265131634189969\n",
      "Epoch 253, Loss: 0.22672002849124726\n",
      "Epoch 254, Loss: 0.22541895293054126\n",
      "Epoch 255, Loss: 0.22576007533641088\n",
      "Epoch 256, Loss: 0.22393917273907435\n",
      "Epoch 257, Loss: 0.22495989473093123\n",
      "Epoch 258, Loss: 0.22501279595352355\n",
      "Epoch 259, Loss: 0.2253315042597907\n",
      "Epoch 260, Loss: 0.22453392482939222\n",
      "Epoch 261, Loss: 0.22401550179436094\n",
      "Epoch 262, Loss: 0.22384461394378116\n",
      "Epoch 263, Loss: 0.2235628684929439\n",
      "Epoch 264, Loss: 0.22453523936725797\n",
      "Epoch 265, Loss: 0.2238817933059874\n",
      "Epoch 266, Loss: 0.22314590060994738\n",
      "Epoch 267, Loss: 0.2224286943106424\n",
      "Epoch 268, Loss: 0.22354510869298663\n",
      "Epoch 269, Loss: 0.22337318883055732\n",
      "Epoch 270, Loss: 0.22425627228759584\n",
      "Epoch 271, Loss: 0.22450545501141322\n",
      "Epoch 272, Loss: 0.2231572899931953\n",
      "Epoch 273, Loss: 0.22428957703567687\n",
      "Epoch 274, Loss: 0.22094165032818203\n",
      "Epoch 275, Loss: 0.22301338739338375\n",
      "Epoch 276, Loss: 0.22365854061785198\n",
      "Epoch 277, Loss: 0.2223567762403261\n",
      "Epoch 278, Loss: 0.22123932389985948\n",
      "Epoch 279, Loss: 0.22232232014338174\n",
      "Epoch 280, Loss: 0.22168391642116364\n",
      "Epoch 281, Loss: 0.22191015432278316\n",
      "Epoch 282, Loss: 0.22178725622949147\n",
      "Epoch 283, Loss: 0.2218126182329087\n",
      "Epoch 284, Loss: 0.2223833583650135\n",
      "Epoch 285, Loss: 0.21969845302048183\n",
      "Epoch 286, Loss: 0.2214334578457333\n",
      "Epoch 287, Loss: 0.22130735306512742\n",
      "Epoch 288, Loss: 0.22078122402940478\n",
      "Epoch 289, Loss: 0.21973329368091765\n",
      "Epoch 290, Loss: 0.21854642098858243\n",
      "Epoch 291, Loss: 0.2211328553727695\n",
      "Epoch 292, Loss: 0.2211769680182139\n",
      "Epoch 293, Loss: 0.21933008824075972\n",
      "Epoch 294, Loss: 0.22111662873200008\n",
      "Epoch 295, Loss: 0.2209196671701613\n",
      "Epoch 296, Loss: 0.21675413361617496\n",
      "Epoch 297, Loss: 0.21868789180403664\n",
      "Epoch 298, Loss: 0.21961926707199642\n",
      "Epoch 299, Loss: 0.22074597768840334\n",
      "Epoch 300, Loss: 0.2188649088428134\n",
      "Epoch 301, Loss: 0.21947994337195442\n",
      "Epoch 302, Loss: 0.21880174829846336\n",
      "Epoch 303, Loss: 0.2193163754258837\n",
      "Epoch 304, Loss: 0.21781701806045714\n",
      "Epoch 305, Loss: 0.217414264749913\n",
      "Epoch 306, Loss: 0.21803030080738522\n",
      "Epoch 307, Loss: 0.21921591775757926\n",
      "Epoch 308, Loss: 0.22060302318561645\n",
      "Epoch 309, Loss: 0.21574158394620532\n",
      "Epoch 310, Loss: 0.21687176187833151\n",
      "Epoch 311, Loss: 0.21970003604888916\n",
      "Epoch 312, Loss: 0.21867830588704062\n",
      "Epoch 313, Loss: 0.2167920850430216\n",
      "Epoch 314, Loss: 0.21738699263050443\n",
      "Epoch 315, Loss: 0.21785883328744343\n",
      "Epoch 316, Loss: 0.21703819584278833\n",
      "Epoch 317, Loss: 0.21643373168650126\n",
      "Epoch 318, Loss: 0.2165151003996531\n",
      "Epoch 319, Loss: 0.21701427066609974\n",
      "Epoch 320, Loss: 0.21755388758012226\n",
      "Epoch 321, Loss: 0.21600480140674683\n",
      "Epoch 322, Loss: 0.21510521895828702\n",
      "Epoch 323, Loss: 0.21722488854612623\n",
      "Epoch 324, Loss: 0.216239415875503\n",
      "Epoch 325, Loss: 0.21550866908970334\n",
      "Epoch 326, Loss: 0.21449101724794933\n",
      "Epoch 327, Loss: 0.21797197343338104\n",
      "Epoch 328, Loss: 0.21436191802933102\n",
      "Epoch 329, Loss: 0.2164549611579804\n",
      "Epoch 330, Loss: 0.21285634448130925\n",
      "Epoch 331, Loss: 0.21599726957934243\n",
      "Epoch 332, Loss: 0.21534699818917682\n",
      "Epoch 333, Loss: 0.21585110810540972\n",
      "Epoch 334, Loss: 0.21481971544878822\n",
      "Epoch 335, Loss: 0.2151234981985319\n",
      "Epoch 336, Loss: 0.2143808448030835\n",
      "Epoch 337, Loss: 0.21411020612432843\n",
      "Epoch 338, Loss: 0.21279809807028088\n",
      "Epoch 339, Loss: 0.21410904907044911\n",
      "Epoch 340, Loss: 0.2142457867662112\n",
      "Epoch 341, Loss: 0.2149811331431071\n",
      "Epoch 342, Loss: 0.2136290381210191\n",
      "Epoch 343, Loss: 0.21572338261774607\n",
      "Epoch 344, Loss: 0.213950919679233\n",
      "Epoch 345, Loss: 0.2121873589640572\n",
      "Epoch 346, Loss: 0.21417623934291657\n",
      "Epoch 347, Loss: 0.21388468387581053\n",
      "Epoch 348, Loss: 0.21382201531103678\n",
      "Epoch 349, Loss: 0.21352617906672614\n",
      "Epoch 350, Loss: 0.21364366342624028\n",
      "Epoch 351, Loss: 0.2146286079997108\n",
      "Epoch 352, Loss: 0.21140283869845528\n",
      "Epoch 353, Loss: 0.21187887420256932\n",
      "Epoch 354, Loss: 0.2110278759258134\n",
      "Epoch 355, Loss: 0.21234375353370394\n",
      "Epoch 356, Loss: 0.2109090711531185\n",
      "Epoch 357, Loss: 0.21504918478784107\n",
      "Epoch 358, Loss: 0.2122428390525636\n",
      "Epoch 359, Loss: 0.20995843424683525\n",
      "Epoch 360, Loss: 0.21320704871699925\n",
      "Epoch 361, Loss: 0.21078635509525026\n",
      "Epoch 362, Loss: 0.21090986595267341\n",
      "Epoch 363, Loss: 0.2118375756910869\n",
      "Epoch 364, Loss: 0.2115819871141797\n",
      "Epoch 365, Loss: 0.21076063185930252\n",
      "Epoch 366, Loss: 0.21242501020431517\n",
      "Epoch 367, Loss: 0.21100737211250123\n",
      "Epoch 368, Loss: 0.21120937249490193\n",
      "Epoch 369, Loss: 0.21140823568616596\n",
      "Epoch 370, Loss: 0.20966305644739242\n",
      "Epoch 371, Loss: 0.21080588570662906\n",
      "Epoch 372, Loss: 0.21100320953698384\n",
      "Epoch 373, Loss: 0.21063275856631142\n",
      "Epoch 374, Loss: 0.21048088307891574\n",
      "Epoch 375, Loss: 0.2123610025928134\n",
      "Epoch 376, Loss: 0.21045980903364364\n",
      "Epoch 377, Loss: 0.209942515875612\n",
      "Epoch 378, Loss: 0.2126539102480525\n",
      "Epoch 379, Loss: 0.21129367499124435\n",
      "Epoch 380, Loss: 0.21022369201694216\n",
      "Epoch 381, Loss: 0.20883709002108802\n",
      "Epoch 382, Loss: 0.21002947429815927\n",
      "Epoch 383, Loss: 0.20993408119394666\n",
      "Epoch 384, Loss: 0.20881634337561472\n",
      "Epoch 385, Loss: 0.2080817002909524\n",
      "Epoch 386, Loss: 0.2092078596211615\n",
      "Epoch 387, Loss: 0.20930520467814945\n",
      "Epoch 388, Loss: 0.2088587727575075\n",
      "Epoch 389, Loss: 0.2100937424103419\n",
      "Epoch 390, Loss: 0.20959072791394734\n",
      "Epoch 391, Loss: 0.21009203916504268\n",
      "Epoch 392, Loss: 0.2093313163235074\n",
      "Epoch 393, Loss: 0.2076194900132361\n",
      "Epoch 394, Loss: 0.2092529083717437\n",
      "Epoch 395, Loss: 0.20897919999701636\n",
      "Epoch 396, Loss: 0.2090204039641789\n",
      "Epoch 397, Loss: 0.2070689138344356\n",
      "Epoch 398, Loss: 0.20812025714488255\n",
      "Epoch 399, Loss: 0.20897204279899598\n",
      "Epoch 400, Loss: 0.2098700561126073\n",
      "Epoch 401, Loss: 0.20733091808500745\n",
      "Epoch 402, Loss: 0.2072009803425698\n",
      "Epoch 403, Loss: 0.21005639578614915\n",
      "Epoch 404, Loss: 0.20906589441356205\n",
      "Epoch 405, Loss: 0.20862834592660268\n",
      "Epoch 406, Loss: 0.20673350812423796\n",
      "Epoch 407, Loss: 0.2073140670004345\n",
      "Epoch 408, Loss: 0.2069838794072469\n",
      "Epoch 409, Loss: 0.20606394156104044\n",
      "Epoch 410, Loss: 0.2065100701508068\n",
      "Epoch 411, Loss: 0.206842693289121\n",
      "Epoch 412, Loss: 0.20770927588144938\n",
      "Epoch 413, Loss: 0.2046571029509817\n",
      "Epoch 414, Loss: 0.20745501003095082\n",
      "Epoch 415, Loss: 0.20507246192012515\n",
      "Epoch 416, Loss: 0.20378001814796812\n",
      "Epoch 417, Loss: 0.20601030152468455\n",
      "Epoch 418, Loss: 0.20831607827118465\n",
      "Epoch 419, Loss: 0.2061093176546551\n",
      "Epoch 420, Loss: 0.20709020408846082\n",
      "Epoch 421, Loss: 0.20557326231684003\n",
      "Epoch 422, Loss: 0.20560718394461133\n",
      "Epoch 423, Loss: 0.20730370552057312\n",
      "Epoch 424, Loss: 0.2052425743852343\n",
      "Epoch 425, Loss: 0.20535903199797584\n",
      "Epoch 426, Loss: 0.20835232375633148\n",
      "Epoch 427, Loss: 0.20683980064732688\n",
      "Epoch 428, Loss: 0.20409135343063445\n",
      "Epoch 429, Loss: 0.2049818488813582\n",
      "Epoch 430, Loss: 0.20520250453835442\n",
      "Epoch 431, Loss: 0.20347860004220691\n",
      "Epoch 432, Loss: 0.2072238436908949\n",
      "Epoch 433, Loss: 0.20648191791205178\n",
      "Epoch 434, Loss: 0.20671401290666488\n",
      "Epoch 435, Loss: 0.20564899030185882\n",
      "Epoch 436, Loss: 0.20683667549065182\n",
      "Epoch 437, Loss: 0.20626349820977166\n",
      "Epoch 438, Loss: 0.2034622842357272\n",
      "Epoch 439, Loss: 0.2052844348549843\n",
      "Epoch 440, Loss: 0.20430502332392192\n",
      "Epoch 441, Loss: 0.20516477506785166\n",
      "Epoch 442, Loss: 0.20450274859155929\n",
      "Epoch 443, Loss: 0.20273984848033813\n",
      "Epoch 444, Loss: 0.20560786638941084\n",
      "Epoch 445, Loss: 0.20419821053743362\n",
      "Epoch 446, Loss: 0.20442844500144322\n",
      "Epoch 447, Loss: 0.20376105212029957\n",
      "Epoch 448, Loss: 0.20255024641752242\n",
      "Epoch 449, Loss: 0.2051927815732502\n",
      "Epoch 450, Loss: 0.20437671858639944\n",
      "Epoch 451, Loss: 0.20448739562715804\n",
      "Epoch 452, Loss: 0.20422249422186897\n",
      "Epoch 453, Loss: 0.20543157962106523\n",
      "Epoch 454, Loss: 0.2039558000507809\n",
      "Epoch 455, Loss: 0.20490866321892964\n",
      "Epoch 456, Loss: 0.2038847586228734\n",
      "Epoch 457, Loss: 0.20086238394180933\n",
      "Epoch 458, Loss: 0.2045868994366555\n",
      "Epoch 459, Loss: 0.20444290822460537\n",
      "Epoch 460, Loss: 0.20332178389742261\n",
      "Epoch 461, Loss: 0.20473900958186103\n",
      "Epoch 462, Loss: 0.20342755828584944\n",
      "Epoch 463, Loss: 0.20276713975838254\n",
      "Epoch 464, Loss: 0.2030936369867552\n",
      "Epoch 465, Loss: 0.20307233627353397\n",
      "Epoch 466, Loss: 0.20270934182973135\n",
      "Epoch 467, Loss: 0.20398436590319588\n",
      "Epoch 468, Loss: 0.20420646687348684\n",
      "Epoch 469, Loss: 0.20241287335043862\n",
      "Epoch 470, Loss: 0.2012882807708922\n",
      "Epoch 471, Loss: 0.20248192243632815\n",
      "Epoch 472, Loss: 0.20365586224056426\n",
      "Epoch 473, Loss: 0.20114478592361723\n",
      "Epoch 474, Loss: 0.20020128109625407\n",
      "Epoch 475, Loss: 0.20255400071541468\n",
      "Epoch 476, Loss: 0.19981341335035505\n",
      "Epoch 477, Loss: 0.20380882595266614\n",
      "Epoch 478, Loss: 0.20473104647227697\n",
      "Epoch 479, Loss: 0.20120435577063334\n",
      "Epoch 480, Loss: 0.20172638358104797\n",
      "Epoch 481, Loss: 0.20395221318517412\n",
      "Epoch 482, Loss: 0.2005622537363143\n",
      "Epoch 483, Loss: 0.20162721483480361\n",
      "Epoch 484, Loss: 0.2014983265598615\n",
      "Epoch 485, Loss: 0.1998934730887413\n",
      "Epoch 486, Loss: 0.20077031091565178\n",
      "Epoch 487, Loss: 0.20332768873089835\n",
      "Epoch 488, Loss: 0.20257078620649518\n",
      "Epoch 489, Loss: 0.19981708498228165\n",
      "Epoch 490, Loss: 0.20070063664799645\n",
      "Epoch 491, Loss: 0.2005997709149406\n",
      "Epoch 492, Loss: 0.2020405734011105\n",
      "Epoch 493, Loss: 0.19944927260989234\n",
      "Epoch 494, Loss: 0.2009296865832238\n",
      "Epoch 495, Loss: 0.19924906615700042\n",
      "Epoch 496, Loss: 0.2001933330439386\n",
      "Epoch 497, Loss: 0.2009571828302883\n",
      "Epoch 498, Loss: 0.20156322408290137\n",
      "Epoch 499, Loss: 0.20021191186848142\n",
      "Epoch 500, Loss: 0.20223203342585336\n"
     ]
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T04:16:15.603203Z",
     "start_time": "2024-08-18T04:16:15.298044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "loader = test_loader\n",
    "# loader = train_loader\n",
    "results = []\n",
    "results_x = []\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU\n",
    "        outputs = model(inputs)\n",
    "        results.append(outputs)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class (highest log-probability)\n",
    "        x, predicted = torch.max(outputs, 1)\n",
    "        results_x.append((x, predicted))\n",
    "        \n",
    "        # print(outputs)\n",
    "        # Calculate the number of correct predictions\n",
    "        correct += (predicted == labels.argmax(dim=1)).sum().item()  # labels.argmax(dim=1) for one-hot encoded labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "avg_test_loss = test_loss / len(loader)\n",
    "accuracy = correct / total * 100\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "# 90% 62%"
   ],
   "id": "b02ec5cf540aa43d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2210, Test Accuracy: 63.17%\n"
     ]
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T04:16:35.510054Z",
     "start_time": "2024-08-18T04:16:35.495346Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"model/model_CNN_2_2.t\")",
   "id": "d3f58cafea3a2e17",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T02:40:10.406524Z",
     "start_time": "2024-08-18T02:40:10.367245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_cnn_2_model = CNN_2().to(device)\n",
    "loaded_cnn_2_model.load_state_dict(torch.load(\"model/model_CNN_2_2.t\"))"
   ],
   "id": "d9de2c9a599b779",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test of combination of models",
   "id": "2871cc2df76b20f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:57:27.442059Z",
     "start_time": "2024-08-21T23:57:25.582931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "df_1 = pd.read_csv('datasets/dataset_2_1.csv')\n",
    "df_2 = pd.read_csv('datasets/dataset_2_2.csv')\n",
    "N_MELS = 16\n",
    "TIME_FRAMES = int(704 / N_MELS)\n",
    "\n",
    "# Separate features and labels\n",
    "X_1 = df_1.iloc[:, :-7].values  # First 198 columns as features\n",
    "y_1 = df_1.iloc[:, -7:].values  # Last 7 columns as labels\n",
    "X_2 = df_2.iloc[:, :-7].values  # First 704 columns as features\n",
    "y_2 = df_2.iloc[:, -7:].values  # Last 7 columns as labels\n",
    "\n",
    "X_2_reshaped = X_2.reshape(-1, 1, N_MELS, TIME_FRAMES)\n",
    "# scaler = StandardScaler()\n",
    "# X_1 = scaler.fit_transform(X_1)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor_1 = torch.tensor(X_1, dtype=torch.float32).unsqueeze(1)\n",
    "y_tensor_1 = torch.tensor(y_1, dtype=torch.float32)\n",
    "X_tensor_2 = torch.tensor(X_2_reshaped, dtype=torch.float32)\n",
    "y_tensor_2 = torch.tensor(y_2, dtype=torch.float32)\n",
    "\n",
    "dataset_1 = TensorDataset(X_tensor_1, y_tensor_1)\n",
    "dataset_2 = TensorDataset(X_tensor_2, y_tensor_2)\n"
   ],
   "id": "3ed6fad1bdfc0676",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:57:49.249900Z",
     "start_time": "2024-08-21T23:57:49.245946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "test_loader_1 = DataLoader(dataset_1, batch_size=batch_size, shuffle=False)\n",
    "test_loader_2 = DataLoader(dataset_2, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "id": "3059ae4d0382fe9e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:57:50.159472Z",
     "start_time": "2024-08-21T23:57:50.033833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_cnn_1_model = CNN_1().to(device)\n",
    "loaded_cnn_1_model.load_state_dict(torch.load(\"model/model_CNN_2_1.t\"))\n",
    "\n",
    "loaded_cnn_2_model = CNN_2().to(device)\n",
    "loaded_cnn_2_model.load_state_dict(torch.load(\"model/model_CNN_2_2.t\"))"
   ],
   "id": "4e86c74ce4cfc787",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:57:54.065343Z",
     "start_time": "2024-08-21T23:57:51.967990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaded_cnn_1_model.eval()  # Set the model to evaluation mode\n",
    "loaded_cnn_2_model.eval()  # Set the model to evaluation mode\n",
    "test_loss1 = 0.0\n",
    "test_loss2 = 0.0\n",
    "combined_test_loss = 0.0\n",
    "correct1 = 0\n",
    "correct2 = 0\n",
    "combined_correct = 0\n",
    "total = 0\n",
    "results1 = []\n",
    "results2 = []\n",
    "results_combined = []\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for (data1, data2) in zip(test_loader_1, test_loader_2):\n",
    "        inputs1, labels1 = data1\n",
    "        inputs2, labels2 = data2\n",
    "        \n",
    "        inputs1, labels1 = inputs1.to(device), labels1.to(device)\n",
    "        inputs2, labels2 = inputs2.to(device), labels2.to(device)\n",
    "        \n",
    "        outputs1 = loaded_cnn_1_model(inputs1)\n",
    "        outputs2 = loaded_cnn_2_model(inputs2)\n",
    "        \n",
    "        combined_outputs = (outputs1 + outputs2) / 2\n",
    "        results1.append(outputs1)\n",
    "        results2.append(outputs2)\n",
    "        results_combined.append(combined_outputs)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss1 = criterion(outputs1, labels2)\n",
    "        loss2 = criterion(outputs2, labels2)\n",
    "        combined_loss = criterion(combined_outputs, labels1)\n",
    "        \n",
    "        test_loss1 += loss1.item()\n",
    "        test_loss2 += loss2.item()\n",
    "        combined_test_loss += combined_loss.item()\n",
    "\n",
    "        # Get the predicted class (highest log-probability)\n",
    "        x1, predicted1 = torch.max(outputs1, 1)\n",
    "        x2, predicted2 = torch.max(outputs2, 1)\n",
    "        _, combined_predicted = torch.max(combined_outputs, 1)\n",
    "        \n",
    "        # print(outputs)\n",
    "        # Calculate the number of correct predictions\n",
    "        correct1 += (predicted1 == labels1.argmax(dim=1)).sum().item()  # labels.argmax(dim=1) for one-hot encoded labels\n",
    "        correct2 += (predicted2 == labels2.argmax(dim=1)).sum().item()  # labels.argmax(dim=1) for one-hot encoded labels\n",
    "        combined_correct += (combined_predicted == labels1.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        total += labels1.size(0)\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "avg_test_loss1 = test_loss1 / len(test_loader_1)\n",
    "avg_test_loss2 = test_loss2 / len(test_loader_2)\n",
    "avg_combined_test_loss = combined_test_loss / len(test_loader_1)\n",
    "\n",
    "accuracy1 = correct1 / total * 100\n",
    "accuracy2 = correct2 / total * 100\n",
    "combined_accuracy = combined_correct / total * 100\n",
    "\n",
    "print(f'Test Loss 1: {avg_test_loss1:.4f}, Test Accuracy 1: {accuracy1:.2f}%')\n",
    "print(f'Test Loss 2: {avg_test_loss2:.4f}, Test Accuracy 2: {accuracy2:.2f}%')\n",
    "print(f'Combined - Test Loss: {avg_combined_test_loss:.4f}, Test Accuracy: {combined_accuracy:.2f}%')\n",
    "# 62% 82% 81%"
   ],
   "id": "ee1c97ce43fb7b3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 1: 0.2236, Test Accuracy 1: 63.38%\n",
      "Test Loss 2: 0.1386, Test Accuracy 2: 82.38%\n",
      "Combined - Test Loss: 0.1669, Test Accuracy: 81.41%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5fc44c16ca89d604"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
