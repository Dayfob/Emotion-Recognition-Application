{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-10T00:45:36.210862Z",
     "start_time": "2024-08-10T00:45:35.467849Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "# to save the audio files\n",
    "import soundfile as sf\n",
    "\n",
    "# import keras\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "# from keras.utils import np_utils, to_categorical\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T00:45:38.255310Z",
     "start_time": "2024-08-10T00:45:38.252654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths for data.\n",
    "Ravdess = \"datasets/Ravdess/audio_speech_actors_01-24/\"\n",
    "Crema = \"datasets/Crema/\"\n",
    "Tess = \"datasets/Tess/\"\n",
    "Savee = \"datasets/Savee/\""
   ],
   "id": "471b8a2d6c7160b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Trimming and combining (0.6)",
   "id": "a26c2fdfb8eab4f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "crema_directory_list = os.listdir(Crema)\n",
    "tess_directory_list = os.listdir(Tess)\n",
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "segment_length = 0.6"
   ],
   "id": "181bf43e9dbf6db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ravdess",
   "id": "6e826899a3ff3c8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T01:40:40.331593Z",
     "start_time": "2024-08-05T01:40:17.639373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "actor_counter = 0\n",
    "\n",
    "# Loop through each file and get the length\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(Ravdess + dir)\n",
    "    actor_samples_counter = 0\n",
    "\n",
    "    for file in actor:\n",
    "\n",
    "        # dir = ravdess_directory_list[0]\n",
    "        # file = os.listdir(Ravdess + dir)[0]\n",
    "\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        if int(part[2]) == 1 or int(part[2]) == 2:\n",
    "            path = \"datasets/combined/neutral+calm/\"\n",
    "        elif int(part[2]) == 3:\n",
    "            path = \"datasets/combined/happy/\"\n",
    "        elif int(part[2]) == 4:\n",
    "            path = \"datasets/combined/sad/\"\n",
    "        elif int(part[2]) == 5:\n",
    "            path = \"datasets/combined/angry/\"\n",
    "        elif int(part[2]) == 6:\n",
    "            path = \"datasets/combined/fear/\"\n",
    "        elif int(part[2]) == 7:\n",
    "            path = \"datasets/combined/disgust/\"\n",
    "        elif int(part[2]) == 8:\n",
    "            path = \"datasets/combined/surprised/\"\n",
    "        else:\n",
    "            path = \"datasets/combined/\"\n",
    "\n",
    "        y, sr = librosa.load(Ravdess + dir + '/' + file)\n",
    "        y_trimmed, _ = librosa.effects.trim(y, top_db=50)\n",
    "        normalized_audio = librosa.util.normalize(y_trimmed)\n",
    "\n",
    "        # Segment length in samples\n",
    "        segment_length_samples = int(segment_length * sr)\n",
    "\n",
    "        # Number of segments\n",
    "        num_segments = len(normalized_audio) // segment_length_samples\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length_samples\n",
    "            end_sample = start_sample + segment_length_samples\n",
    "            segment = normalized_audio[start_sample:end_sample]\n",
    "            output_file_path = os.path.join(path, f'ravdess_{actor_counter}_{actor_samples_counter}_{i}.wav')\n",
    "            sf.write(output_file_path, segment, sr)\n",
    "\n",
    "        actor_samples_counter += 1\n",
    "    actor_counter += 1\n"
   ],
   "id": "1d2ed36788c65973",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Crema",
   "id": "94e13f16fd533d7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T01:51:15.755593Z",
     "start_time": "2024-08-05T01:48:38.521314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_counter = 0\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    part = file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        path = \"datasets/combined/sad/\"\n",
    "    elif part[2] == 'ANG':\n",
    "        path = \"datasets/combined/angry/\"\n",
    "    elif part[2] == 'DIS':\n",
    "        path = \"datasets/combined/disgust/\"\n",
    "    elif part[2] == 'FEA':\n",
    "        path = \"datasets/combined/fear/\"\n",
    "    elif part[2] == 'HAP':\n",
    "        path = \"datasets/combined/happy/\"\n",
    "    elif part[2] == 'NEU':\n",
    "        path = \"datasets/combined/neutral+calm/\"\n",
    "    else:\n",
    "        path = \"datasets/combined/\"\n",
    "\n",
    "    y, sr = librosa.load(Crema + file)\n",
    "    y_trimmed, _ = librosa.effects.trim(y, top_db=25)\n",
    "    normalized_audio = librosa.util.normalize(y_trimmed)\n",
    "\n",
    "    # Segment length in samples\n",
    "    segment_length_samples = int(segment_length * sr)\n",
    "\n",
    "    # Number of segments\n",
    "    num_segments = len(normalized_audio) // segment_length_samples\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_length_samples\n",
    "        end_sample = start_sample + segment_length_samples\n",
    "        segment = normalized_audio[start_sample:end_sample]\n",
    "        output_file_path = os.path.join(path, f'crema_{file_counter}_{i}.wav')\n",
    "        sf.write(output_file_path, segment, sr)\n",
    "\n",
    "    file_counter += 1\n"
   ],
   "id": "2106abac9b01ce71",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tess",
   "id": "458ae5f9ec5df11a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:03:48.472762Z",
     "start_time": "2024-08-05T02:03:00.959370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tess\n",
    "folder_counter = 0\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    file_counter = 0\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "\n",
    "        if part == \"angry\":\n",
    "            path = \"datasets/combined/angry/\"\n",
    "        elif part == \"disgust\":\n",
    "            path = \"datasets/combined/disgust/\"\n",
    "        elif part == \"fear\":\n",
    "            path = \"datasets/combined/fear/\"\n",
    "        elif part == \"happy\":\n",
    "            path = \"datasets/combined/happy/\"\n",
    "        elif part == \"neutral\":\n",
    "            path = \"datasets/combined/neutral+calm/\"\n",
    "        elif part == 'ps':\n",
    "            path = \"datasets/combined/surprised/\"\n",
    "        elif part == 'sad':\n",
    "            path = \"datasets/combined/sad/\"\n",
    "        else:\n",
    "            path = \"datasets/combined/\"\n",
    "\n",
    "        y, sr = librosa.load(Tess + dir + '/' + file)\n",
    "        y_trimmed, _ = librosa.effects.trim(y)\n",
    "        normalized_audio = librosa.util.normalize(y_trimmed)\n",
    "\n",
    "        # Segment length in samples\n",
    "        segment_length_samples = int(segment_length * sr)\n",
    "\n",
    "        # Number of segments\n",
    "        num_segments = len(normalized_audio) // segment_length_samples\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length_samples\n",
    "            end_sample = start_sample + segment_length_samples\n",
    "            segment = normalized_audio[start_sample:end_sample]\n",
    "            output_file_path = os.path.join(path, f'tess_{folder_counter}_{file_counter}_{i}.wav')\n",
    "            sf.write(output_file_path, segment, sr)\n",
    "\n",
    "        file_counter += 1\n",
    "    folder_counter += 1"
   ],
   "id": "7c376e0dd0118ec3",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Savee",
   "id": "2804644319d4c484"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:12:54.205553Z",
     "start_time": "2024-08-05T02:12:42.232355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# savee\n",
    "file_counter = 0\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele == 'a':\n",
    "        path = \"datasets/combined/angry/\"\n",
    "    elif ele == 'd':\n",
    "        path = \"datasets/combined/disgust/\"\n",
    "    elif ele == 'f':\n",
    "        path = \"datasets/combined/fear/\"\n",
    "    elif ele == 'h':\n",
    "        path = \"datasets/combined/happy/\"\n",
    "    elif ele == 'n':\n",
    "        path = \"datasets/combined/neutral+calm/\"\n",
    "    elif ele == 'sa':\n",
    "        path = \"datasets/combined/sad/\"\n",
    "    elif ele == 'su':\n",
    "        path = \"datasets/combined/surprised/\"\n",
    "    else:\n",
    "        path = \"datasets/combined/\"\n",
    "\n",
    "    y, sr = librosa.load(Savee + file)\n",
    "    y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "    normalized_audio = librosa.util.normalize(y_trimmed)\n",
    "\n",
    "    # Segment length in samples\n",
    "    segment_length_samples = int(segment_length * sr)\n",
    "\n",
    "    # Number of segments\n",
    "    num_segments = len(normalized_audio) // segment_length_samples\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_length_samples\n",
    "        end_sample = start_sample + segment_length_samples\n",
    "        segment = normalized_audio[start_sample:end_sample]\n",
    "        output_file_path = os.path.join(path, f'savee_{file_counter}_{i}.wav')\n",
    "        sf.write(output_file_path, segment, sr)\n",
    "\n",
    "    file_counter += 1\n"
   ],
   "id": "1a8aad15604f890b",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Augmentation",
   "id": "2790e6e064ba9e44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T03:02:48.150405Z",
     "start_time": "2024-08-05T03:02:48.145530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Individual augmentation functions\n",
    "def pitch_shift(audio, sampling_rate, n_steps):\n",
    "    return librosa.effects.pitch_shift(audio, sr=sampling_rate, n_steps=n_steps)\n",
    "\n",
    "def add_noise(audio, noise_factor):\n",
    "    noise_amp = noise_factor*np.random.uniform()*np.amax(audio)\n",
    "    audio = audio + noise_amp*np.random.normal(size=audio.shape[0])\n",
    "    return audio\n",
    "\n",
    "def frequency_masking(audio, sr, freq_mask_param=15):\n",
    "    spectrogram = librosa.stft(audio)\n",
    "    spectrogram_db = librosa.amplitude_to_db(np.abs(spectrogram))\n",
    "    \n",
    "    freq_mask = np.random.randint(0, spectrogram_db.shape[0] - freq_mask_param)\n",
    "    spectrogram_db[freq_mask:freq_mask + freq_mask_param, :] = 0\n",
    "    \n",
    "    masked_audio = librosa.istft(librosa.db_to_amplitude(spectrogram_db))\n",
    "    return masked_audio\n",
    "\n",
    "def time_masking(audio, sr, time_mask_param=30):\n",
    "    spectrogram = librosa.stft(audio)\n",
    "    spectrogram_db = librosa.amplitude_to_db(np.abs(spectrogram))\n",
    "    \n",
    "    time_mask = np.random.randint(0, spectrogram_db.shape[1] - time_mask_param)\n",
    "    spectrogram_db[:, time_mask:time_mask + time_mask_param] = 0\n",
    "    \n",
    "    masked_audio = librosa.istft(librosa.db_to_amplitude(spectrogram_db))\n",
    "    return masked_audio\n",
    "\n",
    "# Combination augmentation function\n",
    "def combine_augmentations(audio, sr):\n",
    "    if random.random() < 0.5:\n",
    "        audio = pitch_shift(audio, sr, random.randint(-2, 2))\n",
    "    if random.random() < 0.5:\n",
    "        audio = add_noise(audio, 0.035)\n",
    "    if random.random() < 0.5:\n",
    "        audio = frequency_masking(audio, sr)\n",
    "    if random.random() < 0.5:\n",
    "        audio = time_masking(audio, sr)\n",
    "    return audio\n"
   ],
   "id": "40d21bfe8b06af9a",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T03:12:22.063780Z",
     "start_time": "2024-08-05T03:12:03.965555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = 'datasets/combined/surprised'\n",
    "directory_list = os.listdir(path)\n",
    "file = directory_list[0]\n",
    "\n",
    "for file in directory_list:\n",
    "    y, sr = librosa.load(path + \"/\" + file)\n",
    "    \n",
    "    # Apply individual augmentations\n",
    "    pitch_shifted_audio = pitch_shift(y, sr, 1)\n",
    "    noisy_audio = add_noise(y, 0.035)\n",
    "    # freq_masked_audio = frequency_masking(y, sr)\n",
    "    # time_masked_audio = time_masking(y, sr)\n",
    "    \n",
    "    # Apply combination augmentations\n",
    "    # combined_augmented_audio = combine_augmentations(y, sr)\n",
    "    \n",
    "    sf.write(os.path.join(path, f'shifted_{file}'), pitch_shifted_audio, sr)\n",
    "    sf.write(os.path.join(path, f'noisy_{file}'), noisy_audio, sr)\n",
    "    \n",
    "    # pd.Series(pitch_shifted_audio).plot(figsize=(10, 5), lw=1, title='Raw audio data Tess (normalized)')\n",
    "    # librosa.get_duration(y=pitch_shifted_audio, sr=sr)\n",
    "    # Audio(pitch_shifted_audio, rate=sr)"
   ],
   "id": "5895166a128dcef0",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature extraction",
   "id": "db38a5766b45e5a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T01:47:28.222525Z",
     "start_time": "2024-08-08T01:47:28.199826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa.feature\n",
    "\n",
    "def extract_zcr(audio):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio)\n",
    "    zcr_mean = np.mean(zcr.T, axis=0)\n",
    "    # print(\"extract_zcr\", zcr.shape, zcr_mean.shape)\n",
    "    return zcr_mean\n",
    "\n",
    "def extract_chroma(audio, sr):\n",
    "    chroma = librosa.feature.chroma_stft(S=audio, sr=sr)\n",
    "    chroma_mean = np.mean(chroma.T, axis=0)\n",
    "    # print(\"extract_chroma\", chroma.shape, chroma_mean.shape)\n",
    "    return chroma_mean\n",
    "\n",
    "def extract_mfccs(audio, sr):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    # print(\"extract_mfccs\", mfccs.shape, mfccs_mean.shape)\n",
    "    return mfccs_mean\n",
    "\n",
    "def extract_spectral_contrast(audio, sr):\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "    spectral_contrast_mean = np.mean(spectral_contrast.T, axis=0)\n",
    "    # print(\"extract_spectral_contrast\", spectral_contrast.shape, spectral_contrast_mean.shape)\n",
    "    return spectral_contrast_mean\n",
    "\n",
    "def extract_spectral_rolloff(audio, sr):\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "    spectral_rolloff_mean = np.mean(spectral_rolloff.T, axis=0)\n",
    "    # print(\"extract_spectral_rolloff\", spectral_rolloff.shape, spectral_rolloff_mean.shape)\n",
    "    return spectral_rolloff_mean\n",
    "\n",
    "def extract_rmse(audio):\n",
    "    rmse = librosa.feature.rms(y=audio)\n",
    "    rmse_mean = np.mean(rmse.T, axis=0)\n",
    "    # print(\"extract_rmse\", rmse.shape, rmse_mean.shape)\n",
    "    return rmse_mean\n",
    "\n",
    "def extract_mel_spectrogram(audio, sr):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    mel_spectrogram_mean = np.mean(mel_spectrogram.T, axis=0)\n",
    "    # print(\"extract_mel_spectrogram\", mel_spectrogram.shape, mel_spectrogram_mean.shape)\n",
    "    return mel_spectrogram_mean\n",
    "\n",
    "def extract_features(data, sample_rate):\n",
    "    result = np.array([])\n",
    "    \n",
    "    # ZCR\n",
    "    zcr = extract_zcr(data)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = extract_chroma(stft, sample_rate)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = extract_mfccs(data, sample_rate)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Spectral_contrast\n",
    "    spectral_contrast = extract_spectral_contrast(data, sample_rate)\n",
    "    result = np.hstack((result, spectral_contrast)) # stacking horizontally\n",
    "\n",
    "    # Spectral_rolloff\n",
    "    spectral_rolloff = extract_spectral_rolloff(data, sample_rate)\n",
    "    result = np.hstack((result, spectral_rolloff)) # stacking horizontally\n",
    "\n",
    "    # RMS\n",
    "    rms = extract_rmse(data)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # Mel_spectrogram\n",
    "    mel_spectrogram = extract_mel_spectrogram(data, sample_rate)\n",
    "    result = np.hstack((result, mel_spectrogram)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    data, sample_rate = librosa.load(path)\n",
    "    \n",
    "    features = extract_features(data, sample_rate)\n",
    "    result = np.array(features)\n",
    "    \n",
    "    return result\n"
   ],
   "id": "e05976b30c57ada9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T23:57:30.517250Z",
     "start_time": "2024-08-05T23:57:30.491697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = get_features(\"datasets/combined/angry/crema_0_0.wav\")\n",
    "features.shape"
   ],
   "id": "d6fea3e898efdb2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_zcr (1, 26) (1,)\n",
      "extract_chroma (12, 26) (12,)\n",
      "extract_mfccs (20, 26) (20,)\n",
      "extract_spectral_contrast (7, 26) (7,)\n",
      "extract_spectral_rolloff (1, 26) (1,)\n",
      "extract_rmse (1, 26) (1,)\n",
      "extract_mel_spectrogram (128, 26) (128,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(170,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T02:06:44.667772Z",
     "start_time": "2024-08-08T01:55:19.836525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = \"datasets/combined\"\n",
    "directory_list = os.listdir(path)\n",
    "X = []\n",
    "angry_labels = []\n",
    "disgust_labels = []\n",
    "fear_labels = []\n",
    "happy_labels = []\n",
    "neutral_labels = []\n",
    "sad_labels = []\n",
    "surprised_labels = []\n",
    "\n",
    "for emotion in directory_list:\n",
    "    angry_label = 0\n",
    "    disgust_label = 0\n",
    "    fear_label = 0\n",
    "    happy_label = 0\n",
    "    neutral_label = 0\n",
    "    sad_label = 0\n",
    "    surprised_label = 0\n",
    "    match emotion:\n",
    "        case \"angry\":\n",
    "            angry_label = 1\n",
    "        case \"disgust\":\n",
    "            disgust_label = 1\n",
    "        case \"fear\":\n",
    "            fear_label = 1\n",
    "        case \"happy\":\n",
    "            happy_label = 1\n",
    "        case \"neutral+calm\":\n",
    "            neutral_label = 1\n",
    "        case \"sad\":\n",
    "            sad_label = 1\n",
    "        case \"surprised\":\n",
    "            surprised_label = 1\n",
    "        \n",
    "    samples = os.listdir(path + \"/\" + emotion)\n",
    "    for sample in samples:\n",
    "        features = get_features(path + \"/\" + emotion + \"/\" + sample)\n",
    "        X.append(features)\n",
    "        angry_labels.append(angry_label)\n",
    "        disgust_labels.append(disgust_label)\n",
    "        fear_labels.append(fear_label)\n",
    "        happy_labels.append(happy_label)\n",
    "        neutral_labels.append(neutral_label)\n",
    "        sad_labels.append(sad_label)\n",
    "        surprised_labels.append(surprised_label)\n",
    "    \n",
    "Features = pd.DataFrame(X)\n",
    "Features['angry'] = angry_labels\n",
    "Features['disgust'] = disgust_labels\n",
    "Features['fear'] = fear_labels\n",
    "Features['happy'] = happy_labels\n",
    "Features['neutral'] = neutral_labels\n",
    "Features['sad'] = sad_labels\n",
    "Features['surprised'] = surprised_labels\n",
    "Features.to_csv('datasets/dataset.csv', index=False)\n",
    "Features.head()"
   ],
   "id": "ceceb40dbe3ded1e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.087571  0.562773  0.518651  0.655225  0.707285  0.727889  0.448072   \n",
       "1  0.124568  0.457904  0.494245  0.595628  0.611942  0.353614  0.321154   \n",
       "2  0.180251  0.410289  0.499764  0.502243  0.554269  0.463229  0.482461   \n",
       "3  0.084322  0.366516  0.315910  0.325588  0.493562  0.646365  0.616358   \n",
       "4  0.087384  0.376576  0.329216  0.332739  0.547763  0.756527  0.571407   \n",
       "\n",
       "          7         8         9  ...       167       168       169  angry  \\\n",
       "0  0.416224  0.407370  0.469570  ...  0.000028  0.000027  0.000027      1   \n",
       "1  0.424224  0.517753  0.752975  ...  0.000003  0.000003  0.000003      1   \n",
       "2  0.552123  0.663478  0.645860  ...  0.000011  0.000010  0.000010      1   \n",
       "3  0.526592  0.493724  0.551897  ...  0.000014  0.000014  0.000014      1   \n",
       "4  0.379520  0.367596  0.464656  ...  0.000050  0.000049  0.000049      1   \n",
       "\n",
       "   disgust  fear  happy  neutral  sad  surprised  \n",
       "0        0     0      0        0    0          0  \n",
       "1        0     0      0        0    0          0  \n",
       "2        0     0      0        0    0          0  \n",
       "3        0     0      0        0    0          0  \n",
       "4        0     0      0        0    0          0  \n",
       "\n",
       "[5 rows x 177 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>angry</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087571</td>\n",
       "      <td>0.562773</td>\n",
       "      <td>0.518651</td>\n",
       "      <td>0.655225</td>\n",
       "      <td>0.707285</td>\n",
       "      <td>0.727889</td>\n",
       "      <td>0.448072</td>\n",
       "      <td>0.416224</td>\n",
       "      <td>0.407370</td>\n",
       "      <td>0.469570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.124568</td>\n",
       "      <td>0.457904</td>\n",
       "      <td>0.494245</td>\n",
       "      <td>0.595628</td>\n",
       "      <td>0.611942</td>\n",
       "      <td>0.353614</td>\n",
       "      <td>0.321154</td>\n",
       "      <td>0.424224</td>\n",
       "      <td>0.517753</td>\n",
       "      <td>0.752975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180251</td>\n",
       "      <td>0.410289</td>\n",
       "      <td>0.499764</td>\n",
       "      <td>0.502243</td>\n",
       "      <td>0.554269</td>\n",
       "      <td>0.463229</td>\n",
       "      <td>0.482461</td>\n",
       "      <td>0.552123</td>\n",
       "      <td>0.663478</td>\n",
       "      <td>0.645860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084322</td>\n",
       "      <td>0.366516</td>\n",
       "      <td>0.315910</td>\n",
       "      <td>0.325588</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.646365</td>\n",
       "      <td>0.616358</td>\n",
       "      <td>0.526592</td>\n",
       "      <td>0.493724</td>\n",
       "      <td>0.551897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087384</td>\n",
       "      <td>0.376576</td>\n",
       "      <td>0.329216</td>\n",
       "      <td>0.332739</td>\n",
       "      <td>0.547763</td>\n",
       "      <td>0.756527</td>\n",
       "      <td>0.571407</td>\n",
       "      <td>0.379520</td>\n",
       "      <td>0.367596</td>\n",
       "      <td>0.464656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 177 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T01:10:37.505104Z",
     "start_time": "2024-08-06T01:10:37.495127Z"
    }
   },
   "cell_type": "code",
   "source": "Features.shape",
   "id": "e999bf2253f5996a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43830, 171)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3572e54f1f82b0e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
