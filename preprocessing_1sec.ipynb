{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-11T01:20:11.775488Z",
     "start_time": "2024-08-11T01:20:11.111718Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "# to save the audio files\n",
    "import soundfile as sf\n",
    "\n",
    "# import keras\n",
    "# from keras.callbacks import ReduceLROnPlateau\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "# from keras.utils import np_utils, to_categorical\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:20:22.521199Z",
     "start_time": "2024-08-11T01:20:22.518363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths for data.\n",
    "Ravdess = \"datasets/Ravdess/audio_speech_actors_01-24/\"\n",
    "Crema = \"datasets/Crema/\"\n",
    "Tess = \"datasets/Tess/\"\n",
    "Savee = \"datasets/Savee/\""
   ],
   "id": "471b8a2d6c7160b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Trimming and combining (1sec)",
   "id": "7323ab1f0de2e42d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:20:26.138263Z",
     "start_time": "2024-08-11T01:20:26.124883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "crema_directory_list = os.listdir(Crema)\n",
    "tess_directory_list = os.listdir(Tess)\n",
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "segment_length = 1\n",
    "sampling_rate = 22050"
   ],
   "id": "991277c6bd321de7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ravdess",
   "id": "6adafeee235a2485"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:22:34.875895Z",
     "start_time": "2024-08-11T01:21:57.786187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "actor_counter = 0\n",
    "\n",
    "# Loop through each file and get the length\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(Ravdess + dir)\n",
    "    actor_samples_counter = 0\n",
    "\n",
    "    for file in actor:\n",
    "\n",
    "        # dir = ravdess_directory_list[0]\n",
    "        # file = os.listdir(Ravdess + dir)[0]\n",
    "\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        if int(part[2]) == 1 or int(part[2]) == 2:\n",
    "            path = \"datasets/combined_L/neutral+calm/\"\n",
    "        elif int(part[2]) == 3:\n",
    "            path = \"datasets/combined_L/happy/\"\n",
    "        elif int(part[2]) == 4:\n",
    "            path = \"datasets/combined_L/sad/\"\n",
    "        elif int(part[2]) == 5:\n",
    "            path = \"datasets/combined_L/angry/\"\n",
    "        elif int(part[2]) == 6:\n",
    "            path = \"datasets/combined_L/fear/\"\n",
    "        elif int(part[2]) == 7:\n",
    "            path = \"datasets/combined_L/disgust/\"\n",
    "        elif int(part[2]) == 8:\n",
    "            path = \"datasets/combined_L/surprised/\"\n",
    "        else:\n",
    "            path = \"datasets/combined_L/\"\n",
    "\n",
    "        y, sr = librosa.load(Ravdess + dir + '/' + file)\n",
    "        y_trimmed, _ = librosa.effects.trim(y, top_db=50)\n",
    "        normalized_audio = librosa.util.normalize(y_trimmed)\n",
    "\n",
    "        segment_length_samples = int(segment_length * sr)\n",
    "        num_segments = -(-len(normalized_audio) // segment_length_samples)\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length_samples\n",
    "            end_sample = start_sample + segment_length_samples\n",
    "            segment = normalized_audio[start_sample:end_sample]\n",
    "            \n",
    "            seg_ln = librosa.get_duration(y=segment, sr=sr)\n",
    "            if seg_ln > 0.2:\n",
    "                if segment_length > seg_ln:\n",
    "                    segment = librosa.util.fix_length(segment, size=sampling_rate)\n",
    "            \n",
    "                output_file_path = os.path.join(path, f'ravdess_{actor_counter}_{actor_samples_counter}_{i}.wav')\n",
    "                sf.write(output_file_path, segment, sr)\n",
    "\n",
    "        actor_samples_counter += 1\n",
    "    actor_counter += 1\n"
   ],
   "id": "51a3bccd6c94550a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Crema",
   "id": "9a5518ba60138a03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:25:23.232192Z",
     "start_time": "2024-08-11T01:22:42.019044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_counter = 0\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    part = file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        path = \"datasets/combined_L/sad/\"\n",
    "    elif part[2] == 'ANG':\n",
    "        path = \"datasets/combined_L/angry/\"\n",
    "    elif part[2] == 'DIS':\n",
    "        path = \"datasets/combined_L/disgust/\"\n",
    "    elif part[2] == 'FEA':\n",
    "        path = \"datasets/combined_L/fear/\"\n",
    "    elif part[2] == 'HAP':\n",
    "        path = \"datasets/combined_L/happy/\"\n",
    "    elif part[2] == 'NEU':\n",
    "        path = \"datasets/combined_L/neutral+calm/\"\n",
    "    else:\n",
    "        path = \"datasets/combined_L/\"\n",
    "\n",
    "    y, sr = librosa.load(Crema + file)\n",
    "    y_trimmed, _ = librosa.effects.trim(y, top_db=25)\n",
    "    normalized_audio = librosa.util.normalize(y_trimmed)\n",
    "\n",
    "    # Segment length in samples\n",
    "    segment_length_samples = int(segment_length * sr)\n",
    "\n",
    "    # Number of segments\n",
    "    num_segments = -(-len(normalized_audio) // segment_length_samples)\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_length_samples\n",
    "        end_sample = start_sample + segment_length_samples\n",
    "        segment = normalized_audio[start_sample:end_sample]\n",
    "        \n",
    "        seg_ln = librosa.get_duration(y=segment, sr=sr)\n",
    "        if seg_ln > 0.2:\n",
    "            if segment_length > seg_ln:\n",
    "                segment = librosa.util.fix_length(segment, size=sampling_rate)\n",
    "        \n",
    "            output_file_path = os.path.join(path, f'crema_{file_counter}_{i}.wav')\n",
    "            sf.write(output_file_path, segment, sr)\n",
    "\n",
    "    file_counter += 1\n"
   ],
   "id": "f7d227af3a95a9e4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tess",
   "id": "e941a614034d9621"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:26:32.503347Z",
     "start_time": "2024-08-11T01:25:33.702254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tess\n",
    "folder_counter = 0\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    file_counter = 0\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "\n",
    "        if part == \"angry\":\n",
    "            path = \"datasets/combined_L/angry/\"\n",
    "        elif part == \"disgust\":\n",
    "            path = \"datasets/combined_L/disgust/\"\n",
    "        elif part == \"fear\":\n",
    "            path = \"datasets/combined_L/fear/\"\n",
    "        elif part == \"happy\":\n",
    "            path = \"datasets/combined_L/happy/\"\n",
    "        elif part == \"neutral\":\n",
    "            path = \"datasets/combined_L/neutral+calm/\"\n",
    "        elif part == 'ps':\n",
    "            path = \"datasets/combined_L/surprised/\"\n",
    "        elif part == 'sad':\n",
    "            path = \"datasets/combined_L/sad/\"\n",
    "        else:\n",
    "            path = \"datasets/combined_L/\"\n",
    "\n",
    "        y, sr = librosa.load(Tess + dir + '/' + file)\n",
    "        y_trimmed, _ = librosa.effects.trim(y)\n",
    "        normalized_audio = librosa.util.normalize(y_trimmed)\n",
    "\n",
    "        # Segment length in samples\n",
    "        segment_length_samples = int(segment_length * sr)\n",
    "\n",
    "        # Number of segments\n",
    "        num_segments = -(-len(normalized_audio) // segment_length_samples)\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length_samples\n",
    "            end_sample = start_sample + segment_length_samples\n",
    "            segment = normalized_audio[start_sample:end_sample]\n",
    "            \n",
    "            seg_ln = librosa.get_duration(y=segment, sr=sr)\n",
    "            if seg_ln > 0.2:\n",
    "                if segment_length > seg_ln:\n",
    "                    segment = librosa.util.fix_length(segment, size=sampling_rate)\n",
    "            \n",
    "                output_file_path = os.path.join(path, f'tess_{folder_counter}_{file_counter}_{i}.wav')\n",
    "                sf.write(output_file_path, segment, sr)\n",
    "\n",
    "        file_counter += 1\n",
    "    folder_counter += 1"
   ],
   "id": "1dbf1a370fd9655e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Savee",
   "id": "fc564a36f7a59c36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:27:03.521301Z",
     "start_time": "2024-08-11T01:26:51.631201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# savee\n",
    "file_counter = 0\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele == 'a':\n",
    "        path = \"datasets/combined_L/angry/\"\n",
    "    elif ele == 'd':\n",
    "        path = \"datasets/combined_L/disgust/\"\n",
    "    elif ele == 'f':\n",
    "        path = \"datasets/combined_L/fear/\"\n",
    "    elif ele == 'h':\n",
    "        path = \"datasets/combined_L/happy/\"\n",
    "    elif ele == 'n':\n",
    "        path = \"datasets/combined_L/neutral+calm/\"\n",
    "    elif ele == 'sa':\n",
    "        path = \"datasets/combined_L/sad/\"\n",
    "    elif ele == 'su':\n",
    "        path = \"datasets/combined_L/surprised/\"\n",
    "    else:\n",
    "        path = \"datasets/combined_L/\"\n",
    "\n",
    "    y, sr = librosa.load(Savee + file)\n",
    "    y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "    normalized_audio = librosa.util.normalize(y_trimmed)\n",
    "\n",
    "    # Segment length in samples\n",
    "    segment_length_samples = int(segment_length * sr)\n",
    "\n",
    "    # Number of segments\n",
    "    num_segments = -(-len(normalized_audio) // segment_length_samples)\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_length_samples\n",
    "        end_sample = start_sample + segment_length_samples\n",
    "        segment = normalized_audio[start_sample:end_sample]\n",
    "        \n",
    "        seg_ln = librosa.get_duration(y=segment, sr=sr)\n",
    "        if seg_ln > 0.2:\n",
    "            if segment_length > seg_ln:\n",
    "                segment = librosa.util.fix_length(segment, size=sampling_rate)\n",
    "        \n",
    "            output_file_path = os.path.join(path, f'savee_{file_counter}_{i}.wav')\n",
    "            sf.write(output_file_path, segment, sr)\n",
    "\n",
    "    file_counter += 1\n"
   ],
   "id": "6270818abfb2465d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Augmentation",
   "id": "2790e6e064ba9e44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:36:00.543843Z",
     "start_time": "2024-08-11T01:36:00.538603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Individual augmentation functions\n",
    "def pitch_shift(audio, sampling_rate, n_steps):\n",
    "    return librosa.effects.pitch_shift(audio, sr=sampling_rate, n_steps=n_steps)\n",
    "\n",
    "def add_noise(audio, noise_factor):\n",
    "    noise_amp = noise_factor*np.random.uniform()*np.amax(audio)\n",
    "    audio = audio + noise_amp*np.random.normal(size=audio.shape[0])\n",
    "    return audio\n",
    "\n",
    "def frequency_masking(audio, sr, freq_mask_param=15):\n",
    "    spectrogram = librosa.stft(audio)\n",
    "    spectrogram_db = librosa.amplitude_to_db(np.abs(spectrogram))\n",
    "    \n",
    "    freq_mask = np.random.randint(0, spectrogram_db.shape[0] - freq_mask_param)\n",
    "    spectrogram_db[freq_mask:freq_mask + freq_mask_param, :] = 0\n",
    "    \n",
    "    masked_audio = librosa.istft(librosa.db_to_amplitude(spectrogram_db))\n",
    "    return masked_audio\n",
    "\n",
    "def time_masking(audio, sr, time_mask_param=30):\n",
    "    spectrogram = librosa.stft(audio)\n",
    "    spectrogram_db = librosa.amplitude_to_db(np.abs(spectrogram))\n",
    "    \n",
    "    time_mask = np.random.randint(0, spectrogram_db.shape[1] - time_mask_param)\n",
    "    spectrogram_db[:, time_mask:time_mask + time_mask_param] = 0\n",
    "    \n",
    "    masked_audio = librosa.istft(librosa.db_to_amplitude(spectrogram_db))\n",
    "    return masked_audio\n",
    "\n",
    "# Combination augmentation function\n",
    "def combine_augmentations(audio, sr):\n",
    "    if random.random() < 0.5:\n",
    "        audio = pitch_shift(audio, sr, random.randint(-2, 2))\n",
    "    if random.random() < 0.5:\n",
    "        audio = add_noise(audio, 0.035)\n",
    "    if random.random() < 0.5:\n",
    "        audio = frequency_masking(audio, sr)\n",
    "    if random.random() < 0.5:\n",
    "        audio = time_masking(audio, sr)\n",
    "    return audio\n"
   ],
   "id": "40d21bfe8b06af9a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:36:22.975064Z",
     "start_time": "2024-08-11T01:36:02.174112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = 'datasets/combined_L/surprised'\n",
    "directory_list = os.listdir(path)\n",
    "# file = directory_list[0]\n",
    "\n",
    "for file in directory_list:\n",
    "    y, sr = librosa.load(path + \"/\" + file)\n",
    "    \n",
    "    # Apply individual augmentations\n",
    "    pitch_shifted_audio = pitch_shift(y, sr, 1)\n",
    "    noisy_audio = add_noise(y, 0.035)\n",
    "    # freq_masked_audio = frequency_masking(y, sr)\n",
    "    # time_masked_audio = time_masking(y, sr)\n",
    "    \n",
    "    # Apply combination augmentations\n",
    "    # combined_augmented_audio = combine_augmentations(y, sr)\n",
    "    \n",
    "    sf.write(os.path.join(path, f'shifted_{file}'), pitch_shifted_audio, sr)\n",
    "    sf.write(os.path.join(path, f'noisy_{file}'), noisy_audio, sr)\n",
    "    \n",
    "    # pd.Series(pitch_shifted_audio).plot(figsize=(10, 5), lw=1, title='Raw audio data Tess (normalized)')\n",
    "    # librosa.get_duration(y=pitch_shifted_audio, sr=sr)\n",
    "    # Audio(pitch_shifted_audio, rate=sr)"
   ],
   "id": "5895166a128dcef0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature extraction",
   "id": "db38a5766b45e5a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:38:18.374840Z",
     "start_time": "2024-08-11T01:38:18.369519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa.feature\n",
    "\n",
    "def extract_zcr(audio):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio)\n",
    "    zcr_mean = np.mean(zcr.T, axis=0)\n",
    "    # print(\"extract_zcr\", zcr.shape, zcr_mean.shape)\n",
    "    return zcr_mean\n",
    "\n",
    "def extract_chroma(audio, sr):\n",
    "    chroma = librosa.feature.chroma_stft(S=audio, sr=sr)\n",
    "    chroma_mean = np.mean(chroma.T, axis=0)\n",
    "    # print(\"extract_chroma\", chroma.shape, chroma_mean.shape)\n",
    "    return chroma_mean\n",
    "\n",
    "def extract_mfccs(audio, sr):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    # print(\"extract_mfccs\", mfccs.shape, mfccs_mean.shape)\n",
    "    return mfccs_mean\n",
    "\n",
    "def extract_spectral_contrast(audio, sr):\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "    spectral_contrast_mean = np.mean(spectral_contrast.T, axis=0)\n",
    "    # print(\"extract_spectral_contrast\", spectral_contrast.shape, spectral_contrast_mean.shape)\n",
    "    return spectral_contrast_mean\n",
    "\n",
    "def extract_spectral_rolloff(audio, sr):\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "    spectral_rolloff_mean = np.mean(spectral_rolloff.T, axis=0)\n",
    "    # print(\"extract_spectral_rolloff\", spectral_rolloff.shape, spectral_rolloff_mean.shape)\n",
    "    return spectral_rolloff_mean\n",
    "\n",
    "def extract_rmse(audio):\n",
    "    rmse = librosa.feature.rms(y=audio)\n",
    "    rmse_mean = np.mean(rmse.T, axis=0)\n",
    "    # print(\"extract_rmse\", rmse.shape, rmse_mean.shape)\n",
    "    return rmse_mean\n",
    "\n",
    "def extract_mel_spectrogram(audio, sr):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    mel_spectrogram_mean = np.mean(mel_spectrogram.T, axis=0)\n",
    "    # print(\"extract_mel_spectrogram\", mel_spectrogram.shape, mel_spectrogram_mean.shape)\n",
    "    return mel_spectrogram_mean\n",
    "\n",
    "def extract_features(data, sample_rate):\n",
    "    result = np.array([])\n",
    "    \n",
    "    # ZCR\n",
    "    zcr = extract_zcr(data)\n",
    "    result=np.hstack((result, zcr)) # stacking horizontally\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = extract_chroma(stft, sample_rate)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = extract_mfccs(data, sample_rate)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    # Spectral_contrast\n",
    "    spectral_contrast = extract_spectral_contrast(data, sample_rate)\n",
    "    result = np.hstack((result, spectral_contrast)) # stacking horizontally\n",
    "\n",
    "    # Spectral_rolloff\n",
    "    spectral_rolloff = extract_spectral_rolloff(data, sample_rate)\n",
    "    result = np.hstack((result, spectral_rolloff)) # stacking horizontally\n",
    "\n",
    "    # RMS\n",
    "    rms = extract_rmse(data)\n",
    "    result = np.hstack((result, rms)) # stacking horizontally\n",
    "\n",
    "    # Mel_spectrogram\n",
    "    mel_spectrogram = extract_mel_spectrogram(data, sample_rate)\n",
    "    result = np.hstack((result, mel_spectrogram)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    data, sample_rate = librosa.load(path)\n",
    "    \n",
    "    features = extract_features(data, sample_rate)\n",
    "    result = np.array(features)\n",
    "    \n",
    "    return result\n"
   ],
   "id": "e05976b30c57ada9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:38:24.283159Z",
     "start_time": "2024-08-11T01:38:24.261323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = get_features(\"datasets/combined_L/angry/crema_0_0.wav\")\n",
    "features.shape"
   ],
   "id": "d6fea3e898efdb2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T01:48:15.732197Z",
     "start_time": "2024-08-11T01:39:02.926088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = \"datasets/combined_L\"\n",
    "directory_list = os.listdir(path)\n",
    "X = []\n",
    "angry_labels = []\n",
    "disgust_labels = []\n",
    "fear_labels = []\n",
    "happy_labels = []\n",
    "neutral_labels = []\n",
    "sad_labels = []\n",
    "surprised_labels = []\n",
    "\n",
    "for emotion in directory_list:\n",
    "    angry_label = 0\n",
    "    disgust_label = 0\n",
    "    fear_label = 0\n",
    "    happy_label = 0\n",
    "    neutral_label = 0\n",
    "    sad_label = 0\n",
    "    surprised_label = 0\n",
    "    match emotion:\n",
    "        case \"angry\":\n",
    "            angry_label = 1\n",
    "        case \"disgust\":\n",
    "            disgust_label = 1\n",
    "        case \"fear\":\n",
    "            fear_label = 1\n",
    "        case \"happy\":\n",
    "            happy_label = 1\n",
    "        case \"neutral+calm\":\n",
    "            neutral_label = 1\n",
    "        case \"sad\":\n",
    "            sad_label = 1\n",
    "        case \"surprised\":\n",
    "            surprised_label = 1\n",
    "        \n",
    "    samples = os.listdir(path + \"/\" + emotion)\n",
    "    for sample in samples:\n",
    "        features = get_features(path + \"/\" + emotion + \"/\" + sample)\n",
    "        X.append(features)\n",
    "        angry_labels.append(angry_label)\n",
    "        disgust_labels.append(disgust_label)\n",
    "        fear_labels.append(fear_label)\n",
    "        happy_labels.append(happy_label)\n",
    "        neutral_labels.append(neutral_label)\n",
    "        sad_labels.append(sad_label)\n",
    "        surprised_labels.append(surprised_label)\n",
    "    \n",
    "Features = pd.DataFrame(X)\n",
    "Features['angry'] = angry_labels\n",
    "Features['disgust'] = disgust_labels\n",
    "Features['fear'] = fear_labels\n",
    "Features['happy'] = happy_labels\n",
    "Features['neutral'] = neutral_labels\n",
    "Features['sad'] = sad_labels\n",
    "Features['surprised'] = surprised_labels\n",
    "Features.to_csv('datasets/dataset_L.csv', index=False)\n",
    "Features.head()"
   ],
   "id": "ceceb40dbe3ded1e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.105047  0.575523  0.570168  0.629563  0.657737  0.675737  0.471088   \n",
       "1  0.161821  0.368584  0.428432  0.539139  0.590300  0.394862  0.391811   \n",
       "2  0.048495  0.416398  0.456305  0.366213  0.373536  0.409270  0.357111   \n",
       "3  0.086381  0.365141  0.354305  0.494114  0.693808  0.680345  0.539391   \n",
       "4  0.074174  0.314639  0.372686  0.397095  0.391753  0.489682  0.519263   \n",
       "\n",
       "          7         8         9  ...           167           168  \\\n",
       "0  0.477760  0.565239  0.545473  ...  1.381563e-07  1.360737e-07   \n",
       "1  0.499014  0.623780  0.721728  ...  6.980856e-06  6.932686e-06   \n",
       "2  0.363098  0.395970  0.506166  ...  7.347799e-06  7.279295e-06   \n",
       "3  0.460055  0.496273  0.441196  ...  1.869142e-06  1.863559e-06   \n",
       "4  0.524107  0.475452  0.485388  ...  1.027138e-05  1.013511e-05   \n",
       "\n",
       "            169  angry  disgust  fear  happy  neutral  sad  surprised  \n",
       "0  1.348835e-07      1        0     0      0        0    0          0  \n",
       "1  6.897007e-06      1        0     0      0        0    0          0  \n",
       "2  7.233022e-06      1        0     0      0        0    0          0  \n",
       "3  1.861637e-06      1        0     0      0        0    0          0  \n",
       "4  1.005470e-05      1        0     0      0        0    0          0  \n",
       "\n",
       "[5 rows x 177 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>angry</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105047</td>\n",
       "      <td>0.575523</td>\n",
       "      <td>0.570168</td>\n",
       "      <td>0.629563</td>\n",
       "      <td>0.657737</td>\n",
       "      <td>0.675737</td>\n",
       "      <td>0.471088</td>\n",
       "      <td>0.477760</td>\n",
       "      <td>0.565239</td>\n",
       "      <td>0.545473</td>\n",
       "      <td>...</td>\n",
       "      <td>1.381563e-07</td>\n",
       "      <td>1.360737e-07</td>\n",
       "      <td>1.348835e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161821</td>\n",
       "      <td>0.368584</td>\n",
       "      <td>0.428432</td>\n",
       "      <td>0.539139</td>\n",
       "      <td>0.590300</td>\n",
       "      <td>0.394862</td>\n",
       "      <td>0.391811</td>\n",
       "      <td>0.499014</td>\n",
       "      <td>0.623780</td>\n",
       "      <td>0.721728</td>\n",
       "      <td>...</td>\n",
       "      <td>6.980856e-06</td>\n",
       "      <td>6.932686e-06</td>\n",
       "      <td>6.897007e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048495</td>\n",
       "      <td>0.416398</td>\n",
       "      <td>0.456305</td>\n",
       "      <td>0.366213</td>\n",
       "      <td>0.373536</td>\n",
       "      <td>0.409270</td>\n",
       "      <td>0.357111</td>\n",
       "      <td>0.363098</td>\n",
       "      <td>0.395970</td>\n",
       "      <td>0.506166</td>\n",
       "      <td>...</td>\n",
       "      <td>7.347799e-06</td>\n",
       "      <td>7.279295e-06</td>\n",
       "      <td>7.233022e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.086381</td>\n",
       "      <td>0.365141</td>\n",
       "      <td>0.354305</td>\n",
       "      <td>0.494114</td>\n",
       "      <td>0.693808</td>\n",
       "      <td>0.680345</td>\n",
       "      <td>0.539391</td>\n",
       "      <td>0.460055</td>\n",
       "      <td>0.496273</td>\n",
       "      <td>0.441196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.869142e-06</td>\n",
       "      <td>1.863559e-06</td>\n",
       "      <td>1.861637e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074174</td>\n",
       "      <td>0.314639</td>\n",
       "      <td>0.372686</td>\n",
       "      <td>0.397095</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.489682</td>\n",
       "      <td>0.519263</td>\n",
       "      <td>0.524107</td>\n",
       "      <td>0.475452</td>\n",
       "      <td>0.485388</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027138e-05</td>\n",
       "      <td>1.013511e-05</td>\n",
       "      <td>1.005470e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 177 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T01:10:37.505104Z",
     "start_time": "2024-08-06T01:10:37.495127Z"
    }
   },
   "cell_type": "code",
   "source": "Features.shape",
   "id": "e999bf2253f5996a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43830, 171)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3572e54f1f82b0e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
